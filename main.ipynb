{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## TDDPG Rec System"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a09e1bade02960"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-11T18:18:33.749541Z",
     "start_time": "2024-03-11T16:50:13.537160Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY_CAPACITY: 1000\n",
      "WARNING:tensorflow:From <ipython-input-2-f54e6bf2e0c7>:31: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From /Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Cluster:0\n",
      "A_Loss:-0.9592146970704198 -2.0476703071594238 -2.7128325402736664 -2.955142641067505 -3.274189853668213 -3.7295869636535643 -3.6265320682525637 -3.3461175680160524 -3.703864517211914 -4.019438502788543 -4.310933268070221 -4.560672419071198 -5.038578746318817 -4.538175737857818 -4.40381875038147 -4.5782862830162045 -4.821437828540802 -4.797091612815857 -4.780717959403992 -4.660648672580719 -4.806647427082062 -4.61062831401825 -4.571415934562683 -4.94633367061615 -5.15044219493866 -5.192372274398804 -5.625848183631897 -6.000116291046143 -6.274040174484253 -6.442616600990295 -6.78418568611145 -6.959264211654663 -6.771686019897461 -6.810886130332947 -6.648271722793579 -6.95887776851654 -6.665806646347046 -6.623743071556091 -6.706845788955689 -6.796528806686402 -6.545594186782837 -6.5546927690505985 -6.538251066207886 -6.3589431667327885 -6.322943954467774 -6.25173237323761 -6.5493732357025145 -6.666908392906189 -6.504409232139587 -6.633891234397888 -6.746637825965881 -6.65327748298645 -6.446203722953796 -6.434466285705566 -6.377114515304566 -6.249265365600586 -6.229314107894897 -6.307079892158509 -6.326693415641785 -6.286997880935669 -6.08327353477478 -6.239727144241333 -6.285166869163513 -6.247371616363526 -6.20408022403717 -6.348702440261841 -6.291880044937134 -6.211349382400512 -6.006070351600647 -6.059055633544922 -6.169836983680725 -6.273121752738953 -6.334199471473694 -6.226958227157593 -6.245688028335572 -6.128827152252197 -6.05714693069458 -5.822484087944031 -5.79691891670227 -5.965468764305115 -6.043706908226013 -5.910581088066101 -6.06216739654541 -5.99200174331665 -6.143646817207337 -6.257137026786804 -6.1210481071472165 -6.271712718009948 -6.362096490859986 -6.271284589767456 -6.363398933410645 -6.45062825679779 -6.3201392459869385 -6.390568499565124 -6.362931919097901 -6.320637021064758 -6.288454775810242 -6.358665580749512 -6.423446927070618 -6.2610503196716305 \n",
      "C_Loss:6.451880919933319 4.965433609485626 4.02647390127182 3.7178188800811767 3.7342685508728026 3.649932733774185 3.79680850148201 3.799172396659851 3.7382163679599762 3.5905103170871735 3.6961695420742036 3.7269470381736753 3.9473651373386383 4.1704569029808045 4.093723566532135 3.897265663146973 4.20533415555954 4.583948595523834 4.35097250699997 4.095494562387467 4.554971935749054 4.929953479766846 4.783375760316849 5.141713317632675 4.881680295467377 4.788579946756363 5.302994275093079 5.306514236927033 5.17468353509903 5.207447528839111 5.091118974685669 5.316252641677856 5.159211640357971 5.1980575489997864 4.785673129558563 4.987155146598816 4.802287285327911 4.93265287399292 4.734654257297516 4.75320059299469 4.811546566486359 4.376780309677124 4.890578672885895 5.3138905310630795 5.514963593482971 5.241732141971588 5.174982581138611 5.394522550106049 5.547311558723449 4.919094297885895 4.699742503166199 4.912132034301758 4.514702472686768 4.308387135267258 4.011367659568787 4.151322573423386 3.782728707790375 4.068128614425659 3.6847131562232973 4.984589653015137 4.956426289081573 5.266285253763199 5.020920178890228 5.216262953281403 5.395534582138062 5.3252740836143495 5.418630292415619 5.214750843048096 5.26451628446579 4.341743357181549 4.33853141784668 4.36173730134964 4.444588849544525 4.223197988271713 4.411818816661834 4.398847823143005 4.473566720485687 4.296222178936005 4.397911014556885 4.333399727344513 4.523489031791687 4.4528712153434755 4.425651798248291 4.337762060165406 4.143435461521149 4.448341102600097 4.055602335929871 4.4726036620140075 4.634636785984039 4.303358867168426 4.1784654808044435 4.3942574429512025 4.33550852060318 4.323104693889618 4.134478991031647 4.234292171001434 4.260980341434479 4.1815512037277225 4.295497903823852 4.017925896644592 \n",
      "Mean_Reward:1.4723453628666061 2.5936866589510963 3.412135927889054 3.6699723389511916 5.127343281497714 4.073899713270733 3.9522860703651514 3.9533235253319914 6.018359010155153 5.401059244069811 5.298003416755273 5.300611710321708 4.224231556427553 4.2449606440729974 5.385127854582091 5.888324440496676 4.750604621670643 5.786968004121169 5.784042780088749 6.03678341525835 5.717263486596692 4.678096972455472 5.196589114736022 6.312899662292396 6.241689638572711 5.216222852866009 7.157436638274633 6.592359276567907 5.768950234233024 7.142146358290311 6.625793366716533 5.081331289777053 6.435013747466087 5.270061025253811 6.077238393257867 5.02038159789239 4.764823521685443 7.099626572432652 7.012343533292656 5.320098992592701 5.223075146901263 7.047924626750954 6.562779323533908 5.3325868772934255 5.586837529607401 5.983983024976766 7.508914412683641 5.587094605801489 6.090672421259639 5.378166686270217 5.360074777369299 5.59214748842485 6.963700261905465 4.455921046527511 6.434273089981121 4.8892115377081415 5.979336201505922 6.712814589461616 5.049094889796512 5.5327484811535665 6.160999401524684 5.461039052209609 5.874512299967581 6.437889073206824 5.832308532254044 6.182216190507084 5.043755239250855 5.862264969425386 4.976335728460535 6.832527814016377 6.138443692811839 5.697348120384996 6.123592036047698 6.709863814245016 5.158476276186043 5.908399335058518 5.086968215134851 5.456132614879575 6.140982811224255 7.021895288191458 5.165208463362928 6.920506275732416 5.38647434672663 5.99150721021287 6.54720073438505 5.580769157158088 6.310564671208505 6.590803790496518 6.914879968585573 6.570990024143537 6.74627606386626 5.191384887657495 5.954950175281205 6.897097348712691 5.3638161660413255 5.723428731505735 5.93168581549273 6.748020745485297 5.76832243966106 6.946075884318564 \n",
      "Steps:10000\n",
      "Evaluate of cluster 0, Epoch 0\n",
      "Top 5. Hit_rate:0.9835082458770614 nDCG:0.9103298809379037 Precision:0.23148425787106444 Recall:0.9734854184629297 F1:0.37402827150414786 Total steps:1000\n",
      "Top 10. Hit_rate:0.9910044977511244 nDCG:0.9116369515874008 Precision:0.1209895052473763 Recall:0.9896626778185997 F1:0.2156187000167326 Total steps:1000\n",
      "Top 20. Hit_rate:0.9955022488755623 nDCG:0.9125927443736516 Precision:0.06124437781109446 Recall:0.9955022488755623 F1:0.11538973791328405 Total steps:1000\n",
      "Cluster:0\n",
      "A_Loss:-6.25193727016449 -6.224570622444153 -6.193951168060303 -6.138731746673584 -6.183915753364563 -6.2138126039505 -6.31082462310791 -6.28848560333252 -6.539376492500305 -6.680710306167603 -6.858654994964599 -6.908981704711914 -7.071619834899902 -6.938837738037109 -6.957702574729919 -7.001023774147034 -7.0484660577774045 -6.901234169006347 -6.765771350860596 -6.867542028427124 -6.736335434913635 -6.8601287698745725 -6.665909748077393 -6.442591586112976 -6.2787243747711186 -5.983821754455566 -6.0944263362884525 -6.177528548240661 -6.197145290374756 -5.959010138511657 -6.0268714904785154 -5.8132216215133665 -5.602790379524231 -5.929334602355957 -5.991270899772644 -6.145855488777161 -6.136078290939331 -6.09323356628418 -6.155686688423157 -6.323458552360535 -6.257786827087402 -6.423075780868531 -6.392423658370972 -6.246200919151306 -6.384080414772034 -6.484094672203064 -6.556222047805786 -6.5495141410827635 -6.3992401266098025 -6.161475715637207 -6.300487756729126 -6.169519457817078 -6.134306569099426 -6.1031998443603515 -6.000503249168396 -5.942862629890442 -5.940328388214112 -6.038940649032593 -5.9722531175613405 -5.959024906158447 -5.915316190719604 -5.859148392677307 -5.793458557128906 -5.851794986724854 -5.820512404441834 -5.6646503782272335 -5.5810553216934204 -5.568220038414001 -5.749636087417603 -5.679208302497864 -5.701764011383057 -5.59814817905426 -5.735351600646973 -5.715105576515198 -6.016565732955932 -6.177903289794922 -6.053758153915405 -6.068136997222901 -6.0085287237167355 -5.922382221221924 -6.014587206840515 -5.739269552230835 -5.751355438232422 -5.729719467163086 -5.7249885845184325 -5.60302396774292 -5.692889785766601 -5.582333807945251 -5.517309541702271 -5.409162726402283 -5.435022358894348 -5.538353922367096 -5.709784688949585 -5.535283508300782 -5.698327827453613 -5.805583844184875 -5.694876322746277 -5.733065414428711 -5.747241387367248 -5.551933612823486 \n",
      "C_Loss:4.094763498306275 4.293157941102981 4.283030576705933 4.484844393730164 4.290320732593536 4.535580458641053 4.2409361445903775 4.231139454841614 4.4802687549591065 4.1243030238151555 4.40795597076416 4.5587779235839845 4.481445355415344 4.5260626459121704 4.654263846874237 4.42800669670105 4.565224733352661 4.794750435352325 5.443267498016358 5.79655380487442 5.488284027576446 5.120671570301056 5.322929883003235 5.38796047449112 5.2732265138626095 5.201180772781372 4.898641741275787 5.2505279159545895 4.651268579959869 4.53827465057373 4.5089434158802035 4.5898650574684146 4.348881278038025 4.44942522764206 4.687611980438232 4.3368416285514835 4.364139816761017 4.363840461969375 4.502101082801818 4.527573175430298 4.395437502861023 4.359883313179016 4.270307323932648 4.333703191280365 4.655092945098877 4.38555878162384 4.460269250869751 4.465402278900147 4.283911375999451 4.191821057796478 4.041302709579468 4.22394119977951 4.330160541534424 4.276197718381882 4.1115850472450255 4.129991323947906 4.2822051835060115 3.9958836936950686 4.330241614580155 4.403535289764404 4.500238699913025 4.595919451713562 4.386840534210205 4.290896109342575 4.173572670221329 4.099900979995727 3.6862769150733947 3.995874240398407 3.9613585329055785 3.797561674118042 3.761220036745071 3.772858010530472 3.549411600828171 3.506131100654602 4.103907024860382 4.2464435148239135 4.6299406433105466 4.575889797210693 4.236590359210968 4.177962081432343 4.370287611484527 4.587598149776459 4.752788949012756 4.827564668655396 4.390456876754761 4.30829393863678 4.4235018801689145 4.588550522327423 4.258073536157608 4.1580724310874935 3.9064228904247282 4.242151324748993 4.612527282238006 4.413409888744354 4.568897578716278 4.178526195287705 4.126966172456742 4.073601944446564 4.460544323921203 4.2683237719535825 \n",
      "Mean_Reward:6.142691061934162 6.294780728906287 6.619748429442629 6.848933301486725 6.7488612324717385 5.759923012452743 6.725031797724102 6.488934602210631 6.185032978903011 7.505760355671674 6.105698569327455 7.9559632723239595 7.37408944653973 4.961026471709668 5.96356521455089 6.682304629713332 5.344319956116545 4.662388703759601 6.232241279677884 6.430794533517274 5.560992942705019 7.756723149095822 4.411618994117231 5.983550323068673 6.13212411122052 5.350670623744972 7.038001147158832 6.028705154788335 5.641147531789998 5.4933328965926975 5.965949394792685 4.977431077631982 6.524531166022747 6.623754673018619 6.800331037817651 6.058648186025067 6.306209352994139 6.802351180460222 7.027000703732813 6.414357775336802 6.681127853691716 5.978848733538504 5.500927778602317 7.627805069611926 6.536560841059167 6.619933628282041 6.873323429797457 5.535044068198377 5.301377252310334 6.514471118047502 6.496636583708871 5.372965220640417 5.899598894782344 6.515658182599855 6.185160680157298 6.117435475925912 6.014613687575673 4.81918060440065 6.1192963187620615 6.415319341538895 5.777490502811898 5.702113553209114 5.320455907388537 5.628656643627008 5.038669398523435 4.933142029804461 5.625342844303407 5.116114106472981 7.130332372542715 6.093193235455065 6.343985672733298 6.553996761335182 5.165367517179946 6.42413241258035 7.4234738389320265 6.024378905676974 5.636684674250456 5.513415688312245 6.476053107103448 6.464962326215784 5.128503725428459 4.05573434413083 6.73595563842532 6.886713725679965 5.241850431567912 7.516176548259466 6.164694032100409 5.753018874629082 6.62256744107963 5.391593929445862 5.993069862063378 6.37755119731706 5.896823867620453 6.949473157259811 7.040487285416152 6.7230699953467195 6.390094349056548 6.024428515201821 5.630605648890964 6.208560072792059 \n",
      "Steps:10000\n",
      "Evaluate of cluster 0, Epoch 1\n",
      "Top 5. Hit_rate:0.9820089955022488 nDCG:0.9088363409740189 Precision:0.23163418290854573 Recall:0.972819084963013 F1:0.37417469450533986 Total steps:2000\n",
      "Top 10. Hit_rate:0.9887556221889056 nDCG:0.9099908872503517 Precision:0.12083958020989505 Recall:0.9876636773188496 F1:0.21533316330573712 Total steps:2000\n",
      "Top 20. Hit_rate:0.9970014992503748 nDCG:0.9120101892358256 Precision:0.06128185907046477 Recall:0.9968944099378882 F1:0.11546561153255233 Total steps:2000\n",
      "Cluster:0\n",
      "A_Loss:-5.701635303497315 -5.628089542388916 -5.696987729072571 -5.639933323860168 -5.434904613494873 -5.290829353332519 -5.355774011611938 -5.430548710823059 -5.497252788543701 -5.563079738616944 -5.548407626152039 -5.3390440130233765 -5.40130573272705 -5.226819944381714 -5.249883489608765 -5.296432163715362 -5.320517230033874 -5.410440089702607 -5.4368158006668095 -5.3672922372817995 -5.386943717002868 -5.411662883758545 -5.289201674461364 -5.258373522758484 -5.307934346199036 -5.3362746429443355 -5.478924770355224 -5.587455830574036 -5.589039807319641 -5.635795969963073 -5.694148020744324 -5.745435934066773 -5.919171690940857 -5.925037589073181 -5.932104706764221 -5.806606378555298 -5.668144159317016 -5.591330947875977 -5.4802651643753055 -5.6466007947921755 -5.550536160469055 -5.58263325214386 -5.601567251682281 -5.641767420768738 -5.559300827980041 -5.507142276763916 -5.627160229682922 -5.739714326858521 -5.699677677154541 -5.682562694549561 -5.979884848594666 -5.930343050956726 -5.925665822029114 -5.817952036857605 -5.869771656990051 -5.746591725349426 -5.725833072662353 -5.754715080261231 -5.682913179397583 -5.697772707939148 -5.523855233192444 -5.436067950725556 -5.353383340835571 -5.304480748176575 -5.253837919235229 -5.242791414260864 -5.55017689704895 -5.437235679626465 -5.495840153694153 -5.712400937080384 -5.5502873802185055 -5.546349706649781 -5.766469349861145 -5.961831178665161 -6.019114890098572 -6.134606866836548 -5.8781757831573485 -5.877293400764465 -5.8009988927841185 -5.807201528549195 -5.80357451915741 -5.6938743400573735 -5.593600530624389 -5.464615607261658 -5.3150628423690796 -5.190252757072448 -5.118501219749451 -5.354336850643158 -5.266712467670441 -5.146224732398987 -5.002332742214203 -5.0337498259544375 -4.997161016464234 -5.145614247322083 -5.123508729934692 -5.189032642841339 -5.253438892364502 -5.1682824969291685 -5.2931215691566464 -5.397583913803101 -5.493033809661865 \n",
      "C_Loss:4.493315184116364 4.305342324972153 4.104680061340332 4.169529106616974 4.185745861530304 4.059014972448349 4.2094731879234315 4.000464537143707 3.9926681971549987 4.144323754310608 4.001198132038116 3.684371554851532 4.2084038853645325 3.879651515483856 4.01173956155777 4.140055639743805 3.9770630264282225 4.052781577110291 4.092790048122406 3.803812004327774 3.8888470911979676 3.8622905302047728 3.575515501499176 3.750552251338959 3.8294662165641786 4.057457776069641 4.195560717582703 4.293835728168488 4.520670449733734 4.414067244529724 4.443710267543793 4.483898074626922 4.348823082447052 4.3101220536232 4.506307754516602 4.693435087203979 4.830887696743011 4.668372011184692 4.445363624095917 4.771991393566132 4.141957731246948 4.299461598396301 4.4443137431144715 4.395456666946411 4.170463531017304 3.996046831607819 3.8949738466739654 3.872660449743271 3.835816683769226 3.9127068424224856 3.692527860403061 3.458055624961853 3.5837810492515563 3.7974309945106506 3.833919816017151 4.393492220640183 4.2792944240570066 3.9628548979759217 4.205513412952423 4.458196449279785 4.373883242607117 4.5650830078125 4.333090755939484 4.21159236907959 4.120266771316528 4.037565159797668 4.510891194343567 4.679309456348419 4.764729151725769 4.473887351751327 5.430272645950318 4.676145067214966 5.0885743594169615 4.920022933483124 5.006696460247039 4.580131707191467 4.112041261196136 4.406760592460632 4.137774748802185 4.130995333194733 4.376815192699432 3.9547186613082888 3.9875758910179138 4.034789077043533 4.463546528816223 4.358845076560974 4.4015186762809755 4.626411969661713 4.970897073745728 5.178435232639313 5.047493104934692 4.751663358211517 4.78438246011734 4.566250038146973 4.70772114276886 4.7988805270195005 4.6153838300704955 4.152181959152221 4.4935440254211425 3.9426584815979004 4.065917246341705 \n",
      "Mean_Reward:6.456951475813797 6.3145069386664785 5.77133263687562 6.578224051807048 5.061674791695636 5.693196480387336 6.102635799687565 6.262804702476144 6.670360677335827 5.399152042406731 5.819724108374827 5.687252881060764 5.1466882860073015 5.113128698670144 5.498935542545436 5.327478206804347 5.998609877614955 6.392269924977451 5.517609795494118 6.4716975632961065 5.510293911388196 5.201635955809229 5.351534527311032 5.88416862558654 6.752579525043831 6.364780468173794 7.123853900941761 7.542184159511552 5.056080268641487 6.534235659997313 5.726568157379255 6.395173638177522 5.885883547885787 5.818517815547904 5.697713455816877 5.50161751332547 6.8434696256913305 6.0190239687124505 5.8628942880510735 5.114193394319835 5.748188967391888 7.1408467632314965 5.671858088610993 6.807349896885194 5.725010698267114 5.9320201914698965 6.530672886192821 6.265734948162592 5.371061209179699 7.406747271582733 6.601415065364246 7.811762471897809 5.134907797469719 5.435057309284925 6.456954111535646 5.47995076879596 6.0100728123146725 4.6254075334685085 4.775688598562508 7.3945728590013 5.311575927675014 6.266383747854082 4.323152362249107 5.700015655793403 5.630151961236943 6.108700873961974 6.540643966151512 4.757707368506711 5.852057355543366 6.831106149419205 5.499147103889768 6.245530189076061 6.345124582454883 6.51228095486515 6.141487292102855 6.479597123764055 5.968874548232974 5.5922872161176835 5.415012446820059 7.277954436197066 5.882359919490369 5.312537654884384 5.373965552653417 5.864358580759168 5.6084241550404235 5.950659772277244 6.021209374336821 6.094002611050903 5.4950445896674065 4.808870934763554 5.88651014848105 5.842848664416071 5.692680834448331 4.934922676569936 6.57766901719703 6.1814842998485915 6.398912616433207 5.4451345927576345 6.3743019029847225 5.8544700280635835 5.419489311704935 \n",
      "Steps:10100\n",
      "Evaluate of cluster 0, Epoch 2\n",
      "Top 5. Hit_rate:0.9810094952523738 nDCG:0.9096243969097395 Precision:0.2312843578210895 Recall:0.9716383261360773 F1:0.37363092819900434 Total steps:3010\n",
      "Top 10. Hit_rate:0.9885057471264368 nDCG:0.9111230083363193 Precision:0.12078960519740133 Recall:0.9872472188814018 F1:0.21524391895205924 Total steps:3010\n",
      "Top 20. Hit_rate:0.9965017491254373 nDCG:0.9130807115114459 Precision:0.061244377811094465 Recall:0.9963589633754552 F1:0.11539548848669737 Total steps:3010\n",
      "Cluster:1\n",
      "A_Loss:-0.7060531119536608 -1.7349177873134614 -2.46132466673851 -2.896827380657196 -2.9109048008918763 -3.1117696380615234 -3.057764492034912 -3.1006789326667787 -3.0832033443450926 -3.1844262647628785 -2.8601419162750243 -2.9941044783592226 -2.964652862548828 -3.232059962749481 -3.1601152920722964 -3.276128557920456 -3.2633242869377135 -3.2206175398826598 -3.3301978516578674 -3.2026016664505006 -3.3796639895439147 -3.563814928531647 -3.626167299747467 -3.5906605648994447 -3.42818704366684 -3.1664054775238037 -3.355840570926666 -3.5037870705127716 -3.589680700302124 -3.7738344645500184 -3.6639162731170654 -3.5098443102836607 -3.3316128778457643 -3.3675222516059877 -3.469441089630127 -3.9680224466323852 -4.2131019115448 -4.163015668392181 -3.9986343431472777 -4.061463558673859 -4.161256625652313 -4.098864057064056 -4.3995835494995115 -4.392786405086517 -3.892977809906006 -3.582994136810303 -3.598236954212189 -3.894856436252594 -4.307894105911255 -4.376731705665589 -4.040541250705719 -3.6328923082351685 -3.5741648745536803 -3.752404205799103 -3.7752990317344666 -3.8400551867485047 -3.8634212708473203 -3.9205848383903503 -3.71639431476593 -3.95660293340683 -3.72864013671875 -3.614279179573059 -3.567034718990326 -3.5420499515533446 -3.690713732242584 -3.594085941314697 -3.6371936082839964 -3.6369583201408386 -3.660860366821289 -3.536338243484497 -3.5812400341033936 -3.5006156826019286 -3.3399118185043335 -3.396169400215149 -3.4095931315422057 -3.4683233428001405 -3.398361780643463 -3.266510109901428 -3.122414679527283 -2.9041183578968046 -2.9649654483795165 -3.1476724886894227 -3.0460455656051635 -3.1563647305965423 -2.968999854326248 -2.9940752840042113 -2.968380346298218 -3.0036059856414794 -3.147835760116577 -3.1340703892707826 -3.210721161365509 -3.20865603685379 -3.1763262939453125 -3.2183847522735594 -3.1569681549072266 -3.107788860797882 -3.06916405916214 -3.1444213128089906 -2.9415487802028655 -2.9835346841812136 \n",
      "C_Loss:5.206001834869385 3.3772553312778473 2.561950136423111 2.459447191953659 2.4599790728092192 2.430878564119339 2.514496428966522 2.4399148058891296 2.7456471300125123 2.626738748550415 2.440114594101906 2.4001131576299666 2.4544979560375215 2.4680936205387116 2.6081111705303193 2.7498634600639345 2.519367182254791 2.469792283773422 2.463419369459152 2.663298028707504 2.5170536828041077 2.693015820980072 2.7521869909763335 3.2977211117744445 3.4876862347126005 3.6548938143253324 3.4781834256649016 3.6608347129821777 3.7346789968013763 3.6972357296943663 3.824435005187988 3.72181422829628 3.585509501695633 3.4883392024040223 3.5468680572509768 3.438336914777756 3.4131808269023893 3.4476608633995056 3.3190368700027464 3.6189370357990267 3.313096421957016 3.285432653427124 3.357186706066132 3.759662891626358 3.396921430826187 3.175279961824417 3.029635908603668 3.3788526463508606 3.410131232738495 3.4970409226417543 3.5336344063282015 3.48003497838974 3.6367389142513273 3.6893315529823303 3.5975964295864107 3.3217859184741974 3.3814474785327913 3.425579849481583 3.1522365593910218 3.1121032857894897 3.138405442237854 2.9964467799663543 3.045320293903351 3.317951658964157 3.5186375224590303 3.3019416534900667 3.5121165359020234 3.4306449949741364 3.597411334514618 3.589405517578125 3.4097155642509462 3.1673134887218475 3.151505801677704 3.3691928720474245 2.910294530391693 2.832226595878601 2.794250701665878 2.7735693287849426 2.6381863033771515 2.71360094666481 2.7419620835781098 2.96235072016716 2.839777421951294 2.97504190325737 2.912778090238571 2.892755206823349 2.7403603172302247 2.7254018664360045 2.8721048152446746 2.882882912158966 2.7384767603874205 3.066491457223892 3.145781031847 2.949482876062393 2.8927905488014223 2.68510279417038 2.7479536283016204 3.080305507183075 3.6858849132061007 3.839405232667923 \n",
      "Mean_Reward:0.047116737047072164 1.9773925292099737 2.4984593438227094 1.9628884441394832 2.653611036525122 2.9493028485210573 2.6891404652378155 2.8359905808078762 3.097069110656276 2.94266651260603 2.90576898572792 2.5719846201853587 3.4578750991417353 4.274375329841736 2.425049952516124 3.8299129773112064 3.4130082099415073 2.6970031720387135 3.032679205043704 3.428702286739522 3.8226449293943983 3.01290278014557 4.027974972700994 2.4920155264869974 2.5191959874803254 3.0639393310151037 2.9391350249051085 3.729838877350435 3.478629742203533 4.089982562483468 3.298313183435032 2.758473843530961 2.509030535797228 2.700035680697667 5.025592301476049 4.479535491686191 3.8622924540992942 3.452790279238785 2.882483627864835 4.33084447209001 3.1927642641798766 3.5489189085091732 3.1437972608820512 2.9064626533335574 2.9466022788073034 3.7774685206165475 3.0297545420255023 4.49064679234116 4.821446325014139 3.8869778041911487 3.373280281086157 2.9131312035743258 4.431591512399573 3.088952165115001 3.6601672558852085 3.0667040108470935 2.605050126702697 2.6713324148958413 3.3263456088008794 2.770278610398005 4.503900031922347 3.3266476447939146 3.5376957182330373 2.77298975250324 4.767504741717156 3.1891900578151846 4.7235410088421625 2.6467720589343804 3.180912866374637 2.5959708986619874 3.3146152805571334 2.6380383470805238 3.121192216364956 3.118864886931812 3.8330118951439665 2.5439198755992676 3.5403166884333075 2.3754682202483774 2.850283315903581 2.503507109449684 3.7366310714552884 2.593276322610712 2.815455924502238 3.527099428780862 3.3609257022126173 3.420132634724922 3.33842909592109 3.4675315900357115 3.181402607454002 3.2257951673472576 2.920033545514276 3.8655861164426586 3.1319455457946863 3.290679867203729 2.4286821742463904 3.2877009968103232 3.3866669934413283 2.3542447452332538 2.687733181915499 2.7946535869534803 \n",
      "Steps:10000\n",
      "Evaluate of cluster 1, Epoch 0\n",
      "Top 5. Hit_rate:0.9728199320498301 nDCG:0.8078860837930746 Precision:0.2579841449603624 Recall:0.9505290889375533 F1:0.4058229971832025 Total steps:4010\n",
      "Top 10. Hit_rate:0.9784824462061155 nDCG:0.8085545018246013 Precision:0.13997734994337488 Recall:0.9690755133754543 F1:0.24462044043809544 Total steps:4010\n",
      "Top 20. Hit_rate:0.9875424688561721 nDCG:0.8103969003616668 Precision:0.07412231030577579 Recall:0.984322474102867 F1:0.13786300052612482 Total steps:4010\n",
      "Cluster:1\n",
      "A_Loss:-3.078366603851318 -2.9553634238243105 -3.1462929916381834 -3.065031886100769 -3.168132939338684 -3.2201366686820982 -3.191144759654999 -3.2710254859924315 -3.2993542528152466 -3.5391935181617735 -3.3247525453567506 -3.5455929160118105 -3.67022851228714 -3.7877124071121218 -3.860720841884613 -3.9424994564056397 -3.8605183267593386 -3.7030485820770265 -3.6296217751502993 -3.508050446510315 -3.5848937582969667 -3.615639023780823 -3.6569365215301515 -3.70228892326355 -3.6472429418563843 -3.7309274172782896 -3.708567521572113 -3.883034245967865 -3.962722556591034 -3.944817523956299 -3.720647568702698 -3.822311291694641 -3.6821953320503233 -3.876782548427582 -3.99448392868042 -3.9914206862449646 -4.030553691387176 -3.891920564174652 -3.8263813996315004 -3.9131727385520936 -4.056970236301422 -4.094041059017181 -3.9969397926330568 -3.9672789430618285 -3.8688475728034972 -3.945769610404968 -3.832907831668854 -3.925061981678009 -4.070959393978119 -3.998612859249115 -3.8396168112754823 -3.796071846485138 -3.8240594625473023 -3.7010093665122987 -3.8518705534935 -3.6474031448364257 -3.819858961105347 -3.7970830678939818 -3.651024980545044 -3.793312718868256 -3.850003306865692 -3.8678057479858396 -3.876645276546478 -3.9772257351875306 -3.9759184765815734 -4.140200490951538 -4.153217163085937 -4.238642764091492 -4.278672609329224 -4.439867870807648 -4.4154810404777525 -4.326701896190643 -4.386160888671875 -4.391398937702179 -4.418202037811279 -4.416150689125061 -4.509340081214905 -4.502880699634552 -4.487053663730621 -4.419903790950775 -4.2303146195411685 -4.285436987876892 -4.242323303222657 -4.336243674755097 -4.249419150352478 -4.141018662452698 -4.132466609477997 -4.115934820175171 -4.241394414901733 -4.401428117752075 -4.546318924427032 -4.527855410575866 -4.6160280537605285 -4.470221538543701 -4.485183610916137 -4.534389305114746 -4.686117358207703 -4.748409519195556 -4.729518005847931 -4.636696312427521 \n",
      "C_Loss:3.720908337831497 3.667901784181595 3.363972145318985 3.49318940281868 3.5214263939857484 3.6899436378479002 3.47830247759819 3.5306897163391113 3.1021272134780884 3.0649748754501345 2.9772214579582212 2.932447544336319 2.8311000883579256 2.678086117506027 2.7004469430446623 2.8270755505561826 3.0902263927459717 2.882670300602913 2.7329464769363403 2.6986487710475924 2.804289062023163 2.768813863992691 2.8311857891082766 2.98805207490921 2.901646980047226 2.92355993270874 3.172039395570755 3.1483176600933076 3.3721221077442167 3.1941871321201325 3.1969455206394195 3.1654027664661406 3.1809482741355897 3.1703901648521424 3.2623585379123687 3.2224086368083955 3.3699373483657835 3.286726928949356 3.0606267833709717 3.3862709069252013 3.2439748919010163 3.3302097630500795 3.3580234813690186 3.501065117120743 3.424875237941742 3.1632666862010956 3.206724181175232 3.2990669739246368 3.196344244480133 3.3242966508865357 3.1813361370563507 2.93018213391304 2.835626183748245 2.9197881162166595 3.1195817732810975 3.143081510066986 3.0539759361743926 3.134971560239792 2.81497838139534 2.959064565896988 3.0507324028015135 3.0447325539588928 2.939755609035492 2.9223395264148713 2.815800083875656 2.780593383312225 2.84840380191803 2.8335251915454864 2.9081371033191683 2.98904443025589 2.9802524721622468 2.8365030133724214 2.678102754354477 2.662752254605293 2.679286333322525 2.504873777627945 2.6280970799922945 2.482763274908066 2.569418053627014 2.6455433785915377 2.6607200396060944 2.563221854567528 2.697605119943619 2.7366940808296203 2.7078401935100556 2.6541679286956787 2.6529997825622558 2.4926386988162994 2.6660441017150878 2.689022912979126 2.6881858384609223 2.624720712900162 2.500319719314575 2.64753328204155 2.855481206178665 2.8826496958732606 2.9220597422122956 2.8480557787418364 2.967490611076355 2.8851325261592864 \n",
      "Mean_Reward:2.6200306489720107 3.710902647019881 3.7972674326358704 3.3539259807544277 2.4817769704867327 3.1110389692871827 4.308595070092384 2.5702061818855615 3.908432880805267 2.8077686006357356 3.041392939529638 3.043797629165796 4.101128389583589 3.110261241979626 3.203313079782153 2.773718493357945 3.3188249177439957 2.695089729545147 2.315689335921837 3.654877598752386 3.3658600386797675 3.9233769376656107 3.344683887915478 2.9030773998787316 3.8300831625407756 3.938732575655241 3.0437828697555087 4.317166185862392 3.1253287121204316 3.354382239576471 3.1236561768538165 3.5934842693958924 2.748932884908655 4.045460469137816 2.848213320357678 4.189046678753524 3.1283951237048075 2.7358456707383696 4.094006237888486 4.022203786343147 3.1954359146374434 3.092417890868141 2.8301454392218623 2.856030566542475 3.348993182230343 3.66455194207298 3.1668334934439257 3.6244942939485583 2.5340563321721508 3.3565049564927008 2.869946702055374 2.8250931637530425 2.8635116734878623 3.4576589275728025 2.589857544072926 3.2720504692718206 3.604573812486346 2.426284086947009 2.702896761818291 3.742354373198846 3.199632017516834 3.301537385351501 3.0172356545345065 3.549290555916021 3.0873764628037668 3.630150438731967 2.9373127173291107 3.530619957730525 2.5366876239000877 4.13050868008441 3.226220018020842 2.867027939693112 3.261986644286895 2.7655279090304816 4.049987572890513 3.16235288537496 3.273711638118272 3.6719630448874234 3.047101874355003 2.851083986249979 3.9407629451374926 3.1663825318737118 3.662669743740959 3.082857476698036 2.6334777936767906 2.4246857457138953 2.855411438381875 3.3704568200890583 4.148840946634807 2.9962141206762785 3.8945386300631744 3.4349217960399523 3.0794764833666766 2.990690789098896 2.8055580475559303 4.023722955068916 3.8297602649683973 3.191434423808081 2.917769257353754 3.2576000088921404 \n",
      "Steps:10000\n",
      "Evaluate of cluster 1, Epoch 1\n",
      "Top 5. Hit_rate:0.9716874292185731 nDCG:0.8205748360142403 Precision:0.258550396375991 Recall:0.9499740873236 F1:0.40647248260342195 Total steps:5010\n",
      "Top 10. Hit_rate:0.9750849377123443 nDCG:0.8206817666385882 Precision:0.13997734994337488 Recall:0.9659862973190808 F1:0.24452174364710938 Total steps:5010\n",
      "Top 20. Hit_rate:0.986409966024915 nDCG:0.8231542583838888 Precision:0.07406568516421291 Recall:0.9832322397170493 F1:0.13775436217031095 Total steps:5010\n",
      "Cluster:1\n",
      "A_Loss:-4.756198163032532 -4.698582291603088 -4.814831173419952 -4.802099266052246 -4.8880171298980715 -4.930948839187622 -4.921171855926514 -4.880236976146698 -5.035173754692078 -5.062110154628754 -5.002083303928376 -5.052039308547974 -5.150665264129639 -5.182906713485718 -5.35438982963562 -5.342048625946045 -5.337314033508301 -5.165842065811157 -5.1228362607955935 -5.082343120574951 -5.093919811248779 -5.018991327285766 -5.043661346435547 -5.016828484535218 -4.89348596572876 -4.892784538269043 -5.078880848884583 -5.1666076421737674 -5.109566164016724 -5.152175250053406 -5.095146842002869 -5.2641944360733035 -5.186725006103516 -5.155153760910034 -5.364682879447937 -5.324021248817444 -5.287877702713013 -5.219343590736389 -5.062499742507935 -4.862247676849365 -4.966000237464905 -5.011142106056213 -5.106991510391236 -5.097983937263489 -5.006103863716126 -5.012437191009521 -4.849470298290253 -4.754000554084778 -4.7252924489974975 -4.686925086975098 -4.592941892147064 -4.412178378105164 -4.509323837757111 -4.30762540102005 -4.147368507385254 -4.205642719268798 -4.223258624076843 -4.197967014312744 -4.113370270729065 -4.326537277698517 -4.322004609107971 -4.380091013908387 -4.387066457271576 -4.523240094184875 -4.518775017261505 -4.422084994316101 -4.5460187458992 -4.48959478855133 -4.4580921053886415 -4.31072452545166 -4.290621731281281 -4.343866784572601 -4.339837601184845 -4.270694892406464 -4.382623302936554 -4.530081787109375 -4.226874074935913 -4.142983253002167 -4.404782371520996 -4.43317773103714 -4.2797454476356505 -4.1573661422729495 -3.9610079765319823 -4.040945627689362 -3.999053394794464 -3.9868073892593383 -4.00765725851059 -4.236948940753937 -4.388352479934692 -4.459958581924439 -4.447998752593994 -4.367003939151764 -4.361749403476715 -4.481726059913635 -4.423481297492981 -4.60604332447052 -4.598008139133453 -4.507591016292572 -4.36679634809494 -4.399603912830353 \n",
      "C_Loss:3.040659639835358 3.019865572452545 3.173310452699661 2.919812023639679 3.094519180059433 2.9181706213951113 3.014475531578064 2.9719952619075776 3.0446685659885406 3.2098543751239776 3.0906309342384337 2.9949189960956573 3.018874043226242 3.1721753776073456 3.2950436305999755 3.1617432034015653 3.3034664487838743 2.970469592809677 2.791688438653946 2.8755428433418273 2.698376914262772 2.6979146552085878 2.757252939939499 2.47728213429451 2.717458280324936 2.472333216667175 2.6111105209589005 2.576296372413635 2.605343965291977 2.875106671452522 2.669932565689087 2.9183184349536897 2.8589839470386504 2.7139621794223787 2.8859001493453977 2.8959212577342988 2.848396226167679 2.783516139984131 2.9201469087600707 3.0054713535308837 2.735504195690155 2.648158996105194 2.7282024347782134 2.8087974894046783 2.7850258564949035 2.814124246835709 2.828722901344299 3.0881994926929472 3.0613847303390505 3.040392735004425 3.207159560918808 3.0699997615814207 3.1181875646114348 2.815211822986603 2.846045125722885 2.862491306066513 2.9890379905700684 2.682664715051651 2.590485482215881 2.6983564782142637 2.5279941821098326 2.5350049328804016 2.5563633239269254 2.7390925657749174 2.833451589345932 3.449475880861282 3.328513978719711 3.0001239371299744 3.884362405538559 3.9655136704444884 4.055967812538147 4.167092372179031 4.073623880147934 3.9343462681770323 4.142713248729706 3.6510943365097046 3.5241153663396836 3.6895389461517336 3.539741221666336 3.1635762894153596 3.07116263628006 2.8519953167438508 2.7128767657279966 2.6567919659614563 2.5804402923583982 2.5483134984970093 2.589186930656433 2.558987817764282 2.622707155942917 2.5421540212631224 2.4692997109889983 2.6910314428806306 2.8048689794540405 2.87302809715271 2.951157191991806 3.010017809867859 3.0950215923786164 3.0573702001571657 3.1667294466495512 3.0334817242622374 \n",
      "Mean_Reward:3.3607950395543607 4.061071294517642 3.819479857785603 3.1186602184607155 3.690165260047762 3.0208298567177794 3.809519902817371 3.2578556439032575 4.750263880923846 3.038946951063424 3.6678539393066867 3.183829895582686 3.5965531063106875 3.810082615539082 3.6804050069808154 2.615914769794473 2.472806457299539 2.605104029145454 3.569518188417423 3.0675056383198953 2.9140430546761773 3.3709186742597006 3.1763759475070468 2.576592773817832 2.9488157732550166 3.030434315003246 3.488522198411141 3.481127704224859 3.6255765037342367 3.5820230969206426 3.310585166606481 2.963724947170228 3.005981737387547 2.9420948404737577 3.834868294553882 2.8299643019307097 2.9331885351984783 2.7082655247326466 2.4104598780752644 2.791836710366378 3.059503619228973 4.566943671244951 3.1224913630786277 3.9425379210696865 3.4914409901858714 2.436062188304413 3.1422733660535447 3.3710072782177303 2.881641388602717 2.0297456291557516 2.821857801966097 2.928308793859124 2.317763479320779 2.5509900556949696 4.049725226504603 2.528887529416151 2.865494548198604 2.9255967052638687 3.715693317244245 2.8941633781154685 3.2754387517630867 3.655420584112775 2.832811821604719 2.58374641896354 2.56531089808508 2.8351175407168934 2.6634847310617205 2.1942991876503246 2.2507869059798673 2.120042729187883 3.3195821057997907 4.3572853108139125 2.619139584108942 2.3312819629380153 3.0732069470021512 3.0481128366124968 2.1424664091576293 3.272413072370126 3.473955973256236 1.7937139358005851 2.769689522645561 2.3784029271525005 2.3615126076918536 1.9523465670494133 2.3352092058212746 2.4034145711026365 3.1626161988669397 3.810713025813447 3.0200656499469436 2.3687020043655123 2.8483176804176664 2.0461705444698097 3.1387374536931905 2.6434726693455777 3.5061056535530337 3.1862810815658236 3.6075735440635066 2.8574788764662005 3.316345383697881 3.0381471042661463 \n",
      "Steps:10000\n",
      "Evaluate of cluster 1, Epoch 2\n",
      "Top 5. Hit_rate:0.9716874292185731 nDCG:0.8159904351764431 Precision:0.2584371460928652 Recall:0.9495203582609413 F1:0.40629099536379176 Total steps:6010\n",
      "Top 10. Hit_rate:0.9739524348810872 nDCG:0.8158976496576091 Precision:0.13993959984899965 Recall:0.964808335665468 F1:0.24442638156719326 Total steps:6010\n",
      "Top 20. Hit_rate:0.9848999622499056 nDCG:0.8182529071568293 Precision:0.0739524348810872 Recall:0.9814217413040593 F1:0.13754071358210357 Total steps:6010\n",
      "Cluster:2\n",
      "A_Loss:-0.7545711996406317 -2.1025159680843353 -3.727442669868469 -4.724736557006836 -5.024901270866394 -5.042646718025208 -5.005315074920654 -5.107227244377136 -5.441214957237244 -5.458803505897522 -5.703666381835937 -5.835667099952698 -5.9151382160186765 -6.098508744239807 -6.215573773384095 -6.2287749624252315 -6.244414825439453 -6.3011472797393795 -6.3249819946289065 -6.352060399055481 -6.052808480262756 -5.964587025642395 -6.027295260429383 -6.343371205329895 -6.372060241699219 -6.1026136302948 -6.315069637298584 -5.9775675010681155 -6.010228796005249 -5.915988574028015 -5.984525971412658 -6.008831791877746 -6.079185314178467 -5.847397379875183 -5.879348521232605 -6.315485835075378 -6.459833521842956 -6.368404574394226 -6.4906562280654905 -6.561178183555603 -6.430231695175171 -6.501160435676574 -6.539804077148437 -6.364952135086059 -6.268384666442871 -6.095507125854493 -5.945614023208618 -5.953866453170776 -6.0587577676773074 -6.030671820640564 -5.917425336837769 -5.9897773694992065 -6.14406849861145 -6.482276377677917 -6.545837645530701 -6.44475715637207 -6.496281208992005 -6.568153753280639 -6.659162998199463 -6.701140179634094 -6.705025644302368 -6.861008477210999 -6.7676977443695066 -6.5257577705383305 -6.554477243423462 -6.6631762981414795 -6.558096251487732 -6.376240959167481 -6.3275710344314575 -6.197927060127259 -6.359228830337525 -6.2770434093475345 -6.626337280273438 -6.530891571044922 -6.284423809051514 -6.137979187965393 -5.920803933143616 -6.02265034198761 -6.070079627037049 -6.192475652694702 -6.044910316467285 -5.960233702659607 -5.996246781349182 -5.84644510269165 -5.861825103759766 -6.069830288887024 -6.086180906295777 -6.17963791847229 -6.260972309112549 -6.218479318618774 -6.034116539955139 -6.21902410030365 -6.2880304908752445 -6.338028435707092 -6.26721697807312 -6.407414436340332 -6.392930836677551 -6.057795605659485 -6.198112325668335 -6.205384788513183 \n",
      "C_Loss:3.761858159303665 2.6919765949249266 2.0792670106887816 1.7686335587501525 1.8774644339084625 1.6204679822921753 1.5224276787042619 1.5143345046043395 1.6433134657144546 1.8226509124040604 2.0238728654384612 2.3527885699272155 2.351702345609665 2.3560468584299086 2.4056407809257507 2.7846425211429597 2.8350840997695923 2.942510414123535 3.0483239912986755 3.1357202661037444 2.772172350883484 2.777364957332611 2.746687202453613 2.7844763225317 2.816392812728882 2.7282643127441406 3.0465910410881043 3.0909878420829773 3.2214098048210142 2.977846636772156 2.982998574972153 2.9493937158584593 2.904549607038498 2.863167120218277 2.5600212800502775 2.8745467710494994 2.8479551458358765 2.7222418904304506 2.647131212949753 2.8595633268356324 3.1442363512516023 3.1605818009376527 2.916892706155777 2.9176895415782926 2.873488472700119 2.87525111913681 3.049373917579651 2.9322933661937713 2.8872155249118805 3.1354503512382506 3.0434545719623567 3.2607292413711546 3.178741543292999 3.605770809650421 3.4735526871681213 3.531201386451721 3.650888819694519 3.6403850495815275 3.7542140007019045 3.610200208425522 3.6345503771305085 3.4987216699123382 3.5452754843235015 3.2917869007587433 3.4351103687286377 3.109481973648071 3.169502719640732 3.1067190051078795 3.1054309642314912 2.828937683105469 2.886623876094818 2.8547636902332307 2.792164399623871 3.0050085961818693 2.8059622120857237 2.8462141764163973 2.827044131755829 3.0088438212871553 3.226414850950241 3.420727994441986 3.3121491158008576 3.818328720331192 3.836417410373688 3.576690753698349 3.4812051451206205 3.86680806517601 3.309061127901077 3.4491720533370973 3.344161502122879 3.342883472442627 3.0488304936885835 3.321877022981644 3.4010720443725586 3.397693169116974 3.632646542787552 3.4580240774154665 3.54710089802742 3.322987291812897 3.306330541372299 3.2867601430416107 \n",
      "Mean_Reward:0.1463442692781838 1.3958500892731458 1.4779875896652017 1.270698638406574 1.122532802805576 1.5705979541898853 1.7379246807824407 2.5835410029270025 2.7648134977626055 2.282049767805833 3.4368859892985117 2.5025887048833146 3.9786091747021275 3.9653889307115686 2.8945800887613897 3.119094857454523 3.755051605259089 3.617266492166126 4.2023532057694 2.975132470765251 3.1504333700261533 3.0645305610476274 4.063819580339052 3.716725436533267 3.2160415181910524 4.630790556481293 2.2468004876293937 2.8236678043393004 2.4471031930817793 3.3239549651327076 2.5680549294138535 3.3309189568538056 2.7772351664947634 3.8377064083682098 3.5330232081780997 4.626206018039463 3.637951726441682 3.0134729253397707 3.8633312845478414 3.459280119794796 3.634013632428928 3.431736553296277 3.075414191430531 2.5585976132145984 3.8884359284581493 3.0746488050197263 3.7788956213562557 3.6836607049228247 3.65361509858903 3.8879331728164574 3.1813875947012487 4.059827157624901 3.446240807171754 4.433537932095919 3.871213607372592 3.461774451409434 3.71998368296445 3.945143028836451 4.125899379230384 4.119162068105514 5.1095344556689835 4.3986064015474255 3.4929722282453937 2.5250027302262508 4.35564287669307 4.353417974379289 3.238966065220436 3.686757628284998 3.8198713024982 3.955895487416892 3.762599111929474 3.3896870714963687 4.759142115631473 3.8079112145461833 3.837884792900423 2.88096615763155 4.468932435054421 4.513669264919378 3.1008837778108638 4.28020041508041 3.1172906466049914 2.8523784870737505 4.613126751227425 2.9499339197015537 3.9265143461398937 3.3996162066588753 3.4716801777710873 4.510998970397583 3.916077405088833 3.7245250913977035 3.941256285819028 3.6318424566988075 4.455655169418505 4.293933183252969 4.3929979170746325 3.6245613911675543 3.2502911610717287 4.010098349156675 4.693140455357881 4.27642697547786 \n",
      "Steps:10000\n",
      "Evaluate of cluster 2, Epoch 0\n",
      "Top 5. Hit_rate:0.9715639810426541 nDCG:0.8398190060183747 Precision:0.24241706161137444 Recall:0.9576818365387834 F1:0.38689848591799236 Total steps:7010\n",
      "Top 10. Hit_rate:0.981042654028436 nDCG:0.8424545337804527 Precision:0.1279620853080569 Recall:0.9725228580211119 F1:0.2261656383282117 Total steps:7010\n",
      "Top 20. Hit_rate:0.990521327014218 nDCG:0.8447773510785748 Precision:0.06723933649289102 Recall:0.986136488040797 F1:0.12589447879042906 Total steps:7010\n",
      "Cluster:2\n",
      "A_Loss:-6.207475347518921 -6.207967495918274 -6.025688886642456 -5.8587671709060665 -5.660035581588745 -5.5648812437057495 -5.636381788253784 -5.72188401222229 -5.7362091970443725 -5.914245638847351 -5.842898044586182 -5.933922829627991 -5.797707443237305 -6.010468425750733 -6.053301877975464 -5.835239400863648 -5.8746997308731075 -5.742365980148316 -5.655757369995118 -5.740128664970398 -5.82538941860199 -5.877139220237732 -5.996090888977051 -5.997513279914856 -5.876427655220032 -5.735105018615723 -5.78511305809021 -6.0966561412811275 -6.260195798873902 -6.422200198173523 -6.442067103385925 -6.538329100608825 -6.459719452857971 -6.37392117023468 -6.3765089273452755 -6.500809817314148 -6.567823972702026 -6.522611923217774 -6.39830650806427 -6.342539076805115 -6.320094032287598 -6.3610768699646 -6.141030011177063 -6.07980947971344 -6.037376847267151 -6.278001937866211 -6.244272646903991 -6.149840593338013 -5.956310539245606 -5.9059285640716555 -5.92387957572937 -5.827010331153869 -5.9321930742263795 -6.0502812910079955 -6.12776093006134 -6.042969479560852 -6.0333953905105595 -6.100958766937256 -6.04351423740387 -6.095280780792236 -6.022898573875427 -5.851557302474975 -5.843797121047974 -5.756093277931213 -5.806815619468689 -5.692935452461243 -5.561959576606751 -5.5995868921279905 -6.008646574020386 -6.32125759601593 -6.613439202308655 -6.513660354614258 -6.303812556266784 -6.195605907440186 -5.944146523475647 -5.784685401916504 -5.916744666099548 -5.795491647720337 -5.801355538368225 -5.816643643379211 -5.941327795982361 -6.132788414955139 -6.389301838874817 -6.3200777149200436 -6.347925577163696 -6.582970051765442 -6.606261115074158 -6.790567221641541 -6.9447794008255 -7.067802982330322 -6.943818154335022 -6.887240176200867 -6.726560320854187 -6.761889019012451 -6.964299635887146 -7.1884783744812015 -7.2223766851425175 -7.095573306083679 -6.911765570640564 -7.077554936408997 \n",
      "C_Loss:3.042342103719711 3.1076077854633333 3.2569671547412873 3.1576028537750243 3.071908017396927 3.085254272222519 2.987902034521103 3.2872621631622314 2.9242812156677247 3.229125908613205 2.918997738361359 2.9152677977085113 2.8394007158279417 2.876200406551361 2.867858877182007 2.5903919088840484 2.745417959690094 2.614600473642349 2.89669020652771 2.671960973739624 2.8969024419784546 2.8399683344364166 2.8462351047992707 2.952559801340103 2.91041446685791 2.823157855272293 2.8979700899124143 3.047294052839279 3.1351730608940125 3.1899944829940794 3.0205292224884035 3.2608087074756624 3.032289113998413 3.084821537733078 2.9188698625564573 3.074936339855194 3.221853960752487 3.1752833986282347 3.075999108552933 3.095180252790451 3.024090232849121 3.06857705950737 3.2051392257213593 3.0852393984794615 2.818165009021759 2.801760321855545 2.7316435611248018 2.7605347347259523 2.5472793698310854 2.8590915250778197 2.8688282322883607 2.7302685701847076 2.811073796749115 2.8237125492095947 2.936440908908844 2.792382502555847 2.9530484247207642 2.9272545278072357 2.808654478788376 3.1053025448322296 2.833279297351837 3.107215405702591 3.0689745008945466 3.1040451300144194 2.9260241878032685 3.1518860340118406 2.914464042186737 2.685066454410553 2.928799960613251 3.127562069892883 3.1623361003398895 3.08944770693779 3.228967767953873 3.1099802434444426 2.892787538766861 3.070632153749466 3.205447950363159 2.871664295196533 2.8359183192253115 2.943058476448059 2.892147773504257 3.0470473527908326 3.0798554825782776 3.1931329238414765 3.1133692502975463 3.0906326031684874 3.4048005104064942 3.28739009141922 3.161402413845062 3.3618201184272767 3.130639147758484 3.0267443013191224 2.9171146762371065 2.889736067056656 2.8374228894710543 3.264151784181595 3.369980400800705 3.0265690302848816 2.8020274937152863 2.69094473361969 \n",
      "Mean_Reward:3.6376602355443315 3.1816056588933166 4.406819584336211 3.537707329279064 3.4606592742984734 4.053691243231738 3.0523260305033735 3.506015650701616 3.311391145619501 3.5013391118325994 3.5681912114880987 3.2769916575014135 3.2236503136867123 3.8972959944295695 3.409039673466077 4.217722129293815 3.6466921905783267 2.8829017806484014 4.499131616004038 3.2426202388032124 4.298503185171121 4.403533349566324 3.7154808080719786 3.041571103313627 3.301846341415924 3.5639086423898796 4.406865164680951 4.996202839254202 4.168098754918953 3.7544153652121874 3.7108575908808827 4.612297108454092 3.5913856848968964 3.822648595118596 3.4784710456518777 3.723229558741068 4.95422352956667 3.1585059831523914 4.730914388747555 3.2618554889229308 4.478671239185098 3.708629964775871 2.531437349897407 3.4055065384933325 4.266154394059666 3.4351917997508523 4.100112710599769 3.118714748886512 3.9551161832100923 3.1460521054260635 3.4542178642692436 3.8395029054195273 3.1850339033063877 3.9449930802559283 3.535837444820315 3.7113372651704206 3.624235368954012 3.8392764905710397 3.816630054211087 3.7819300390255335 3.369573793564841 3.009905086395214 3.662623236663141 4.443480472120428 3.060124297981234 2.645071346850747 3.5284365199695533 3.562435425917903 4.731970974545316 4.312143975724109 4.258702790593502 2.964634145353067 3.150384538253178 3.981915163886012 2.6325977883454725 3.8094176543816936 2.9364279308898205 2.62023936934571 3.6464303246255803 3.886444379905039 4.543704567757228 4.8338603477687725 3.718065526885039 3.5285281883066633 3.84392500531809 3.1963725724593943 4.527113829929164 4.941536410586075 4.00130949259254 3.4425429158578726 3.55579740038674 3.4457273902109695 3.6060055929416275 3.1192266241159707 4.153884123738863 4.017225205742418 2.6470503698751675 3.0222094355967726 3.8850620827518965 4.68620940295528 \n",
      "Steps:10000\n",
      "Evaluate of cluster 2, Epoch 1\n",
      "Top 5. Hit_rate:0.9603080568720379 nDCG:0.8353483252178701 Precision:0.23933649289099532 Recall:0.9434995601527155 F1:0.3818173859029471 Total steps:8010\n",
      "Top 10. Hit_rate:0.9709715639810427 nDCG:0.8384644739156308 Precision:0.1261848341232228 Recall:0.9598823844941954 F1:0.22304786640271007 Total steps:8010\n",
      "Top 20. Hit_rate:0.9875592417061612 nDCG:0.8424198591688001 Precision:0.06673578199052134 Recall:0.9817278963691722 F1:0.12497584366619872 Total steps:8010\n",
      "Cluster:2\n",
      "A_Loss:-7.268767905235291 -7.400735721588135 -7.300198254585266 -7.079396715164185 -7.08911633014679 -7.0639893388748165 -7.054714035987854 -7.001834487915039 -6.888971405029297 -6.773859000205993 -6.702656579017639 -6.758323659896851 -6.616444931030274 -6.389020409584045 -6.2503046035766605 -6.342085242271423 -6.225114369392395 -6.341662259101867 -6.349827556610108 -6.386302466392517 -6.389415431022644 -6.3630999040603635 -6.225562777519226 -6.004382085800171 -5.909160184860229 -5.966143712997437 -6.079557409286499 -6.1285088968276975 -6.206606321334839 -6.226004571914673 -6.364343886375427 -6.448192467689514 -6.428441653251648 -6.352577953338623 -6.578324284553528 -6.628727703094483 -6.88067467212677 -6.754472246170044 -6.700399432182312 -6.6332665014266965 -6.785517559051514 -6.790711636543274 -6.826462368965149 -7.000339999198913 -7.034394283294677 -7.026055254936218 -7.171203045845032 -7.134800562858581 -7.077290186882019 -6.982714428901672 -7.148741340637207 -7.140136017799377 -7.190177645683288 -7.184990162849426 -7.073510551452637 -6.8420950269699095 -6.706376118659973 -6.849688444137573 -6.632085881233215 -6.64970000743866 -6.629110651016235 -6.640367956161499 -6.556082935333252 -6.478024983406067 -6.437993540763855 -6.458066401481628 -6.426598262786865 -6.423773102760315 -6.41299409866333 -6.605586709976197 -6.533302383422852 -6.7130598449707035 -6.664436106681824 -6.781542835235595 -6.839658331871033 -6.819977903366089 -6.8284975004196165 -6.832601752281189 -6.737640438079834 -6.663099460601806 -6.717231850624085 -6.751253309249878 -6.842383503913879 -6.739424591064453 -6.898534202575684 -6.842308807373047 -7.076824650764466 -7.032753481864929 -7.032113819122315 -7.0475246667861935 -6.993004331588745 -6.958998394012451 -6.927680854797363 -6.926834621429443 -7.0388533306121825 -7.080012397766113 -7.185938692092895 -7.309535756111145 -7.318116455078125 -7.356875281333924 \n",
      "C_Loss:3.065612373352051 2.922855498790741 3.1541971242427826 3.1624173486232756 3.2517942237854003 3.127363005876541 3.3115107679367064 3.3498485040664674 3.365690813064575 3.5088141632080077 3.4471953892707825 3.3858624076843262 3.6504689860343933 3.4850416946411134 3.685795955657959 3.631690652370453 3.703180832862854 3.667441520690918 3.5609547293186186 3.55137521147728 3.394367747306824 3.4116134917736054 3.347195658683777 3.1007863771915436 2.903846278190613 2.8551351153850555 2.849296097755432 3.122423928976059 2.9467479276657103 2.7877913439273834 2.8816868937015534 2.703754723072052 3.266990342140198 3.0230853188037874 3.4969567966461184 3.2519772708415986 3.2247470355033876 3.276034518480301 3.647529966831207 3.501962814331055 3.603023602962494 3.2938286423683167 3.7236492323875425 3.550670318603516 3.416807086467743 3.460772515535355 3.470818110704422 3.432574713230133 3.693238092660904 3.50639297246933 3.329499161243439 3.1937418460845945 3.0793154609203337 3.0918324530124663 3.084710648059845 3.1351349103450774 2.987182066440582 2.980777666568756 3.026816402673721 2.9376807701587677 2.952334487438202 3.009869947433472 2.8987309408187865 3.0352603077888487 2.769211918115616 2.7298077058792116 2.9725553607940673 2.846900453567505 2.6962908804416656 2.6351768732070924 2.874875555038452 2.9777676367759707 3.0201338791847228 3.1066285705566408 3.293146790266037 3.1324126327037813 2.888827486038208 3.219002332687378 3.0399564504623413 2.9027196764945984 2.9123887610435486 3.0984252953529356 3.1253459525108336 2.9163239300251007 2.878496578335762 2.791906176805496 2.952734376192093 2.960324686765671 2.9427021396160127 3.1338639092445373 3.163562055826187 3.0560354232788085 2.9815440475940704 3.0454852068424225 3.0834017884731293 3.1211270201206207 2.9634611761569976 2.8960671496391295 2.948047112226486 3.0801184153556824 \n",
      "Mean_Reward:4.771411719288881 4.342556855429191 3.446430196792018 3.452418302896397 4.1097849097852865 4.1326682783672535 3.6580022483747308 2.9395159643230193 3.835714239817685 3.5942235701200707 3.6782325599854526 3.3464879619537 3.8420890791224345 3.2229940219714566 4.213312300107716 4.0421371350729585 2.7457043809117443 3.8984118472275755 3.951386062010319 3.2089734318500143 3.050681181648399 3.216258981107751 3.4742697512606657 3.9212395417171013 3.515419247642163 4.020064593351382 3.2342570510961726 4.855274091538158 4.083428088665339 4.229555252761779 3.2181344977930397 3.320535264770068 3.693970201558284 4.224987125729625 4.067276994693137 4.14240836273065 3.6819608199510627 2.689770010798016 4.607706325700883 4.332661372642479 3.525830824772961 3.344236842750638 4.31944013480005 4.258738697588459 4.547616120466399 4.737599950792526 2.878865635749348 3.139467338681398 4.273031138559817 4.929157512261258 4.037985854594988 4.2851870371403455 4.273939357776815 2.8914975581160065 4.093149422240603 3.7112692850345654 3.065650721363332 3.2195885708902874 3.337464282718837 4.66684902563438 4.1722634694527505 3.8445708352390593 3.093025976333446 2.933736736156714 3.6689184291523524 3.1650736720994326 3.4654103237055143 3.808011462351536 3.60473374185068 4.392830706757414 4.492850593778301 3.4216515573904553 3.8668073908889613 3.1218294178744572 4.05799830161303 3.259804880638366 3.8457642616132777 4.106979450074308 2.971615121806993 4.309969809234908 4.576625349084248 3.544920405727842 4.4360967109587275 3.678566451486785 3.939310841929363 4.306278324358889 4.26921610009497 4.338797139602987 3.803853266493892 3.8859453548568923 3.658257902960388 4.065088728783491 4.346189639814073 3.999397288243622 4.042489822988524 4.651238750600577 3.9514684747031272 4.267323814230959 3.245317476212906 3.558150849883081 \n",
      "Steps:10000\n",
      "Evaluate of cluster 2, Epoch 2\n",
      "Top 5. Hit_rate:0.9545813586097947 nDCG:0.8335024013049065 Precision:0.23854660347551343 Recall:0.93792300356905 F1:0.38035518351794023 Total steps:9010\n",
      "Top 10. Hit_rate:0.9680094786729858 nDCG:0.8373512749341754 Precision:0.12610584518167456 Recall:0.9573925219932641 F1:0.22285715490793154 Total steps:9010\n",
      "Top 20. Hit_rate:0.9849921011058452 nDCG:0.8413496589731602 Precision:0.06656793048973145 Recall:0.9793420143031955 F1:0.12466218363689806 Total steps:9010\n",
      "Cluster:3\n",
      "A_Loss:-1.7768617188930511 -3.7023391938209533 -5.084139199256897 -5.822054648399353 -6.064779653549194 -5.695435562133789 -5.595153040885926 -5.633620476722717 -5.787864499092102 -5.753647813796997 -6.045619664192199 -6.080520811080933 -6.177136940956116 -6.066649551391602 -6.124091358184814 -6.252599534988403 -6.143935885429382 -6.169856996536255 -6.19703845500946 -6.22004081249237 -6.290936532020569 -6.406348485946655 -6.366169390678405 -6.436724338531494 -6.382854719161987 -6.226926527023315 -6.37647554397583 -6.402228488922119 -6.3508664417266845 -6.219814615249634 -6.0458954286575315 -5.7466522359848025 -5.651795845031739 -5.506111264228821 -5.87778977394104 -5.99591579914093 -6.180099468231202 -6.18947919845581 -6.107237935066223 -6.041580452919006 -6.095973420143127 -6.055918464660644 -6.09367115020752 -6.206293206214905 -6.135258846282959 -5.9865072107315065 -5.9236683177947995 -5.850601367950439 -5.909807515144348 -5.853338394165039 -6.013222126960755 -6.117792601585388 -6.071098918914795 -6.240869960784912 -6.302497420310974 -6.457427244186402 -6.608659315109253 -6.6140210056304936 -6.73352349281311 -6.726834969520569 -6.776994819641113 -6.70358672618866 -6.62976900100708 -6.424929838180542 -6.49719964504242 -6.625955014228821 -6.672169184684753 -6.495433521270752 -6.350053558349609 -6.278974652290344 -6.1762530755996705 -6.110619206428527 -6.324557051658631 -6.484886937141418 -6.496721076965332 -6.423910608291626 -6.298423600196839 -6.040566492080688 -6.00420389175415 -5.972602162361145 -5.782931060791015 -5.563235349655152 -5.425878806114197 -5.428351731300354 -5.450763154029846 -5.407712717056274 -5.446553001403808 -5.589798135757446 -5.572957043647766 -5.39999520778656 -5.482343082427978 -5.485134897232055 -5.728723282814026 -5.545269570350647 -5.494743814468384 -5.348890781402588 -5.2393035364151 -5.378722748756409 -5.409193391799927 -5.2522575521469115 \n",
      "C_Loss:7.568639574050903 4.85536491394043 4.109790112972259 3.142265228033066 3.094213054180145 3.43834526181221 3.294064910411835 3.346744108200073 3.1894208824634553 3.4322091901302336 3.0087621200084684 3.385482474565506 3.0993258786201476 4.028529485464096 4.019552859067917 3.541892570257187 3.7295431339740754 4.103833087682724 3.725203024148941 3.9447256898880005 3.6582919585704805 3.716725174188614 3.2476615250110625 3.07487828373909 3.6049482655525207 3.31967636346817 3.00233873128891 3.1667151165008547 3.4786316859722137 3.106180937290192 2.9482413649559023 3.066871340274811 3.2043132531642913 3.2633777046203614 2.98989586353302 2.803842306137085 2.9047738242149355 2.9371750259399416 2.89260549724102 2.8348019301891325 2.80356663107872 3.1526893627643586 3.114982079267502 3.0798350262641905 3.1372662842273713 3.446616996526718 3.1385701084136963 3.197947248220444 3.1603089225292207 3.3785771894454957 2.9690227365493773 2.9703364431858064 2.943694771528244 3.0473511064052583 3.0814345479011536 3.0273313677310942 2.8804395365715028 2.7505796337127686 2.7764712166786194 2.7232442331314086 2.8026880741119387 2.7930799925327303 2.6576187205314636 2.778088518381119 2.724362065792084 2.8192773878574373 2.7541211140155792 2.6391744196414946 2.8559881269931795 2.7223484313488004 2.7004578745365144 2.7606579840183256 2.832391370534897 2.8198895394802093 2.948568511009216 2.79559272646904 2.725616055727005 3.0159705591201784 2.9474657547473906 2.6720791387557985 3.0359582030773162 2.831972311735153 2.8396860003471374 2.906609847545624 2.699962623119354 2.80959410071373 2.556715339422226 2.617280157804489 2.4351787757873535 2.549293692111969 2.399170678853989 2.453329943418503 2.400827325582504 2.1784213638305663 2.2704097843170166 2.3996692645549773 2.3201971745491026 2.456103880405426 2.599947214126587 2.51399547457695 \n",
      "Mean_Reward:1.4149175560177096 4.261295497427036 4.777247036918128 5.051530300567722 4.48120665525793 4.523999592253246 5.486007986267563 5.915028069949497 5.6706665416737225 5.611359796672055 5.7273869352475275 6.169079004092874 6.584622213105836 4.746694544692321 5.849219364200793 5.229307986347957 4.652758580844145 6.5724725872735155 5.4955375397321236 5.721271980563635 5.900897685737347 5.48473247617184 5.760129922613839 5.652042093147809 5.453070133289843 4.761171324615007 5.570563978146741 5.71752681347134 5.3768400622598245 4.57091891175571 4.889500979990598 4.198326566682069 4.346590212322516 5.242021282735139 5.297978725739971 5.766869856017031 6.307314034117359 5.970008260979341 4.895432194274942 5.275112167434346 5.992122386055688 5.250815869550301 5.9105985451383525 4.651178204029008 5.528332061478246 4.981499619782125 5.192258579284546 5.662423885562637 5.140283210419716 4.87448469545967 6.404712096000003 5.381076553196888 6.229585870677843 4.822049593429441 6.346865354078297 5.969813163728219 5.080351388768881 5.479754108072983 5.236292553889805 5.404234944495451 6.040367835324377 4.926832659435905 4.894328294311324 5.018603857768453 6.264446369833283 5.690530630073268 5.959974543140472 4.670968937807732 5.804499432018792 5.615713395822418 5.954945137358984 5.643982582231822 6.402025892754607 5.926706689053593 5.114016761089872 5.896135268861872 4.73091867172773 4.28351377526112 5.681675959946052 5.317594001107818 5.5241102426861035 5.440176868667705 4.789632152840356 5.360670562824313 5.989955736373061 5.7409926545613805 5.7444213105698285 5.412963416392808 4.8877929221507 4.91082509458761 5.603624898094688 5.937481290927196 5.711053501650593 5.003114146569735 5.050334451267824 5.465932110863057 6.494487455882454 5.606280605332903 5.2331884893933776 5.232337038044291 \n",
      "Steps:10000\n",
      "Evaluate of cluster 3, Epoch 0\n",
      "Top 5. Hit_rate:0.7682926829268293 nDCG:0.7445311456508334 Precision:0.16829268292682922 Recall:0.7591463414634146 F1:0.27550843435501143 Total steps:10010\n",
      "Top 10. Hit_rate:0.8048780487804879 nDCG:0.7563007284624058 Precision:0.08841463414634146 Recall:0.7967479674796747 F1:0.15916646351511288 Total steps:10010\n",
      "Top 20. Hit_rate:0.9024390243902439 nDCG:0.7775276090853912 Precision:0.05030487804878049 Recall:0.8973577235772359 F1:0.09526897682517228 Total steps:10010\n",
      "Cluster:3\n",
      "A_Loss:-5.242516527175903 -5.212199516296387 -5.2230024766922 -5.309720282554626 -5.397188487052918 -5.366433782577515 -5.470227112770081 -5.4708983421325685 -5.384497570991516 -5.446067934036255 -5.425079951286316 -5.557060780525208 -5.661104049682617 -5.802697405815125 -5.890597062110901 -5.859841594696045 -5.992834668159485 -5.757282948493957 -5.728205890655517 -5.943267984390259 -5.838467073440552 -5.74706193447113 -5.553046979904175 -5.287829794883728 -5.198261637687683 -5.184924788475037 -5.169402589797974 -5.177065634727478 -5.197476959228515 -5.352191643714905 -5.413425335884094 -5.368491234779358 -5.393685464859009 -5.346944193840027 -5.250300211906433 -5.294487714767456 -5.142549452781677 -5.134762535095215 -4.895941178798676 -4.787248976230622 -4.748584592342377 -4.873302085399628 -4.938766074180603 -4.948212628364563 -5.180120065212249 -5.1680395126342775 -5.229009399414062 -5.230639390945434 -5.497976355552673 -5.5537491178512575 -5.587695651054382 -5.530056972503662 -5.611136331558227 -5.644932417869568 -5.666799321174621 -5.557132005691528 -5.692354516983032 -5.659993834495545 -5.806385097503662 -5.748925228118896 -5.906662511825561 -5.9739010667800905 -6.09097273349762 -5.97891453742981 -5.995661444664002 -6.077900891304016 -6.016040720939636 -6.176591811180114 -6.17287784576416 -6.175754551887512 -6.058113307952881 -5.955569977760315 -5.947439999580383 -6.016732025146484 -6.023815236091614 -6.211645345687867 -6.276417942047119 -6.071943902969361 -5.953440017700196 -5.993194670677185 -6.131511268615722 -6.027879524230957 -6.123892588615417 -5.962020449638366 -5.966202359199524 -5.939327831268311 -5.857309226989746 -5.753055510520935 -5.718004951477051 -5.791726169586181 -6.05783145904541 -6.084122939109802 -6.042692499160767 -6.029754452705383 -6.017830739021301 -6.015805006027222 -5.840293130874634 -5.81263566493988 -5.900133786201477 -5.854827485084534 \n",
      "C_Loss:2.4864205324649813 2.509583070278168 2.5780672776699065 2.587917145490646 2.4980483901500703 2.489524393081665 2.40675696015358 2.578384053707123 2.80008553147316 2.945081213712692 3.0053974485397337 2.6605942034721375 2.782621227502823 2.7118958818912504 2.680814027786255 3.0902388274669645 2.965772672891617 2.8460547137260437 2.8417939412593842 2.9819583225250246 2.936854774951935 2.88589812874794 2.83563761472702 2.8299256312847136 2.8850313949584963 2.811136906147003 2.8153961586952208 2.6502862977981567 2.4872482943534853 2.3981098449230194 2.309814839363098 2.36072482585907 2.194429020881653 2.180863802433014 2.2693988275527954 2.210067654848099 2.28796750664711 2.4753291606903076 2.9071551156044007 2.7925287008285524 2.6111000561714173 2.677018220424652 2.7660504937171937 2.5353131425380706 2.706767624616623 2.7782100105285643 2.860888137817383 2.4833621156215666 2.5461739134788512 2.513247063159943 2.6976670801639555 2.5068592071533202 2.76252436876297 2.551412923336029 2.6161777663230894 2.5204311287403107 2.7571075570583345 2.671044100522995 2.5674651062488554 2.8185029816627503 2.642051872611046 2.7397504830360413 2.797970225811005 2.919357270002365 3.1780753564834594 3.2219721472263334 3.053143367767334 2.82094367146492 2.704903817176819 2.5268459975719453 2.6288935923576355 2.624368613958359 2.316543869972229 2.2420278859138487 2.1863771533966063 2.1033999812602997 2.2907927429676054 2.492764333486557 2.4348207688331605 2.4278703713417054 2.7730475640296937 2.6100073730945588 2.624667195081711 2.6653176832199095 2.5684596872329712 2.5401976537704467 2.427917537689209 2.2358667182922365 2.5957166528701783 2.5301152789592742 2.521520869731903 2.533476563692093 2.820856956243515 2.626781711578369 2.6172286963462827 2.717043855190277 2.7035379076004027 2.73551646232605 2.6997123193740844 2.6103429698944094 \n",
      "Mean_Reward:5.744230101021152 5.898249907931296 5.243795934669172 5.658735410060666 5.218692532570042 5.121245313585328 5.754498207255541 6.539544590818583 3.89908786169339 5.04938433602046 5.683700534029785 6.525136059706157 6.267846605332708 6.110546086933673 5.691694350253868 5.33498961651663 5.370862680726986 5.580999120237598 5.405430380082969 5.994876344915161 5.8142153488191965 5.125676416120916 4.688478950433339 6.178216909016575 4.816219410777174 5.813373983274909 6.432154929823559 5.106254770190692 6.406149075357473 5.976225730592528 5.261779442153096 5.204567345181456 5.641808315287843 5.097411460535171 5.540170292228066 4.830990217592852 5.111941538602062 4.209428532973103 5.216080327080131 5.633172614582735 5.317423094878669 5.9525476819370775 5.524460391419572 5.454019492217004 5.88517896139595 5.77820750858757 5.083858149068535 5.722079756072812 5.968852633938459 5.764316630436975 5.543693655452441 5.382881218372875 5.010600237937616 6.212410549633351 5.224083615441959 5.987932038724641 5.155432832239379 5.535594876785454 6.428756576773802 5.327436894308875 6.072487847832451 5.112809637510486 5.001516004896785 6.332802435207856 4.849836586724339 5.426953173819393 5.6312818227258346 6.6442778912731715 4.536296819116653 5.268620795807269 5.601576380639525 5.09034126580262 6.532650360584582 6.199610909606164 5.532796045902293 5.682248856268808 5.722441237192619 4.561591299808641 5.613617282906258 5.4997727498460565 6.258123808141132 5.107272791194726 6.674405306653062 5.457474180343704 5.005852417152959 5.635932850191867 5.99315785302393 4.208738243111793 6.228448417776113 6.258430092124086 6.4532376514533265 5.01721973768702 6.599334029365838 6.247009463079777 5.221840067091685 4.710026670577185 5.215293185913065 5.46404138297571 5.347522789344371 5.93066193723995 \n",
      "Steps:10000\n",
      "Evaluate of cluster 3, Epoch 1\n",
      "Top 5. Hit_rate:0.7804878048780488 nDCG:0.7504715697937585 Precision:0.17073170731707318 Recall:0.7713414634146342 F1:0.27957978058340127 Total steps:11010\n",
      "Top 10. Hit_rate:0.8201219512195121 nDCG:0.7634363865122531 Precision:0.08993902439024389 Recall:0.8119918699186991 F1:0.1619407342263969 Total steps:11010\n",
      "Top 20. Hit_rate:0.9115853658536586 nDCG:0.7833164795949582 Precision:0.05045731707317072 Recall:0.9044715447154472 F1:0.09558232356434576 Total steps:11010\n",
      "Cluster:3\n",
      "A_Loss:-5.8073132038116455 -5.715929007530212 -5.66617709159851 -5.621521048545837 -5.534013671875 -5.805041027069092 -5.937725563049316 -5.997674341201782 -6.023218169212341 -6.0692036485672 -6.056220049858093 -6.1122262573242185 -6.033279347419739 -5.9789770984649655 -6.016503210067749 -5.912633800506592 -5.874419341087341 -5.851612086296082 -5.783605499267578 -5.712528100013733 -5.823837003707886 -5.854837102890015 -5.869956860542297 -5.743216223716736 -5.681197943687439 -5.732500257492066 -5.754575324058533 -5.566033959388733 -5.575600972175598 -5.555256514549256 -5.521383833885193 -5.452518653869629 -5.477839097976685 -5.691801319122314 -5.792028360366821 -5.871980843544006 -5.8776920747756956 -5.612404046058654 -5.678045563697815 -5.699056286811828 -5.764188332557678 -5.94931378364563 -5.8611436414718625 -5.727275052070618 -5.713170776367187 -5.617149767875671 -5.610003700256348 -5.552233781814575 -5.378418126106262 -5.403176198005676 -5.324946508407593 -5.223753333091736 -5.306989469528198 -5.210564775466919 -5.144490032196045 -5.298588638305664 -5.317796230316162 -5.319064993858337 -5.321649503707886 -5.148904838562012 -5.198712835311889 -5.030810856819153 -4.913890538215637 -4.94582775592804 -4.903966360092163 -4.963313746452331 -4.957943930625915 -4.95601758480072 -4.921527528762818 -5.0419131994247435 -5.041010427474975 -5.003142218589783 -4.982190542221069 -4.983318135738373 -4.974077944755554 -4.989867920875549 -5.0294666719436645 -4.936871528625488 -4.760043897628784 -4.649839615821838 -4.7013920879364015 -4.725993583202362 -4.823490693569183 -4.7062375402450565 -4.459224827289582 -4.425236403942108 -4.576788341999054 -4.657356631755829 -4.7176039910316465 -4.761515078544616 -4.655501971244812 -4.606523666381836 -4.663120698928833 -4.835093648433685 -4.869405660629273 -4.852608437538147 -4.764424085617065 -4.775378077030182 -4.769029798507691 -4.838667342662811 \n",
      "C_Loss:2.559183542728424 2.409906327724457 2.3294590640068056 2.345256727933884 2.244819176197052 2.224162696003914 2.2346072989702224 2.2301580190658568 2.251776813864708 2.154389969706535 2.145654503107071 2.3047590589523317 2.3160897994041445 2.59719496846199 2.6160006749629976 2.6951249396800994 2.827141764163971 2.9639740908145904 2.767897400856018 2.8220001113414765 2.88864071726799 2.934133734703064 3.0031007421016693 2.842693818807602 2.638076773881912 2.6202292692661286 2.682453702688217 2.724924476146698 2.7656664597988128 2.8481048822402952 2.6813836777210236 2.649445827007294 2.6963827192783354 2.5067087960243226 2.544881291389465 2.56923588514328 2.7773334908485414 2.8602938330173493 2.8360897517204284 2.745479869842529 2.6960265707969664 2.6638370430469513 2.721582623720169 2.6721454668045044 2.8021435642242434 2.800920910835266 2.691183924674988 2.9130726611614226 2.7471358835697175 2.769392663836479 2.6927595484256743 2.626802772283554 2.631100993156433 2.621065751314163 2.7739118468761443 2.7608102238178254 2.73143634557724 2.526857841014862 2.6029812598228457 2.5059757149219513 2.7814103174209595 2.6501005303859713 2.6551080524921415 2.713450791835785 2.637232928276062 2.690886974334717 2.7982498168945313 2.752687728404999 2.7217694878578187 2.873101536035538 2.7558654987812043 2.6203180360794067 2.447766612768173 2.5369772124290466 2.5217093217372892 2.452402836084366 2.6806209295988084 2.6189451324939728 3.1003190267086027 2.725017638206482 2.659342404603958 2.8512741124629972 2.84971569776535 2.944795780181885 3.099486688375473 2.8256642198562623 2.7730593490600586 2.694626052379608 2.640276596546173 2.5058085107803345 2.46162033200264 2.2834484755992888 2.3292391574382783 2.4078129041194916 2.2308320879936216 2.2042601907253268 2.303226035833359 2.282594835162163 2.1879529118537904 2.2826447081565857 \n",
      "Mean_Reward:5.958935351570091 5.7386403888471955 5.333514369458272 5.077058223833907 6.3949081440027244 6.230946717042969 5.52019671573374 6.704480763948502 5.271081989248472 6.4443618003212455 5.216231446975784 5.533253864292683 5.002967447460712 6.195169519221239 4.77511588120424 5.518478808104856 5.841819663291363 5.911653916539496 5.289438458779611 5.737102884861667 6.525610336669336 5.599572320823964 4.7594598184022505 5.03392012289605 5.884372965065138 5.504614887234766 5.181353957347878 5.181283501396538 5.780107964868777 5.848533315971354 5.264419920609856 5.381419625316144 5.119053112918304 6.26809828983336 6.581723486581226 5.0628106725562825 4.996964019523738 5.9273381230680435 6.056703419288904 6.083430645420794 5.698544922576307 5.278270508509385 4.746794320678207 6.748763586036788 4.923981513009181 5.0960635908619425 5.243827814456551 5.403936210285408 5.739693291417065 5.360935837723705 5.848749107076801 5.250644249376146 5.087201203627277 5.378025685731992 5.799927658849865 5.862529220850786 6.104809605649246 5.432473791313137 5.622388173277318 4.940596271768391 5.6100978825942995 5.698860435465967 5.824806237657164 5.416704645157298 5.8178999081256215 5.966742997826148 5.629182540135076 6.06644483777234 4.8009836628847395 6.0868503626475 5.696397506738591 4.70667753892307 5.544637071877973 5.869225364356618 5.9123999096671165 5.675233465544418 5.348603994468158 5.330097980421218 5.034678061464139 4.767998392377827 5.478949671517505 5.59664145845843 5.798267417991825 4.501813616142464 4.327480779918284 6.10911616405147 6.160854298235372 6.128522047575172 5.335915961778661 4.778776941403535 5.0482098052305675 6.285471303694552 5.60389517063816 5.458572060758802 4.838066431029553 5.380729820549727 4.8420329071794095 6.267259062890372 5.928589244595704 5.82841825393561 \n",
      "Steps:10000\n",
      "Evaluate of cluster 3, Epoch 2\n",
      "Top 5. Hit_rate:0.7865853658536586 nDCG:0.7530970960635706 Precision:0.17195121951219514 Recall:0.7774390243902439 F1:0.2816153808008176 Total steps:12010\n",
      "Top 10. Hit_rate:0.8292682926829268 nDCG:0.7663368755012134 Precision:0.09105691056910568 Recall:0.8221544715447154 F1:0.16395495211344327 Total steps:12010\n",
      "Top 20. Hit_rate:0.9126016260162602 nDCG:0.7846534637651336 Precision:0.05050813008130082 Recall:0.9054878048780488 F1:0.0956791683390841 Total steps:12010\n",
      "Cluster:4\n",
      "A_Loss:-2.126801310777664 -3.5989260029792787 -4.26205670595169 -4.2977952694892885 -4.422426958084106 -5.075372424125671 -5.746140866279602 -6.225228519439697 -6.576103057861328 -7.0143792963027956 -7.31377875328064 -7.170789694786071 -6.915711789131165 -6.800711312294006 -6.772913641929627 -6.7648516321182255 -6.781580309867859 -6.990871062278748 -6.424998683929443 -6.7074449300765995 -6.662828741073608 -6.757612166404724 -6.826873846054077 -7.081270895004272 -7.171745176315308 -7.666102156639099 -7.100498418807984 -7.162895393371582 -7.346084208488464 -7.3690824747085575 -7.26745023727417 -7.3750450229644775 -7.438415350914002 -7.259204578399658 -7.420648965835571 -7.419251785278321 -7.468499937057495 -7.380843715667725 -7.38773323059082 -7.427990536689759 -7.437211685180664 -7.3897098493576046 -7.343168549537658 -7.303931636810303 -7.21878098487854 -7.48907968044281 -7.789549627304077 -7.668550868034362 -7.658423829078674 -7.638118906021118 -7.58220874786377 -7.462975468635559 -7.732254199981689 -7.703153686523438 -7.781952362060547 -7.834089307785034 -8.003384008407593 -7.966445064544677 -7.945483913421631 -7.8044704866409305 -7.746273241043091 -7.831796584129333 -7.719193358421325 -7.64374231338501 -7.6390189266204835 -7.588775691986084 -7.480266613960266 -7.421346793174743 -7.020947465896606 -7.0616848134994505 -6.866128673553467 -6.850279321670532 -6.935519194602966 -6.664084286689758 -6.585744247436524 -6.799014563560486 -6.6972503042221065 -6.782870850563049 -6.673801422119141 -6.650785813331604 -6.732365970611572 -6.65380717754364 -6.7388102197647095 -7.020080971717834 -7.348334398269653 -7.113694605827331 -7.038325386047363 -7.083867034912109 -7.015333003997803 -6.939907956123352 -7.093533349037171 -7.120106196403503 -7.066626181602478 -7.036277122497559 -6.981140975952148 -7.283297705650329 -7.318785810470581 -7.107176303863525 -7.007189602851867 -7.054214000701904 \n",
      "C_Loss:6.334231650829315 4.729579865932465 4.270685262680054 4.215038933753967 4.3534480929374695 3.9444360399246214 3.9230372643470766 3.997825506925583 4.208854765892029 3.8942920780181884 3.9826476335525514 4.276547486782074 4.252011158466339 4.294077999591828 4.257941942214966 4.123613438606262 4.329319643974304 4.458582409620285 4.290700649023056 4.617908086776733 4.412471617460251 4.433793517351151 4.632966437339783 5.003022117614746 5.367249135971069 5.510601918697358 5.479349279403687 5.020812957286835 5.132129058837891 4.8479286527633665 4.940050313472748 4.805875887870789 4.744301021099091 4.507264444828033 4.581069662570953 4.376628515720367 4.425455582141876 4.494498786926269 4.728571534156799 5.042708649635315 5.151940882205963 4.985651638507843 4.689682865142823 4.762326366901398 5.104766666889191 5.310704877376557 5.292558555603027 5.028767693042755 5.438935763835907 5.309731974601745 5.3049604606628415 5.3014695882797245 5.327425718307495 5.231766805648804 5.138491849899292 5.2927039062976835 5.179073920249939 5.557534382343293 5.036963665485382 5.245561118125916 4.824634518623352 4.823860082626343 5.107578330039978 5.029079802036286 5.117483434677124 5.15772531747818 4.917059762477875 5.172808463573456 5.071598711013794 5.142684717178344 5.158166284561157 5.136065022945404 5.2379026079177855 5.1527274703979495 4.939651234149933 5.179945635795593 4.748921525478363 4.945879650115967 4.741629128456116 4.935602912902832 5.040745193958283 5.145366265773773 5.128624725341797 5.0208191347122195 5.172391846179962 5.086246683597564 4.674700429439545 4.886852023601532 4.5382920932769775 4.672298023700714 4.370430135726929 4.918281395435333 4.714249336719513 4.3916333091259006 4.82521966457367 5.278547341823578 5.2229855704307555 5.173101153373718 5.375176377296448 5.3066128897666935 \n",
      "Mean_Reward:2.4115920788235408 3.126109732531654 3.840923687779341 2.766804223997896 4.8054681612453845 4.6566891215558615 4.471202661294426 4.682109924706163 4.827417173405344 5.083695315574993 5.285220554554482 4.874974749377002 4.532089063403576 4.394874122950246 5.016946751429429 5.353943279865112 6.851861749563093 4.667016907811922 5.1253272111823405 6.1160277287478015 5.425822633002427 6.001149675621884 5.375919885436637 5.5796378432355285 5.042105504613298 4.658381717721962 5.97316363178042 6.03112024521989 4.813148251727154 5.1382046531384855 4.7615346371277925 6.020801756355383 4.956352062960362 4.9434737702702884 6.1830578229444 6.289317993492562 5.212899698700884 5.92577180951423 5.408744396486493 5.114854575517609 5.708684669020326 4.736021642917447 5.4131064156966655 4.806280818941874 7.16512351389949 6.204763390655314 5.947922884056263 5.17511875106279 5.523833206884251 5.045509432558784 5.489415839692113 5.156813385206502 5.879300546244472 6.029147292109549 6.096850806916061 6.224999662926555 6.858408404345706 4.864313020575326 5.697955446274627 6.053682878651603 5.883694064890625 5.874664459072222 5.7554675210718225 6.703134054641628 5.5254140786824895 5.64637931011291 5.08461445063141 4.632932507251908 6.068225969912163 4.2699565129570765 4.119003180333981 6.644267863886926 3.9948321765417973 5.937422558699184 5.626008883682321 5.552975646695209 5.943794856867572 5.364941195814774 4.904822619206062 5.612317548202231 4.72114998725098 6.284162301849366 5.919881592999443 6.196199861628024 5.775028744077132 4.631463458187581 6.998013681351889 5.020157335035765 5.250562622638679 5.551664626086164 6.060703105135325 5.538182440131705 5.327873469218779 5.3404083807693254 6.78804558231096 6.089344702817908 5.873426249583938 4.552373931998009 5.00556888204378 6.301821450523488 \n",
      "Steps:10000\n",
      "Evaluate of cluster 4, Epoch 0\n",
      "Top 5. Hit_rate:0.935969868173258 nDCG:0.7303133761857183 Precision:0.23992467043314505 Recall:0.9037056316717332 F1:0.37918037998497156 Total steps:13010\n",
      "Top 10. Hit_rate:0.9510357815442562 nDCG:0.7344669760597827 Precision:0.1318267419962335 Recall:0.934500706958334 F1:0.2310586080907289 Total steps:13010\n",
      "Top 20. Hit_rate:0.975517890772128 nDCG:0.7392183424870269 Precision:0.07033898305084746 Recall:0.9678286695235847 F1:0.1311464841727398 Total steps:13010\n",
      "Cluster:4\n",
      "A_Loss:-7.003832573890686 -6.863767786026001 -6.8767733669281 -7.141897115707398 -6.934724617004394 -6.862017040252685 -6.80156268119812 -6.846100959777832 -6.947570290565491 -6.837276182174683 -6.582289824485779 -6.6428562450408934 -6.756488571166992 -6.591465163230896 -6.618426966667175 -6.664797382354736 -6.771755547523498 -6.765848450660705 -6.554531092643738 -6.3756000566482545 -6.312049708366394 -6.2006911277771 -6.000002455711365 -6.001911406517029 -6.176563940048218 -5.932906513214111 -5.991668529510498 -6.103951539993286 -6.123716850280761 -5.952943153381348 -6.029397120475769 -5.986923041343689 -5.937062253952027 -5.759573884010315 -5.789846658706665 -5.849649276733398 -5.821878781318665 -5.74256166934967 -5.8342280769348145 -5.944631991386413 -5.755595998764038 -5.86290066242218 -5.91016685962677 -5.857211761474609 -5.916111264228821 -5.921508274078369 -5.899680986404419 -5.883251533508301 -6.122038698196411 -6.024321823120117 -5.814054856300354 -5.923363499641418 -5.876188311576843 -6.164792551994323 -6.29912579536438 -6.234040794372558 -6.274491572380066 -6.100957398414612 -6.253566575050354 -6.244046168327332 -6.624186882972717 -6.430987339019776 -6.280777983665466 -6.404105925559998 -6.2793639421463014 -6.191698689460754 -6.355625286102295 -6.39278028011322 -6.444881572723388 -6.641126894950867 -6.504683051109314 -6.6784236001968384 -6.73061357498169 -6.9531178426742555 -7.118966460227966 -7.258734526634217 -7.070256443023681 -7.18294144153595 -7.306719741821289 -7.244756736755371 -7.088338150978088 -7.04654522895813 -7.031183519363403 -6.910139241218567 -6.774615602493286 -6.963284769058228 -7.041684255599976 -6.876979112625122 -6.691013827323913 -6.759366593360901 -6.960796208381653 -6.81484703540802 -6.941081008911133 -7.176445717811585 -7.207309141159057 -7.272748250961303 -7.136340937614441 -7.109974212646485 -7.275330920219421 -7.36462821483612 \n",
      "C_Loss:5.8493782424926755 5.059619960784912 4.815288546085358 4.822078659534454 4.7007184410095215 4.739364659786224 4.640443730354309 4.608819344043732 4.494275391101837 4.774569478034973 4.627223687171936 4.707646887302399 4.653481507301331 5.1079569435119625 4.834935272932053 4.635996551513672 4.967306864261627 5.269375658035278 4.789361555576324 4.839751076698303 5.067012162208557 5.027298730611801 4.946343448162079 4.78260678768158 4.772627220153809 5.304516005516052 5.284560112953186 5.338723981380463 5.547870771884918 5.062408611774445 5.204751210212708 5.126205615997314 4.959824261665344 4.984391241073609 5.14027176618576 5.008582322597504 5.14677995800972 5.5675103688240055 5.540129616260528 5.250554225444794 5.387543671131134 5.86034544467926 5.531917161941529 5.5997050499916075 5.588081204891205 5.136179568767548 5.054217638969422 5.103760566711426 5.2038633918762205 4.8980215287208555 5.146091737747192 5.04375248670578 5.074054296016693 5.3454776072502135 5.036883037090302 5.177660086154938 5.228588292598724 5.124570751190186 4.806270980834961 4.8462480711936955 4.863060541152954 4.769874453544617 4.609971939325333 5.099604268074035 4.513662075996399 4.678100671768188 4.566926903724671 4.518776738643647 4.967899922132492 4.7307102751731875 4.862888650894165 5.143273568153381 4.7915087890625 4.535703747272492 4.905993366241455 4.943681554794312 4.983760786056519 5.530939137935638 5.235422875881195 5.115514769554138 5.383363213539123 5.1589949774742125 5.36974226474762 5.3071934342384335 5.562245166301727 5.4394321084022526 5.184677579402924 5.037232441902161 4.746639313697815 5.081496136188507 4.8849255657196045 4.823354096412658 5.054228549003601 4.765322959423065 4.780996356010437 4.884862537384033 4.931615676879883 4.9405788135528566 5.345666842460632 5.04979335308075 \n",
      "Mean_Reward:5.873467215283647 5.787227156008063 5.703864904679418 6.015722213340483 5.196427960336703 5.614091130685867 5.540987112264048 5.837756630615714 5.706106864411976 5.473427202018128 5.961618743318343 5.769358626475997 5.821136585912224 5.33261201875721 6.714145530860424 5.393482140117822 5.7827692674572 5.623862866358835 5.146428657332709 5.766639899203594 4.805896258681454 5.687829833816709 5.149491902951208 6.023388895863207 5.98094093091189 4.9722143318225696 6.855370833777905 4.617725827324202 5.816711614716956 5.361949636114229 6.423202841949875 4.9553205955613375 4.885075007910701 3.899336567884571 5.475315078607204 5.97073929117097 4.868813296942707 6.17302815606871 5.8772772217550155 5.448602294020324 6.0476867030711965 5.565285908239783 5.711860747785742 4.856299979140466 5.034458182435956 6.747186680082049 5.080370387799772 6.953809147502591 4.832982467241402 4.346933580164885 5.59433857996361 6.619323128342509 5.24670687714465 5.458193311644482 6.388203896188547 4.749589220734051 5.318229990796823 5.654134377842059 5.940010867972433 5.293336759011627 4.0325031667536 4.536764919532762 4.991504883811184 4.640041464164474 4.760675790404755 4.757482632461762 5.576596335443151 5.674539894025498 4.7803559479778945 5.646728999361438 5.361615553175869 5.523853621938901 5.725934060340296 6.2385754937888915 6.1567985372335 4.227649992908087 5.696477757651105 7.238618734373578 5.526471809995986 4.9179848009489024 6.658541237197033 5.345535841474463 5.451736026278532 4.953750477097923 4.237742345750763 5.4031615005818825 4.582687463325952 5.025586863667672 4.255156898150396 6.75957821081468 6.28811836156128 4.9873003921693035 6.680139476785131 5.764367721073609 5.298615375719991 6.186892393462029 4.738828673002896 6.13676278292696 7.538614103789898 6.351667471129037 \n",
      "Steps:10000\n",
      "Evaluate of cluster 4, Epoch 1\n",
      "Top 5. Hit_rate:0.9378531073446328 nDCG:0.7345637110642488 Precision:0.2436911487758946 Recall:0.9103066838942545 F1:0.3844608421713601 Total steps:14010\n",
      "Top 10. Hit_rate:0.9519774011299436 nDCG:0.7385990206703836 Precision:0.13314500941619586 Recall:0.9388993751988102 F1:0.23321730207644079 Total steps:14010\n",
      "Top 20. Hit_rate:0.9736346516007532 nDCG:0.7434272830950351 Precision:0.07052730696798494 Recall:0.9673093245127143 F1:0.13146896892834645 Total steps:14010\n",
      "Cluster:4\n",
      "A_Loss:-7.531543321609497 -7.672515139579773 -7.545588212013245 -7.358536081314087 -7.338218388557434 -7.398601975440979 -7.5410997009277345 -7.514754686355591 -7.6788833045959475 -7.440476183891296 -7.508159909248352 -7.4812485885620115 -7.383455924987793 -7.435768547058106 -7.268793568611145 -7.267059588432312 -7.1973135280609135 -7.403176012039185 -7.43962299823761 -7.250873947143555 -7.346389489173889 -7.4123982286453245 -7.220243492126465 -7.307017040252686 -7.262788577079773 -7.287301378250122 -7.102449989318847 -6.95429801940918 -6.71518620967865 -6.655835404396057 -6.657069339752197 -6.438386492729187 -6.664811282157898 -6.880803570747376 -6.913434200286865 -7.055933427810669 -6.9853799486160275 -6.878440003395081 -6.861925067901612 -6.926622357368469 -6.9054998016357425 -6.774663887023926 -6.882979917526245 -6.976435670852661 -6.988998789787292 -7.054182600975037 -6.9806500339508055 -6.838690695762634 -6.540682029724121 -6.581413102149964 -6.7374069881439205 -6.737595281600952 -6.741899619102478 -6.732236976623535 -6.640680255889893 -6.739730300903321 -6.784337997436523 -6.753015460968018 -6.869341921806336 -6.978023052215576 -6.966708378791809 -7.093713798522949 -7.0881826066970826 -7.027311291694641 -7.086398363113403 -7.414142689704895 -7.374821171760559 -7.333583798408508 -7.384782629013062 -7.26330349445343 -7.0674717998504635 -7.113086891174317 -6.986728663444519 -6.894212017059326 -6.933830065727234 -6.836461811065674 -6.996973247528076 -7.070826802253723 -6.987357015609741 -7.106010375022888 -6.981607046127319 -6.865076389312744 -6.9172335052490235 -6.940290875434876 -6.945303163528442 -7.070941324234009 -7.2551841545104985 -7.083317794799805 -7.014479241371155 -6.789441676139831 -6.942479233741761 -6.782867131233215 -6.5661071681976315 -6.433786249160766 -6.425650157928467 -6.307587532997132 -6.126797866821289 -6.095838232040405 -5.970131278038025 -6.0256794786453245 \n",
      "C_Loss:5.0880297183990475 5.192465280294418 5.113231580257416 5.1316194295883175 4.833910226821899 4.938001730442047 5.101365134716034 5.31595694065094 5.100017731189728 5.214924206733704 5.002472100257873 4.739115092754364 4.914639701843262 4.852269389629364 5.134392750263214 5.098854682445526 5.207031180858612 4.875068885087967 5.059637198448181 5.397992053031921 4.713866940736771 5.322671980857849 5.186317999362945 5.312740840911865 5.7746130871772765 5.1726722240448 5.0896208429336545 4.9308731341362 4.865786345005035 4.500592360496521 4.936326286792755 4.805469444990158 5.111064925193786 4.947422137260437 4.899968509674072 4.955732214450836 4.62668518781662 4.6374669051170345 4.864627773761749 4.746329026222229 4.739307694435119 5.081154801845551 4.637363409996032 5.311170027256012 5.163998789787293 4.987225036621094 5.013451297283172 4.9110798835754395 4.829769704341889 4.9596462202072145 4.718514289855957 4.823028874397278 4.5279897177219395 4.675234187841415 4.2612984442710875 4.390514883995056 4.801022311449051 4.703387461900711 4.881718611717224 5.332862384319306 5.111260735988617 5.004918787479401 5.282672166824341 5.526544156074524 5.3889755153656 5.77667206287384 5.315122084617615 5.398991131782532 5.306241211891174 5.683081662654876 5.501419854164124 5.4119658851623536 5.4634022665023805 4.986597352027893 4.797251403331757 4.716524186134339 4.876106724739075 4.811031782627106 4.948754858970642 4.701328966617584 4.818269205093384 4.61480316400528 4.532487833499909 4.832002866268158 4.815347030162811 4.434406158924102 4.40878609418869 4.573092257976532 4.161757028102874 4.414837865829468 4.198330938816071 4.202941129207611 4.33242579460144 4.399102087020874 4.373649606704712 4.5882184910774235 4.733267142772674 4.381954233646393 4.545439631938934 4.422323641777038 \n",
      "Mean_Reward:7.31841554177802 5.367478049967092 5.312174749664675 6.661793405084077 5.887358387503135 5.9922971088367 5.432475831790786 6.47159044591648 5.864566173122101 6.401132492889457 6.233593567696899 4.914985888054112 5.891908952715863 6.215162249843356 4.895591127249574 6.598944224881734 6.360807404604678 6.685946058826318 5.33006031425079 5.032386463526351 7.195889551933026 5.084600257063292 6.305766124533322 5.275769505970661 5.699862325833508 6.056000946287918 5.2748817830321055 7.088131959445811 3.972561343279591 5.564297411893355 4.310340184843949 5.254208290167599 6.283985185846696 6.492726324064455 5.0775404938927435 6.398474950920854 5.245697211639191 5.089412348932014 6.53343310878966 6.059733567922615 5.269089987764302 5.074645011033526 6.671312070474752 5.593023083861868 5.901571087627246 5.525643809788408 5.1956431857021235 4.843632107139989 5.394835927405337 6.5829078928458316 5.707754277727069 5.8132014341789935 6.137916756190848 6.281867140273581 5.171404493809343 5.172018940441797 7.275222003340176 5.087860016839627 6.5177772071076925 5.730078448178419 6.766979181039331 6.407275936641021 5.851504478843799 6.837067212839105 5.763138833737148 7.117235180174566 4.456007772111476 6.8229801911589485 3.8516108795728705 5.725165518377165 6.646208465352584 5.1771119867751585 6.084708387880978 4.899167004642892 5.952415381814028 4.664219247005474 6.588248713468413 5.767269930706488 5.656035951511582 6.139341130907726 4.71505491933188 5.010756329663044 5.676098105788906 5.945497406318194 5.369032023473246 6.338312314032563 6.2656441689978 4.580065631417045 3.657805160104546 6.336986056974716 5.657711098954635 3.3927018889276463 4.471194049223921 6.1395214532253615 5.5099138696120145 4.836603168062717 5.032747326835572 5.100777030015121 5.18357056846232 5.900793808699326 \n",
      "Steps:10000\n",
      "Evaluate of cluster 4, Epoch 2\n",
      "Top 5. Hit_rate:0.9365976145637163 nDCG:0.733945875566977 Precision:0.2446955430006278 Recall:0.9108148368976994 F1:0.38575532005114693 Total steps:15010\n",
      "Top 10. Hit_rate:0.9529190207156308 nDCG:0.7388015748873309 Precision:0.13364720652856246 Recall:0.9408817988384842 F1:0.2340487905600716 Total steps:15010\n",
      "Top 20. Hit_rate:0.9736346516007532 nDCG:0.7435828970890426 Precision:0.07062146892655369 Recall:0.9677360829903203 F1:0.131636501838099 Total steps:15010\n",
      "Cluster:5\n",
      "A_Loss:-3.5875133587419987 -5.1523302245140075 -7.586884388923645 -9.31109094619751 -10.136152868270875 -10.235180597305298 -10.305732736587524 -10.379911794662476 -10.371579551696778 -10.414512910842895 -10.612715740203857 -10.65932906150818 -10.648703632354737 -10.709557390213012 -10.85602466583252 -10.742960958480834 -10.5885040473938 -10.537429113388061 -10.38935188293457 -10.387357845306397 -10.484875345230103 -10.31453085899353 -10.366674327850342 -10.42263219833374 -10.417319326400756 -10.303306169509888 -10.10195894241333 -9.78272644996643 -10.077476892471314 -10.129332418441772 -10.189306592941284 -10.234444341659547 -10.480319662094116 -10.475671834945679 -10.674568252563477 -10.637525253295898 -10.490554637908936 -10.695912551879882 -10.789636430740357 -10.836980257034302 -10.859893369674683 -10.791989831924438 -10.724315910339355 -10.694077081680298 -10.58481743812561 -10.361957921981812 -10.280393114089966 -10.21618618965149 -10.122796640396118 -10.226689949035645 -10.174951524734498 -10.348964033126832 -10.43186650276184 -10.385359306335449 -10.368102254867553 -10.370384559631347 -10.367463502883911 -10.505683317184449 -10.571277027130128 -10.465009670257569 -10.688573350906372 -10.646025094985962 -10.64352770805359 -10.682517433166504 -10.677424030303955 -10.64543511390686 -10.504361753463746 -10.524145660400391 -10.565830383300781 -10.511365146636964 -10.43863805770874 -10.542350635528564 -10.44188455581665 -10.499094381332398 -10.44853819847107 -10.471556816101074 -10.450900039672852 -10.427976131439209 -10.431073093414307 -10.436215963363647 -10.500316982269288 -10.353078155517577 -10.327036619186401 -10.397107915878296 -10.433027725219727 -10.55859787940979 -10.678049154281616 -10.802953281402587 -10.9890651512146 -10.960934104919433 -11.00293433189392 -10.98360894203186 -10.791171703338623 -10.700962238311767 -10.79747423171997 -10.65710578918457 -10.753121032714844 -10.759363164901734 -10.707742652893067 -10.332897119522094 -10.423325328826904 \n",
      "C_Loss:17.56975962162018 11.167494025230408 7.869790935516358 6.512460203170776 5.969568407535553 5.82611912727356 5.470534029006958 5.23697231054306 5.073516256809235 4.568136858940124 4.2334568667411805 4.253360877037048 4.0859962952136994 3.6440436315536497 3.5525522267818452 3.302323188781738 3.2226696467399596 2.807490153312683 2.782591474056244 2.743007665872574 2.6268455600738525 3.022689861059189 2.9888791942596438 3.2023077070713044 3.3156426668167116 3.3558518755435944 3.214026770591736 3.622077000141144 3.5059278917312624 3.2571886205673217 3.2305525279045106 3.136619371175766 3.012674754858017 2.826251912117004 2.702313177585602 2.919281461238861 2.954496986865997 2.7497649919986724 2.7127214574813845 2.7325540053844453 2.648655788898468 2.7671049082279207 2.502996944189072 2.8750670456886294 3.111917734146118 3.071578552722931 3.1069313251972197 3.0767240965366365 3.131072872877121 3.001908177137375 3.2019607722759247 3.086501064300537 3.2030721426010134 2.9251249945163726 2.9238610959053037 2.8466043508052827 2.812680057287216 2.641068686246872 2.747304731607437 2.685694830417633 2.7646838176250457 2.970230677127838 2.8419309198856353 2.6721987891197205 2.663519009947777 2.7690138638019564 2.758580719232559 2.7770769321918487 2.9770240342617034 3.019176722764969 3.0451116931438444 2.81326367020607 2.9395731115341186 2.956311639547348 2.957058790922165 2.8890946769714354 2.7052946746349336 2.9109456050395965 2.68611416220665 2.623071962594986 2.598025012016296 2.774152240753174 2.654366351366043 2.8433993268013 2.9931410324573515 2.6982330679893494 2.81562882065773 2.8919430422782897 2.856275885105133 2.625941607952118 2.676618620157242 2.798530098199844 3.146877188682556 2.986715106964111 2.956461614370346 2.822504745721817 2.8225136303901674 2.7612314677238463 2.7891589510440826 3.150173112154007 2.9161316394805907 \n",
      "Mean_Reward:3.5823860717623517 5.1300156624052065 7.673481517447694 7.877545830292445 8.8709980748206 8.732635216665107 8.578278753751537 7.710171015392972 8.771621709577186 9.646353361956518 8.96135538826159 8.611377853652014 9.026837206724885 9.108935156306028 8.871011391040264 9.538778213402576 9.702039438532484 8.557013806931852 9.038610037958664 9.561542877830721 9.55780301824152 7.094083867875464 9.66637328212364 9.742088872731966 7.764479059152442 9.428039874166846 7.742849418584391 7.309702342841312 8.411303591030691 9.093667454769262 8.28703106815266 8.721842074256891 10.209509552739101 9.581898367246971 8.497243602800333 9.148620946618042 8.640965419020624 9.295988934432708 9.456130655548142 9.034070765282852 9.512448728709906 8.756876721933978 8.61762387938336 9.781769554899848 7.835241831618481 8.492901203230426 9.145079626634086 7.509592101157218 9.275867717279915 8.555619881396975 9.819035788735565 9.328080418852782 8.386252893070225 7.921390095071488 9.282412950787288 8.964286506144852 9.495721373318357 9.439428556481737 8.809967071243523 8.549558907768148 9.762615615849299 8.814714189613374 9.745983133935027 9.581699526128064 8.137594875343176 9.032889683249357 8.501123435945818 8.992373277451103 9.929264502678981 8.51368036548511 9.51089646957634 8.722793753534214 9.368080437260005 8.548306697215583 7.956307868503115 8.871918680354657 8.065016252041476 8.165812993165103 9.300196291622148 9.083106103573538 9.529422941894403 8.042718054762148 9.21721282983698 9.402216014735158 9.684173785171643 9.332760201583095 8.658939872353011 9.709940326460059 9.80624138966644 9.25547236984117 9.231860959511101 8.22048659458829 8.416515844160994 9.477716390027506 9.10249766550661 8.975188690560781 9.442986630520773 9.452463520827811 7.151195275600474 8.029999363694355 8.775692393084931 \n",
      "Steps:10100\n",
      "Evaluate of cluster 5, Epoch 0\n",
      "Top 5. Hit_rate:0.9197860962566845 nDCG:0.897661613908891 Precision:0.188235294117647 Recall:0.9197860962566845 F1:0.31251391282031316 Total steps:16020\n",
      "Top 10. Hit_rate:0.9358288770053476 nDCG:0.9027992443378303 Precision:0.09572192513368984 Recall:0.9358288770053476 F1:0.1736788041412912 Total steps:16020\n",
      "Top 20. Hit_rate:0.9518716577540107 nDCG:0.906723523561173 Precision:0.048663101604278065 Recall:0.9518716577540107 F1:0.09259244712098012 Total steps:16020\n",
      "Cluster:5\n",
      "A_Loss:-10.536890449523925 -10.701416034698486 -10.718597898483276 -10.672173433303833 -10.659070405960083 -10.557693738937378 -10.452241563796997 -10.580711107254029 -10.657837953567505 -10.723529825210571 -10.708124141693116 -10.757028541564942 -10.734271993637085 -10.766004467010498 -10.784433631896972 -10.751846370697022 -10.524138803482055 -10.50924934387207 -10.415525598526001 -10.682491083145141 -10.646294136047363 -10.614531164169312 -10.497068243026733 -10.453600788116455 -10.47388689994812 -10.574439744949341 -10.654661693572997 -10.739978151321411 -10.573493242263794 -10.39964575767517 -10.307321929931641 -10.298167810440063 -10.460941972732543 -10.444498167037963 -10.345727157592773 -10.315014877319335 -10.381152610778809 -10.356564712524413 -10.475593223571778 -10.586819286346435 -10.668237257003785 -10.365732192993164 -10.359386072158813 -10.498659114837647 -10.38670877456665 -10.368739948272705 -10.203331260681152 -10.29736837387085 -10.202378540039062 -10.36447045326233 -10.3707164478302 -10.319989423751831 -10.291233406066894 -10.272723474502563 -10.272278957366943 -10.298885536193847 -10.349077615737915 -10.57209433555603 -10.588020181655883 -10.652570219039918 -10.771286163330078 -10.862379865646362 -10.950031852722168 -11.082292337417602 -11.121279506683349 -11.187106456756592 -11.13250678062439 -11.118114919662476 -11.061677656173707 -10.825744018554687 -10.76616057395935 -10.854024047851562 -10.611774072647094 -10.644100360870361 -10.634767894744874 -10.680854396820068 -10.660946998596192 -10.664486865997315 -10.650978546142579 -10.697662839889526 -10.76065526008606 -10.760132389068604 -10.856673173904419 -10.915765981674195 -10.927185621261597 -10.748759937286376 -10.771438484191895 -10.6769957447052 -10.533164691925048 -10.609495191574096 -10.760509672164916 -10.901604328155518 -10.894324426651002 -10.75067668914795 -10.677988481521606 -10.720381956100464 -10.796808652877807 -10.688331079483032 -10.841076736450196 -10.689755039215088 \n",
      "C_Loss:2.7682992017269132 2.859408450126648 2.691689968109131 2.753987548351288 2.555711681842804 2.574797024726868 2.8126478111743927 2.7864806509017943 2.6371515202522278 2.7554889059066774 2.663390783071518 2.813035900592804 2.6718153488636016 2.649765520095825 2.7470521235466006 2.6191987574100493 2.8308351075649263 2.748131811618805 2.8362974846363067 2.940932266712189 2.795283944606781 2.696507432460785 2.7426941335201263 2.6682385206222534 2.6786183094978333 2.5506341242790223 2.254121676683426 2.4076207876205444 2.3336885023117064 2.4135846590995786 2.670908439159393 2.5831575191020963 2.5967816710472107 2.8013781583309174 2.76421559214592 2.7843788850307463 2.693055189847946 2.7381517243385316 2.8570830929279327 2.8507181453704833 2.4006620168685915 2.5310293006896973 2.45210412979126 2.5662018620967864 2.5457211780548095 2.618603720664978 2.7226006269454954 2.6156627810001374 2.593663170337677 2.686198978424072 2.8523574817180632 2.8702338457107546 2.8948783254623414 2.8660454714298247 2.727941895723343 2.7987234377861023 2.759817498922348 2.6345904326438903 2.6150678825378417 2.6040385901927947 2.6704149401187895 2.825283187627792 2.6560009813308714 2.59352210521698 2.342604992389679 2.3345750772953036 2.424476696848869 2.547908240556717 2.4645898580551147 2.593053628206253 2.595410004854202 2.52492524266243 2.7134281051158906 2.722312253713608 2.859067430496216 2.7420888257026674 2.510475344657898 2.542987631559372 2.728245849609375 2.7167706632614137 2.727523361444473 2.672905913591385 2.7028056395053865 2.6224709939956665 2.6073069834709166 2.7789650082588198 2.8369633865356447 2.852615543603897 2.832895350456238 2.9802302753925325 2.679200133085251 2.5936913752555846 2.4931643557548524 2.6551570880413053 2.7486511301994323 2.7350827395915984 2.6937790524959566 2.7634658968448638 2.643668657541275 2.539257401227951 \n",
      "Mean_Reward:9.624889238303531 9.104426228504433 8.736921252963452 7.671109162010558 8.902273141073474 8.460556741467617 9.482341431071585 7.502331901752562 9.262787616154089 8.496482973444568 9.533147622319397 9.918789915000083 8.82667732847015 8.44671775055168 8.958712949241233 8.48559733456159 6.888223211036778 8.556323260069798 9.522065162976697 9.281633284623176 9.490869024570797 8.61730749018453 9.531089901268945 9.182601323393252 9.45235895568679 9.560300225519175 8.91207110499772 8.54796066296253 8.615164398574988 7.850117391848823 8.55582349034695 9.314613814207929 9.476092105545824 9.303745696488747 9.48403225668569 9.399193725690804 8.76569478349799 9.874277498898751 9.505368281847813 9.206975313501973 8.91575687571048 6.769125921654312 10.372210310514514 8.549445106054359 9.235937780383358 8.257938583459307 9.650374634574598 9.905617763453709 8.483026200802419 9.625869733177899 9.096848447766545 8.027606399066332 9.862211579332643 9.433051351522478 9.032164064887956 9.14071131799319 9.885761523806579 9.548392911952263 10.041494340681217 9.831559266335825 9.551788624204942 8.404558333179118 9.844271174101081 9.701208878120505 9.156102354493378 9.601869904325481 9.30956991245654 9.533959713007494 8.87201433306532 8.311974663553382 9.404337395054553 8.654519331174896 8.567043144966078 9.10990422189711 9.734345383433755 8.975685673517999 9.391726318021046 9.612382924006493 9.325170285728905 9.045599241143593 8.432760005262459 9.596780670864614 9.353185561884377 9.235950792680757 9.004590382023409 7.913497332024072 9.82511147240705 8.310874119813878 9.5659140407782 10.297834488118491 9.646409553129672 9.32379801084333 9.034421438919415 8.493541149671568 9.880142085707675 8.479403407853573 9.189752596272136 9.27634371159302 9.724969725795093 8.80068661884633 \n",
      "Steps:10000\n",
      "Evaluate of cluster 5, Epoch 1\n",
      "Top 5. Hit_rate:0.9224598930481284 nDCG:0.8917882478186095 Precision:0.1887700534759358 Recall:0.9224598930481284 F1:0.3134052446699572 Total steps:17020\n",
      "Top 10. Hit_rate:0.9331550802139037 nDCG:0.8952005520084423 Precision:0.09545454545454546 Recall:0.9331550802139037 F1:0.17319263829796208 Total steps:17020\n",
      "Top 20. Hit_rate:0.9545454545454546 nDCG:0.9005723436397831 Precision:0.04879679144385026 Recall:0.9545454545454546 F1:0.09284710024275443 Total steps:17020\n",
      "Cluster:5\n",
      "A_Loss:-10.621834125518799 -10.630834140777587 -10.666431226730346 -10.553852682113648 -10.56259651184082 -10.553113460540771 -10.559943742752075 -10.413969841003418 -10.417810907363892 -10.226596384048461 -10.17583664894104 -10.2060746383667 -10.097056732177734 -10.162086534500123 -10.148858222961426 -10.141209526062012 -10.192260313034058 -10.221566200256348 -10.324172153472901 -10.156854133605957 -10.345678882598877 -10.254078502655029 -10.323401536941528 -10.324041814804078 -10.297092199325562 -10.21536626815796 -10.338650894165038 -10.288587493896484 -10.286709260940551 -10.32043200492859 -10.311846323013306 -10.430119333267212 -10.529047613143922 -10.428161821365357 -10.522306365966797 -10.686383237838745 -10.573021669387817 -10.619351053237915 -10.458795566558837 -10.615017175674438 -10.588468570709228 -10.502089157104493 -10.542783327102661 -10.439320125579833 -10.412648611068725 -10.367832832336425 -10.614721546173095 -10.66980523109436 -10.623605127334594 -10.40041648864746 -10.402363862991333 -10.370289545059205 -10.226396055221558 -10.230204982757568 -10.084636077880859 -10.122771377563476 -10.157692251205445 -10.18010905265808 -10.064469137191772 -10.23925479888916 -10.233375415802001 -10.20394775390625 -10.068865175247192 -10.146338195800782 -10.109670524597169 -10.176346311569214 -10.13326202392578 -10.232697849273682 -10.242424488067627 -10.270335426330567 -10.230309677124023 -10.355623302459717 -10.263755149841309 -10.228981580734253 -10.144831981658935 -10.028906545639039 -9.997247190475465 -9.994321117401123 -9.988085060119628 -9.957966852188111 -10.014335355758668 -10.045861701965332 -10.206314191818237 -10.208157062530518 -10.3421759223938 -10.454026985168458 -10.620957717895507 -10.66009352684021 -10.6848858833313 -10.65091742515564 -10.478423824310303 -10.462849044799805 -10.499093742370606 -10.525120553970337 -10.514296398162841 -10.339972743988037 -10.294851789474487 -10.185579452514649 -10.136169996261597 -10.163683557510376 \n",
      "C_Loss:2.5508297884464266 2.6639583122730257 2.6962014186382293 2.7267362761497496 2.5419723653793334 2.6006330156326296 2.6568911278247835 2.7977348244190217 2.610879646539688 2.8000473165512085 2.7238094079494477 2.7133530282974245 2.9739358401298523 2.7035910093784334 2.881750166416168 2.7393056350946425 2.7380879271030425 2.656507760286331 2.861280314922333 2.9690747833251954 2.732411766052246 2.7864759051799775 2.849894834756851 2.786795893907547 3.0276241517066955 2.8592883360385897 2.8849927484989166 2.8411154282093047 2.833587874174118 3.0278165340423584 2.878734188079834 2.8588084709644317 2.820854229927063 2.951344403028488 3.0401203441619873 2.843612846136093 2.951209075450897 2.9606664633750914 3.0683640909194945 2.8586855161190035 3.052357717752457 2.8650738751888274 2.953367403745651 2.9999273657798766 2.790124682188034 2.62940673828125 2.5738278472423555 2.700018173456192 2.604803569316864 2.5213569712638857 2.5452380681037905 2.4312729370594024 2.377968884706497 2.397511115074158 2.488390254974365 2.2734399676322936 2.475445249080658 2.341824554204941 2.5811208206415177 2.5970762538909913 2.564052218198776 2.5111556482315063 2.6089751005172728 2.3384062957763674 2.462458918094635 2.5137355196475983 2.4407183003425597 2.5513951492309572 2.674292025566101 2.4711321604251864 2.4529928839206696 2.302102802991867 2.617835319042206 2.513041487932205 2.6957634437084197 2.5592314422130586 2.861023546457291 2.9536855375766753 2.841912840604782 2.8774160993099214 2.7192050623893738 2.86602179646492 2.64000363945961 2.6457334458827972 2.329128452539444 2.4108758330345155 2.3486256194114685 2.368154373168945 2.2435931479930877 2.170796630382538 2.372788043022156 2.5843182122707367 2.486153244972229 2.551231838464737 2.618722695112228 2.847023376226425 2.852620884180069 2.7277591896057127 2.736735061407089 2.9306483244895936 \n",
      "Mean_Reward:9.00886723795747 9.062007601262145 8.117513713273611 9.159277397107013 8.129078899606785 8.944713811671017 8.664867565687466 9.422627845043264 8.589956770670838 8.797907774091128 8.272290415955906 8.569052918273563 7.197307481819536 9.68814054139598 8.757720620431865 8.48654728806234 8.519379691820886 10.435370956087361 8.72629613724457 8.409130973215248 8.995895385344351 7.692652315269738 9.35590269412648 8.929041019072338 8.894200154088105 8.581047372882345 9.504000450458141 8.78268574096144 9.285818286370233 8.799937157893842 9.49545287523633 8.856000999262516 8.98742676635115 9.095122709869718 9.36408669696228 8.857580875886502 8.884725943653244 8.428314631355587 9.659408269725878 9.077266255144124 8.83828459737338 9.39317545938667 8.633505311843923 8.784974928607117 9.066940816825813 9.129044412381836 9.37331455713546 9.3089097230912 8.702702249237923 8.164735619415117 7.712990723222614 9.826466241615556 9.300732001750502 9.213338208606869 8.025502612076854 9.069972587767822 9.136873204132415 9.269740473644566 8.111509292689615 9.266245863326889 9.054748164444087 7.8451200507243195 8.966369302193446 8.979846076702314 8.618659836728115 8.698318069966103 9.828364945105703 8.586851732961014 9.937915895587555 8.923014603788621 8.84677298299163 8.519774998559178 8.465940847398905 8.461347124558626 8.609038202085447 8.398302570587912 8.60197878623584 8.855509203916489 10.215856785427924 9.499437065285905 9.462315838389506 8.936365527307002 9.213696421815976 9.87311023987142 9.74356202819287 10.21442898719508 9.238475680371094 9.12013059896048 9.335949667769103 9.512790055364263 8.379429756723068 9.039218066606331 9.640036858267194 8.970829509294736 9.76720556718216 7.609973755790628 8.570132442735796 9.0660729401554 9.236254893572355 9.096877478876019 \n",
      "Steps:10000\n",
      "Evaluate of cluster 5, Epoch 2\n",
      "Top 5. Hit_rate:0.9233511586452763 nDCG:0.8889391935247013 Precision:0.1889483065953654 Recall:0.9233511586452763 F1:0.3137023552015662 Total steps:18020\n",
      "Top 10. Hit_rate:0.9322638146167558 nDCG:0.8917763889681648 Precision:0.09536541889483066 Recall:0.9322638146167558 F1:0.1730305829901749 Total steps:18020\n",
      "Top 20. Hit_rate:0.9554367201426025 nDCG:0.8975850740183767 Precision:0.04884135472370765 Recall:0.9554367201426025 F1:0.09293198460946261 Total steps:18020\n",
      "Cluster:6\n",
      "A_Loss:-0.6535436002723872 -0.17065738972276448 0.8004757973179221 1.0575865072011947 0.9347045293450356 0.5311765689402819 -0.16259718772023915 -0.7850220818817616 -1.3284228470921517 -1.5841652762889862 -1.7305836963653565 -1.728027190864086 -1.9677361047267914 -2.235753507614136 -2.444474985599518 -2.8969633626937865 -3.281805775165558 -3.4826934337615967 -3.4239952254295347 -3.502307724952698 -3.645469672679901 -3.7612319207191467 -3.6238840317726133 -3.8132340788841246 -3.7684631729125977 -3.9930487990379335 -3.942914786338806 -3.8454026770591736 -3.924777960777283 -3.8343706369400024 -3.852210795879364 -3.763935852050781 -3.9271563935279845 -4.102133967876434 -3.968544661998749 -4.046452271938324 -4.290296339988709 -4.268422315120697 -4.538097665309906 -4.629014294147492 -4.525406537055969 -4.46540944814682 -4.421385154724121 -4.4167650389671325 -4.566587638854981 -4.179257280826569 -4.139737274646759 -4.1146674060821535 -4.071803781986237 -4.269130539894104 -4.521042876243591 -4.58448034286499 -4.677187685966492 -4.708510777950287 -4.600866229534149 -4.665686657428742 -4.517318320274353 -4.555755689144134 -4.621156210899353 -4.511522467136383 -4.265006113052368 -4.235161573886871 -4.141100280284881 -4.066469449996948 -4.240266666412354 -4.485524697303772 -4.592433996200562 -4.55783313035965 -4.725430345535278 -4.7171763634681705 -4.909907338619232 -4.805749678611756 -4.871992971897125 -4.778898825645447 -4.730653035640716 -4.714252028465271 -4.840177483558655 -4.6180646300315855 -4.512650616168976 -4.85646831035614 -5.2056042361259465 -4.9053937292099 -4.736870212554932 -4.81232337474823 -4.773532569408417 -4.613335487842559 -4.595536017417908 -4.671048920154572 -4.6454468655586245 -4.582896912097931 -4.463290469646454 -4.413111956119537 -4.234260663986206 -4.137336759567261 -4.186847372055054 -4.1533436632156375 -4.176212441921234 -4.145702435970306 -4.033906970024109 -3.840947353839874 \n",
      "C_Loss:7.246535801887513 5.667247941493988 5.091073580980301 5.182125456333161 4.89427047252655 4.716690529584884 4.608448235988617 4.651760551929474 4.696861127614975 4.759670631885529 5.097663242816925 5.016162626743316 4.765197585821152 4.751705265045166 4.463924834728241 4.1072936582565305 4.320576703548431 4.042849732637405 3.964944052696228 3.793498718738556 3.9117148160934447 3.87422532081604 5.881510696411133 5.2394735670089725 5.1377114641666415 5.600890786647796 5.685601963996887 5.5228872394561765 5.069350957870483 5.352866413593293 5.609899094104767 5.117501009702682 3.9802856492996215 4.274360609054566 5.949352869987488 4.945492050647736 5.985310959815979 5.068406422138214 5.1416750288009645 5.138209972381592 4.895694088935852 5.006919500827789 4.886295835971833 4.779388440847397 4.234590973854065 5.530688328742981 5.486294989585876 5.625300223827362 5.536888511180877 4.903963565826416 5.00883704662323 4.945552020072937 4.498262292146682 4.71258912563324 4.129094517230987 3.644634976387024 3.566084508895874 3.5888767552375795 3.6550551795959474 3.7859390282630923 5.6412505269050595 5.785032162666321 6.2450555062294 5.80472359418869 5.123766760826111 4.8930009794235225 4.93546353340149 5.279161131381988 4.925940506458282 4.83681538105011 4.011878908872604 4.075506217479706 3.813448052406311 4.014538073539734 4.082632901668549 4.206116280555725 4.222422044277192 5.487605776786804 5.019042508602142 5.001045079231262 5.4065568208694454 5.192399110794067 4.81066294670105 4.760640845298767 4.718194050788879 4.505808935165406 4.29750084400177 3.6367609679698942 3.5875722110271453 3.426218193769455 3.448844645023346 3.411072553396225 3.7899569451808928 3.591284408569336 3.5995121097564695 3.842206575870514 3.6428924441337585 3.4897239875793455 3.4046205139160155 3.423562352657318 \n",
      "Mean_Reward:2.08011446952611 3.1811295008145004 4.3475244779040745 4.6579513242051815 5.262882551858621 5.698771032261715 6.884877510342692 6.218008433553707 6.599618875312225 6.915657659089209 5.372117699058755 6.6868671925689975 7.641561247465672 7.862105563062702 7.589214812176547 7.389568742044307 7.462417251118526 7.77272139035622 7.027630107598034 8.122481748324617 8.303147698463922 7.147324553347687 8.969712258622623 8.035938130116666 7.879254551303189 8.790795729184389 7.666815704375384 7.120306131776638 7.540714610889208 8.690185350210418 7.26873426096399 7.844532469886885 8.685642816630757 6.849218490524513 9.424103928655004 8.176033164556276 7.150717583941681 8.43960621450772 9.125835148942722 7.261162848431127 7.059413635572818 6.9324139776514855 8.513774790853807 9.106349825578725 6.856271528874737 6.9800263676206615 7.196868409632538 8.07063050000064 7.631517151322678 9.152811206944412 8.563678155245416 7.889235486444893 8.126534739163596 8.57976425471785 7.262007665669025 7.866027227466364 7.763587624511163 8.111133837465184 7.673585761467989 6.016479180617306 8.399260349108093 7.164616431732878 6.487228391006641 8.544207164306721 8.119376561450446 6.968702208842679 8.414093442823818 8.20557273802654 7.957463120300279 8.15601047461277 7.74864359931811 7.738781866218869 6.788164474591523 8.249706650336762 7.910667099412307 8.131786724758365 7.781948900197591 6.71986775611 8.630533107533216 8.819427167656263 8.05793612314451 7.121372269200769 8.136793665097565 8.251754872519323 8.002369426756545 7.190818454370329 9.007275456559343 8.043752552554515 8.408261040073178 7.1187682257744305 7.7053668872059715 6.196247914927487 6.998766657952468 7.484404454452942 8.61075227944703 6.966570845391785 7.6055620335592256 6.749239006296034 7.938647315064912 6.184886130456927 \n",
      "Steps:10000\n",
      "Evaluate of cluster 6, Epoch 0\n",
      "Top 5. Hit_rate:0.9813519813519813 nDCG:0.9059457332826912 Precision:0.23589743589743595 Recall:0.9739552114552115 F1:0.3798038507615641 Total steps:19020\n",
      "Top 10. Hit_rate:0.9953379953379954 nDCG:0.909792734464313 Precision:0.12284382284382285 Recall:0.9931526806526807 F1:0.21864327039571718 Total steps:19020\n",
      "Top 20. Hit_rate:1.0 nDCG:0.9109269800177157 Precision:0.06270396270396272 Recall:0.9992715617715617 F1:0.11800314846206131 Total steps:19020\n",
      "Cluster:6\n",
      "A_Loss:-3.843992838859558 -3.5975296974182127 -3.623506863117218 -3.5861865139007567 -3.5619524216651914 -3.5883230209350585 -3.5560095262527467 -3.5560812520980836 -3.513270616531372 -3.599757091999054 -3.656093385219574 -3.94857718706131 -4.10110967874527 -4.067928664684295 -4.058305056095123 -4.003748183250427 -4.043751997947693 -4.12183812379837 -4.250047514438629 -4.242636046409607 -4.203038668632507 -4.064823942184448 -4.191559166908264 -4.1384083676338195 -4.2108144640922545 -4.33856787443161 -4.36984708070755 -4.214175357818603 -4.3606755781173705 -4.472861051559448 -4.555615575313568 -4.452103652954102 -4.3241847395896915 -4.391687421798706 -4.4575452852249144 -4.341109364032746 -4.486070754528046 -4.46016031742096 -4.596501545906067 -4.624395463466644 -4.615229940414428 -4.855675313472748 -4.911370966434479 -4.9168603897094725 -5.002533905506134 -4.97331202507019 -4.950841026306152 -4.956450710296631 -4.802457184791565 -4.836451563835144 -4.8767895722389225 -4.839427280426025 -4.721002769470215 -4.605648765563965 -4.825792381763458 -4.69627893447876 -4.743688447475433 -4.703627727031708 -4.714575800895691 -4.583500905036926 -4.628852438926697 -4.730139245986939 -4.7654897141456605 -4.779104654788971 -4.700028386116028 -4.588423979282379 -4.485643849372864 -4.311773891448975 -4.228565282821656 -4.299708812236786 -4.361744031906128 -4.213532466888427 -4.289695856571197 -4.13619081735611 -4.231646521091461 -4.3521688723564145 -4.468305127620697 -4.5219733119010925 -4.697326738834381 -4.805163397789001 -4.667084124088287 -4.537985012531281 -4.62760302066803 -4.457127130031585 -4.259545800685882 -4.253884956836701 -4.345065541267395 -4.25920972108841 -4.321711814403534 -4.282335388660431 -4.10814260005951 -4.206167004108429 -4.4325186109542845 -4.379062128067017 -4.417129817008973 -4.599639594554901 -4.525393662452697 -4.624691905975342 -4.6037994432449345 -4.6363320684432985 \n",
      "C_Loss:3.820718047618866 3.7813274657726286 3.9496906709671022 4.154809669256211 4.055497527122498 3.727319025993347 3.756991353034973 3.8416241800785063 3.4205193650722503 3.547033258676529 3.431646543741226 3.4961109733581544 3.4797722733020784 3.3979080867767335 3.341039470434189 3.2799882090091703 3.3364985632896422 3.2902049219608305 3.2285952723026274 3.09158740401268 3.710313014984131 3.683404153585434 3.3157533633708955 3.4324596202373505 3.57932071685791 3.570357937812805 3.4576747584342957 3.622088416814804 4.032710696458817 3.8709038388729096 3.6058345997333525 4.117579792737961 3.8347770631313325 3.825837435722351 3.698200043439865 3.916205109357834 3.891293351650238 3.9106684565544128 3.5351921010017393 3.750949726104736 3.6050332617759704 3.640990695953369 3.5195749163627625 3.611190346479416 3.7674610805511475 3.709504129886627 3.5401882123947144 3.6535646653175355 3.5813230228424073 3.7748527348041536 3.4192964887619017 3.5337776100635527 3.488430597782135 3.5449477899074555 3.6394747042655946 3.5222742915153504 3.8495459043979645 3.9919239711761474 3.9149415028095245 4.247168505191803 4.218122124671936 3.986489403247833 4.043135318756104 4.070713297128678 4.236125984191895 4.256302039623261 4.038178482055664 4.758954877853394 5.424132997989655 5.18239890575409 4.919180889129638 4.513671493530273 4.6081923222541805 4.386426360607147 4.291249988079071 4.262714929580689 4.250649011135101 3.812985649108887 3.709691299200058 3.911953296661377 3.8446000242233276 3.998045928478241 3.929852991104126 4.016824878454209 4.115900747776031 4.095391206741333 3.951297868490219 4.43329836010933 4.897994327545166 5.038643935918808 5.20970448255539 4.926921635866165 4.571406271457672 4.55355281829834 4.433484735488892 4.687727229595184 4.351572871208191 3.9781007027626036 3.712882809638977 3.814728479385376 \n",
      "Mean_Reward:5.918512556064888 6.208692888473089 8.361512604064357 6.963518912087261 7.424752804582799 6.81819099674582 8.167815138781686 6.465389565520074 7.146639552032517 7.126044662343592 7.647092136751785 7.3911698344325645 8.419766688203822 7.60036128637304 7.005698353391981 7.302157546768272 7.653211366493152 7.660999385479345 8.080239828471225 7.326013336925794 6.632233266291159 8.056823513064822 7.636512160341798 8.208449948754076 7.732122780762953 7.747314626638531 6.166401586653893 8.105973937687494 7.5588696929147785 9.102516505757842 7.22273401497092 7.707195771828431 6.524712919029579 8.098325378506104 7.276199767198691 8.44252780406123 7.61745900675891 7.362252140113391 7.6377622353930565 8.919124581878833 8.302492410521328 8.140566755261803 7.851512800648958 8.26775173332265 8.202963832648207 7.337487418706355 7.896178899870116 7.566315739373093 7.3931037495871905 7.2028335638055365 7.944990454276776 8.074416323679847 6.432276605557633 8.358320920871229 8.305388449830748 8.514785143022772 8.346376893745783 7.656668546285646 8.444997418685595 7.80258277557571 8.892878889356323 7.873430811824225 8.438141212023268 6.842287382308051 7.848733281457971 8.108345509484664 6.149201426261316 6.661615517616477 7.752371520681222 7.908253875899052 8.66293108176646 6.72413525570553 7.46820756607715 8.302462905673838 8.535991812943793 8.128783774031517 7.62376764011203 7.8411800419331605 7.943555618305246 8.973691544190723 7.385984704190865 6.409889698634621 8.06369673973807 6.774720764268684 7.707119824730361 7.194675347168213 8.007861910051975 6.314159998424075 7.382292071921396 7.747382531706604 6.966149546158479 7.812143200374803 8.8476703531911 8.185069290113878 7.715758498223534 7.327230709353142 8.710571428811267 7.2917047955670276 7.393142161537051 8.92473632259742 \n",
      "Steps:10000\n",
      "Evaluate of cluster 6, Epoch 1\n",
      "Top 5. Hit_rate:0.9825174825174825 nDCG:0.9073075597798822 Precision:0.23636363636363641 Recall:0.9757034632034632 F1:0.3805410251416274 Total steps:20020\n",
      "Top 10. Hit_rate:0.9941724941724942 nDCG:0.9107541469691744 Precision:0.12261072261072262 Recall:0.9919143356643356 F1:0.21824403756331762 Total steps:20020\n",
      "Top 20. Hit_rate:1.0 nDCG:0.9122044652730965 Precision:0.06276223776223777 Recall:0.9993444055944056 F1:0.11810684459826873 Total steps:20020\n",
      "Cluster:6\n",
      "A_Loss:-4.811493136882782 -4.807114608287812 -4.83781126499176 -4.740519597530365 -4.759698677062988 -4.816752171516418 -4.472121908664703 -4.659030916690827 -4.64803995847702 -4.515735495090484 -4.5382843017578125 -4.45260461807251 -4.504329824447632 -4.61974131822586 -4.523571863174438 -4.5157154226303104 -4.517430553436279 -4.446645131111145 -4.2802420067787175 -4.294362380504608 -4.3674031925201415 -4.512868046760559 -4.43039274930954 -4.530851411819458 -4.471158576011658 -4.6064010119438175 -4.649040021896362 -4.7384384250640865 -4.629517822265625 -4.763534495830536 -4.363795206546784 -4.415967533588409 -4.3789310240745545 -4.218059995174408 -4.189059641361236 -4.195218677520752 -4.147401716709137 -4.21869256734848 -4.112722713947296 -4.023067605495453 -4.122554941177368 -4.235463588237763 -4.0797596406936645 -4.124460563659668 -3.986681270599365 -3.977960619926453 -4.020682060718537 -3.821949439048767 -3.864910864830017 -3.908569929599762 -4.028467152118683 -4.004101371765136 -4.021396639347077 -4.0276585292816165 -4.0043947839736935 -3.9222204518318176 -3.870231025218964 -3.9282467770576477 -3.865946412086487 -3.9798445296287537 -4.0606855249404905 -4.2101332950592045 -4.2837016797065735 -4.31687885761261 -4.354893383979797 -4.3013212728500365 -4.123438403606415 -4.048605675697327 -4.164428019523621 -4.016018214225769 -4.105641212463379 -4.0255860590934756 -4.082604322433472 -4.036522030830383 -4.1419739699363705 -4.3010813117027284 -4.375664134025573 -4.418678622245789 -4.424459795951844 -4.5925216436386105 -4.596405956745148 -4.5832080864906315 -4.62791166305542 -4.637328333854676 -4.688840072154999 -4.755427362918854 -4.831877610683441 -4.892033050060272 -4.734497714042663 -4.818982419967651 -4.829390144348144 -4.6997357892990115 -4.745531556606292 -4.664075672626495 -4.680768556594849 -4.795943355560302 -4.933429646492004 -5.01779116153717 -5.145919027328492 -5.3619024229049685 \n",
      "C_Loss:3.4710758662223817 3.43523580789566 3.678171319961548 3.6007737851142885 3.6952757668495178 3.7067022776603697 3.6076919627189636 3.7306222128868103 3.6805028748512267 3.5632446026802063 3.5505045008659364 3.794710977077484 3.7806094312667846 3.618748049736023 3.881759897470474 3.8593257737159727 4.119838104248047 4.063028353452682 3.9249163353443146 3.837253305912018 4.034912164211273 3.8553429675102233 3.8203940761089323 3.5505202555656434 3.5457391583919526 3.6131114292144777 3.487773233652115 3.4798402690887453 3.7796956276893616 4.345747849941254 4.487882066965103 4.126188669204712 4.4192062091827395 4.243408052921295 3.9014030933380126 4.011115560531616 3.785463638305664 3.864187852144241 3.8730337381362916 4.072596702575684 3.629263005256653 3.413810826539993 3.674709343910217 3.378326964378357 3.5738726937770844 3.7848621439933776 3.525956161022186 3.3963112354278566 3.4113594365119932 3.3550722074508665 3.2398148131370545 3.6781660151481628 3.7966610729694366 4.080740058422089 3.885740873813629 4.09883608341217 3.9890526151657104 4.168238263130188 4.281026396751404 4.2457960510253905 4.055728070735931 4.049927079677582 3.892174824476242 3.9393379282951355 4.059931374788285 4.212561750411988 4.654232091903687 4.314898639917374 4.444475409984588 4.071251512765884 4.028001554012299 4.030593192577362 3.6792220425605775 3.6811272835731508 3.667325268983841 3.589403872489929 3.313901094198227 3.4622838056087493 3.366723053455353 3.454026012420654 3.4715336573123934 3.5486869394779204 3.6511200296878816 3.6130800294876098 3.5833608281612395 3.567644370794296 3.3803580307960512 3.5567285192012785 3.567547073364258 3.5424727356433867 3.6775272524356843 3.730265516042709 3.3519387292861937 3.3156552839279176 3.603573169708252 3.396608701944351 3.412297475337982 3.562650158405304 3.509059329032898 3.7518565344810484 \n",
      "Mean_Reward:7.517489755078433 7.525493251046214 6.379417596266536 7.91090502349054 8.730099054652053 5.945059001879177 7.671224309911113 8.535726209354253 7.560317261301304 7.287388698235632 8.052371501897035 7.145951409388102 8.354720227794706 7.429483193189487 8.570956315901164 6.91942065961611 7.695917625445728 7.940870886570044 7.378853068463675 7.617014940851407 8.922760747056332 7.134091758079154 7.6250745018011425 7.995234262191263 7.631181670905189 8.04702462141227 8.468246750876778 7.818414706202927 8.33495976020135 6.054054683485735 7.167056546906894 6.746829138431452 7.091246339377648 7.553653349815424 6.970500213306941 8.284696039462238 9.305478075454468 7.934635563203183 8.007576045220311 7.567444507327582 7.643316397094423 7.423668927801331 8.60881942735026 7.338027007429255 7.702431824932803 7.785557202386446 7.252702371755124 7.705952371735798 7.782934090767685 8.06485995559325 8.213258379353729 7.1844177731587875 7.805944418997967 7.925252330908711 7.140280413425745 7.405465255271086 7.680593054584666 7.22369077620553 7.364548405408207 8.430613319914723 9.050394454511354 7.896751027546965 7.662580268216651 7.732595286991027 7.08240147963195 6.682737834598 8.480515758418843 6.776357852865048 7.618506186355009 7.0726321390915015 8.739699937498257 7.439186742330055 7.770888165090266 7.6264455291900095 7.725786968036647 8.550220713811722 7.601723290014161 7.549753851929376 7.948141034122836 7.90307477259123 8.169465631675996 8.029564604745314 7.8810636830191525 8.417341270425492 7.29896339492577 8.71529877109607 8.197791485330573 8.058061078383945 7.282656659070491 8.431749915549993 7.321498604263777 7.364719806695997 8.096258687196624 7.23148467233934 7.04538381779683 9.24926069161027 8.840425200618716 8.752495080833668 8.162432530944871 8.090605523897263 \n",
      "Steps:10000\n",
      "Evaluate of cluster 6, Epoch 2\n",
      "Top 5. Hit_rate:0.9821289821289821 nDCG:0.910667920351834 Precision:0.23636363636363636 Recall:0.9752761127761128 F1:0.3805085106918372 Total steps:21020\n",
      "Top 10. Hit_rate:0.9937839937839937 nDCG:0.9139270856871794 Precision:0.12253302253302252 Recall:0.9914391164391164 F1:0.21810944509280955 Total steps:21020\n",
      "Top 20. Hit_rate:1.0 nDCG:0.9154643127537321 Precision:0.06274281274281274 Recall:0.9993201243201243 F1:0.11807228028801123 Total steps:21020\n",
      "Cluster:7\n",
      "A_Loss:0.4080528402980417 -0.27329103033989666 -0.545459384098649 -1.0589776265621185 -1.0616598522663117 -0.8924292942881584 -0.9452501848340035 -0.8696268808841705 -0.9327599859237671 -1.0642284566164018 -1.0967009764909745 -1.232081647068262 -1.316266375184059 -1.4898378717899323 -1.8524536609649658 -1.7972040581703186 -1.8860809469223023 -2.0112345826625826 -2.2629013228416444 -2.2740648412704467 -2.5714426386356353 -2.4530073475837706 -2.2708314907550813 -2.1185911178588865 -2.244800490140915 -2.2628961038589477 -2.084774614572525 -1.9715040910243988 -2.0854905688762666 -2.0817249178886414 -2.14663170337677 -1.8692160367965698 -2.0286254131793977 -2.1240097999572756 -2.272423747777939 -2.437736692428589 -2.374498006105423 -2.286175869703293 -2.0600142788887026 -2.080562962293625 -2.0285110580921173 -2.14771439909935 -2.2918723583221436 -2.4397720742225646 -2.47232012629509 -2.412322738170624 -2.334497479200363 -2.3605677843093873 -2.4732281255722044 -2.5460715663433073 -2.470224860906601 -2.4116491997241973 -2.3300116562843325 -2.303764669895172 -2.2569306862354277 -2.127777689695358 -2.103417218923569 -1.9020038664340972 -1.9414998483657837 -1.8562839210033417 -1.8176238524913788 -1.812812711596489 -1.9479898881912232 -2.0191214084625244 -2.0451583206653594 -1.9356828010082245 -2.0285721909999848 -2.0448837208747865 -2.3536830055713653 -2.335650775432587 -2.3848684418201445 -2.347533745765686 -2.4884540069103243 -2.4156305718421938 -2.431116738319397 -2.3916452968120576 -2.487689473628998 -2.445349313020706 -2.3823170506954194 -2.379705015420914 -2.3249735391139983 -2.335047402381897 -2.344435399770737 -2.3551159715652465 -2.3517557120323183 -2.3682634222507475 -2.4041537189483644 -2.3722405076026916 -2.3594448661804197 -2.4443892788887025 -2.5040401101112364 -2.5582157123088836 -2.5148240995407103 -2.4581871962547304 -2.4888059759140013 -2.4302982783317564 -2.3323213493824007 -2.4007769799232483 -2.314691948890686 -2.487062052488327 -2.503428318500519 \n",
      "C_Loss:2.974731707572937 1.5197499483823775 1.2390938046574593 1.0570216056704522 1.0237443268299102 1.068640292286873 1.28773760586977 1.2666964635252953 1.2945773705840111 1.47108521848917 1.5349225348234177 1.681401990056038 1.7544708067178727 1.8704095596075059 1.9052161490917205 1.8600603240728377 1.923964067697525 1.83766257584095 1.7295903658866882 1.7970438128709794 1.8045898497104644 1.7204781067371369 1.5222615802288055 1.4778410997986793 1.4243116176128388 1.3667154270410538 1.3220176672935486 1.2781052923202514 1.3768240547180175 1.2159811091423034 1.2761220091581345 1.283369702398777 1.3332478988170624 1.2467999991774559 1.1891772562265397 1.2042323631048202 1.2338043963909149 1.194316958785057 1.1759588783979416 1.1241362994909287 1.1152438825368882 1.217906664609909 1.1794627833366393 1.2152646636962892 1.3235237413644791 1.7281832498311998 2.186870082616806 2.03765123963356 2.16304158449173 2.3585232466459276 2.1083019018173217 2.1039005225896834 2.0652634072303773 1.823165739774704 1.7125652438402177 1.5529748570919037 1.562044865489006 1.1957093381881714 1.193408984541893 1.0698987159132958 0.9406372970342636 0.954702610373497 0.9145947444438934 0.9377503886818885 1.0818041774630547 1.2164824092388153 1.0996242541074752 1.0982087737321853 1.191717586517334 1.5794546490907668 1.70657535135746 1.4339149379730225 1.4834585511684417 1.3563863199949264 1.4675891226530076 1.4115068596601485 1.4385291081666947 1.4535800617933274 1.4014192867279052 1.6921770817041397 1.660396922826767 1.704451748728752 1.6784017556905746 1.7274125155806541 1.6572020322084426 1.5443972271680833 1.5613292723894119 1.3254690247774124 1.3447424209117889 1.224315402507782 1.2637483310699462 1.2501281851530075 1.2736512690782547 1.0982822930812837 1.1971713384985925 1.24785296022892 1.1987333124876023 1.3208868411183357 1.1836468949913979 1.3247648766636848 1.3912859958410264 \n",
      "Mean_Reward:-0.19026855055719546 0.27601283775657776 0.6835439795597671 0.8044194138471744 0.8769337259927944 0.8483186055698125 0.8276177275580607 1.3758198457993174 1.1707489613221786 1.2605044906761416 1.9320665162357857 1.4046434504946377 1.938905069709115 2.221370384496536 1.2919178562030402 1.981660415544468 2.408118785326013 2.0429394662478293 1.4083474959324533 1.7430614379429528 1.5371174174777837 0.5318934083884668 1.0104103233234227 0.9873118395403091 1.6446788132716192 0.8464655734556225 1.277546675792194 2.072870724035094 1.8098207133450535 2.2471672165058276 1.766367778611415 0.34950999202222205 1.4883929217398568 1.1776712426819826 1.6495220119481004 2.180177657974132 2.242219932035289 1.069928132487526 0.8492803033763144 1.6392662681219299 1.0637446839081133 2.1706510906181262 2.422521419715398 2.021550184149795 1.8567626804516417 1.277590697063637 2.8023647228755535 2.7588730105626764 2.1901577889070207 1.8646629139620385 2.3176114872810096 0.6864644822725733 1.0639306086185758 1.052841600815335 1.2998214505199284 1.26692986284177 1.0062283731915738 0.827443006847745 1.6473465290095743 0.770931011943561 2.095957628715106 1.0616217829742527 1.5692925270140556 1.47449982482476 0.640460442259088 1.2008968761087637 2.3085016153793334 2.1714537304336643 2.7067901515673953 0.5017747948137563 1.1156913064052556 1.3152483954801375 1.64861110918358 0.8025066883133536 1.0976527277800967 2.2123064269693704 1.322052353062662 2.126897382394835 1.4545725023430556 1.2172255795418487 2.114392779865858 1.5877528680495514 2.353959643463495 1.0807514618650935 1.3518446307162169 1.632253393469376 1.669082187122016 1.435261159684919 1.2374656252435963 0.5776883872822356 2.5639109191142673 1.2593956738741787 0.9442347934032433 1.473794262549974 1.7362854006567445 0.6425452346045872 1.3638809250318966 2.14260121619295 1.6531257255073348 2.181354678812619 1.7147450598845513 \n",
      "Steps:10100\n",
      "Evaluate of cluster 7, Epoch 0\n",
      "Top 5. Hit_rate:0.8888888888888888 nDCG:0.6248930240572483 Precision:0.20208333333333334 Recall:0.8617863906926407 F1:0.3273944146022375 Total steps:22030\n",
      "Top 10. Hit_rate:0.9583333333333334 nDCG:0.6482975549936798 Precision:0.11840277777777779 Recall:0.9507284526815778 F1:0.210579919869223 Total steps:22030\n",
      "Top 20. Hit_rate:0.96875 nDCG:0.65093206216056 Precision:0.06215277777777777 Recall:0.9644660894660895 F1:0.11677982950732983 Total steps:22030\n",
      "Cluster:7\n",
      "A_Loss:-2.4894311594963074 -2.4857033562660216 -2.45426575422287 -2.5056047999858855 -2.5476608097553255 -2.5275134193897246 -2.5023850417137146 -2.385471931695938 -2.3042463600635528 -2.244434154033661 -2.2111905646324157 -2.2612143313884734 -2.184778871536255 -2.178221229314804 -2.2036894476413726 -2.2045766842365264 -2.2541931688785555 -2.174622061252594 -2.2519254076480864 -2.257571371793747 -2.4098959767818453 -2.46251482129097 -2.537831301689148 -2.492621831893921 -2.5678794384002686 -2.559608325958252 -2.64178412437439 -2.5839240181446077 -2.53176402926445 -2.6701525330543516 -2.518529167175293 -2.5266343998908996 -2.495593845844269 -2.5366178929805754 -2.4256300699710844 -2.3567658507823945 -2.2842084264755247 -2.138162679672241 -2.1374547839164735 -1.9941142868995667 -2.072732825279236 -2.1066093933582306 -2.269515172243118 -2.3545594775676726 -2.3405937039852143 -2.283202338218689 -2.3953446745872498 -2.395978798866272 -2.576385817527771 -2.6854423081874845 -2.763013161420822 -2.6862323307991027 -2.6746403801441194 -2.661591891050339 -2.6181563568115234 -2.635867394208908 -2.666692454814911 -2.628072693347931 -2.702197878360748 -2.6669909250736237 -2.693953959941864 -2.65506982088089 -2.640399023294449 -2.6138556146621705 -2.568654478788376 -2.462493499517441 -2.714963675737381 -2.648888021707535 -2.5731787812709808 -2.5886025512218476 -2.483802901506424 -2.4938015055656435 -2.7286025059223173 -2.582230404615402 -2.7108656048774717 -2.802985360622406 -2.7080581891536712 -2.7843671822547913 -2.730660401582718 -2.585841335058212 -2.67326966047287 -2.5299141716957094 -2.3743146085739135 -2.5262772595882415 -2.500727497339249 -2.647093985080719 -2.6715541243553163 -2.626708998680115 -2.716969304084778 -2.765432806015015 -2.8697024357318877 -2.956618535518646 -3.0213894629478455 -2.888254599571228 -2.9791475355625154 -2.9148178052902223 -2.917711935043335 -3.0201876521110536 -2.869758715629578 -2.9636422777175904 \n",
      "C_Loss:1.3954807144403458 1.3368946975469589 1.319740007519722 1.2393424117565155 1.2234707736968995 1.228050315976143 1.245575048327446 1.1499865028262137 1.0663039070367812 1.0115228432416916 1.0661985132098197 1.2818417966365814 1.1690007013082504 1.050399522781372 1.336190140247345 1.2399905502796174 1.3433001166582108 1.3311092478036881 1.445775271654129 1.3628231960535049 1.5576533603668212 1.4080839890241623 1.5177418243885041 1.5637805616855622 1.7229421758651733 1.6912255364656448 1.5707983767986298 1.6850669693946838 1.7249599820375443 1.56322649538517 1.4307455611228943 1.4313362509012222 1.4921537035703658 1.428826894760132 1.4932539856433868 1.414638940691948 1.4610428899526595 1.4072436451911927 1.421182463169098 1.4191222846508027 1.4224390596151353 1.5345453387498855 1.6024809896945953 1.8056390464305878 1.619312511086464 1.62482262134552 1.5047771900892257 1.4778155153989792 1.4339698773622513 1.4979545766115188 1.6163938802480697 1.673129130601883 1.5903562289476394 1.6362536346912384 1.4360898923873902 1.3548057526350021 1.3523414433002472 1.3522942388057708 1.4460372120141982 1.4534467577934265 1.3529429191350937 1.5018636652827262 1.459251698255539 1.511847848892212 1.4735409396886825 1.3357135140895844 1.4338269299268722 1.4116213393211365 1.3532123804092406 1.3081802135705949 1.6559926980733872 1.6634919768571854 1.6408936071395874 1.6523559564352035 1.7396778339147567 1.822003048658371 1.738792386651039 2.032005922794342 2.337466493844986 2.0866736060380937 2.0541093587875365 1.8861367601156234 1.7091059541702271 1.8114877313375473 1.7553791564702987 1.7507650113105775 1.8427098786830902 1.5877794414758681 1.5965346294641494 1.5078815287351608 1.533705769777298 1.5581133311986923 1.7026649069786073 1.460573646426201 1.6850327908992768 1.6132404839992522 1.4705295246839523 1.7606798267364503 1.5820770448446273 1.6384421628713608 \n",
      "Mean_Reward:0.7405070498865999 1.5473890565852526 2.382240953359228 0.9941943458060679 1.0851492901959738 1.5036510490605406 0.696221718375418 1.5742502684586848 1.646652687675561 0.9354958949917398 0.8847539452471257 2.0529272794828275 0.8253757854136226 1.594661521594978 1.7701012799446574 1.385373133730439 1.60021645888831 1.3545751348608166 1.7638868429185495 1.8544766419933207 2.9495277205286645 1.303613842752542 1.594362410762783 2.401290093565814 1.8844858960822457 2.1042317585644605 1.4978771613876094 1.9722170422740928 1.3922163492671595 1.5659818230773679 1.0867741059091085 1.404261408430398 2.0261745451175575 1.683232285622781 1.4749971536847573 1.3272946490461515 0.9231455624989026 1.0377090373198685 0.8552824466617324 1.8529552386233994 1.4471181186153868 1.7712478796703113 3.2766043005123238 1.986345224241997 1.322971901113804 1.754754099419124 1.3106534315203728 1.542296698009908 2.1799690898573854 2.574261586005148 1.5438645221560137 1.979839433158377 1.5839623641486142 2.0295689779514476 0.9028902999289689 1.8187674343360611 0.9911456689977406 2.106415933430493 2.254907723966089 2.0598161399958133 1.8006955820264625 1.765805909044503 2.305724302232176 1.4505459859933922 0.6953087465461426 2.4165484047166776 1.6158034433248418 1.28345740764828 1.9991830671569126 2.2272094125330577 2.183852073644688 2.8756811619655913 2.8845891628964506 1.7516898753945502 1.685671660259792 1.458101464190523 3.5327735172379517 1.6636542670567636 0.735252153007607 2.003886940860887 1.591171074305619 1.6270522622714132 1.7809820305870465 2.8389866596070745 1.9544463237410852 3.678844419794807 0.8909668970912372 2.7581872147432107 1.8563547453420821 2.3417988065979958 2.999637901107371 2.8849435928171654 1.5666633837314745 1.881972155204204 2.6412102864067855 1.6797045575149436 2.4116383124818648 1.7214057255603812 1.5504626441586593 3.0415762060990836 \n",
      "Steps:10000\n",
      "Evaluate of cluster 7, Epoch 1\n",
      "Top 5. Hit_rate:0.8975694444444444 nDCG:0.6291709031013074 Precision:0.20555555555555557 Recall:0.8720532144360269 F1:0.3326907159886009 Total steps:23030\n",
      "Top 10. Hit_rate:0.9565972222222222 nDCG:0.6493823427705107 Precision:0.11840277777777776 Recall:0.9490712557118807 F1:0.21053920599524534 Total steps:23030\n",
      "Top 20. Hit_rate:0.9670138888888888 nDCG:0.6519454210341884 Precision:0.062065972222222224 Recall:0.962700385551948 F1:0.11661365857275334 Total steps:23030\n",
      "Cluster:7\n",
      "A_Loss:-2.881872627735138 -2.7703471434116365 -2.712471686601639 -2.774239636659622 -2.8467535734176637 -2.8223749780654908 -2.7602988362312315 -2.780114805698395 -2.8893855452537536 -2.9578452587127684 -2.950803301334381 -3.094329354763031 -3.2204729199409483 -3.0772701930999755 -3.1522787547111513 -3.1628516340255737 -3.2401520442962646 -3.122695665359497 -3.0976291942596434 -3.026629526615143 -2.935379378795624 -3.0910767245292665 -2.869468138217926 -2.8481685757637023 -2.690905486345291 -2.582867830991745 -2.5276013147830962 -2.6426231229305266 -2.6129177057743074 -2.692748476266861 -2.6716637527942657 -2.610896781682968 -2.6209002113342286 -2.66927875995636 -2.700517340898514 -2.9126592564582823 -2.925775841474533 -2.8621384119987487 -2.9398184847831725 -2.9923710441589355 -2.874961574077606 -2.7735676741600037 -2.788327078819275 -2.709944624900818 -2.823189207315445 -2.8712375116348268 -2.974489638805389 -2.8883782172203065 -2.8096740102767943 -2.9083261263370512 -2.848122782707214 -2.772518334388733 -2.9085777163505555 -2.9212572884559633 -2.8504699170589447 -2.7995406126976015 -2.8736260962486266 -2.9127356791496277 -2.943083324432373 -3.0602753448486326 -2.969508156776428 -3.046736567020416 -3.1680077147483825 -3.317881405353546 -3.295165331363678 -3.4659452176094057 -3.3801087522506714 -3.3388332605361937 -3.3572920250892637 -3.320557005405426 -3.200425236225128 -3.1208668112754823 -3.0136261415481567 -3.0220905447006228 -2.9186975145339966 -2.9119880557060243 -2.9771175932884217 -3.0802630186080933 -3.167743234634399 -3.1901738262176513 -3.2898683404922484 -3.2151478791236876 -3.4533826422691347 -3.5288507771492004 -3.627968785762787 -3.6120834827423094 -3.473066282272339 -3.3995418453216555 -3.5460668277740477 -3.488054139614105 -3.4957267665863037 -3.671244442462921 -3.785539267063141 -3.8698741388320923 -3.7510708141326905 -3.8336966490745543 -3.8244330716133117 -3.7974332070350645 -3.7726869225502013 -3.703604748249054 \n",
      "C_Loss:1.694104973077774 1.5753395467996598 1.651006317138672 1.700443971157074 1.7049653124809265 1.7090618604421615 1.800894905924797 1.8199141204357148 1.8409374916553498 1.8336725229024886 1.8519016045331955 1.8546806168556214 1.9381046164035798 1.853915529847145 1.8965113627910615 1.8830923801660537 1.892821366786957 1.8030039024353028 1.9392614620923996 2.0420532917976377 2.028975330591202 2.2958099937438963 2.3094178354740142 2.029183442592621 1.9052840226888657 1.8770844638347626 1.8589405775070191 2.2126820349693297 2.144137356877327 3.435927412509918 3.158371241092682 3.134518506526947 3.1735884940624235 3.0383125925064087 2.9545926332473753 3.2973812568187713 3.2255024576187132 3.164450161457062 2.800502458810806 2.3205491322278977 2.0807774019241334 2.1350547349452973 2.4985511302948 2.771025524139404 2.7340264678001405 2.5719461238384245 2.6701177990436555 2.601699219942093 2.5709328079223632 2.3522602212429047 3.0882365602254866 3.096712439060211 2.91741627573967 2.58390150308609 2.4036546528339384 2.5434854578971864 2.5598615288734434 2.6312312376499176 2.9372017657756806 2.5849083822965624 2.1502465236186983 2.137298669219017 2.1273796594142915 2.2762429010868073 2.4169138646125794 2.2426128721237184 2.213237950801849 2.1886384797096254 2.2343066239356997 2.208573772907257 2.1010631990432738 1.9910735708475114 2.1538080191612243 1.983705887198448 1.8735989898443222 1.80627368748188 1.8496460682153701 1.9676327538490295 1.767575781941414 1.9121266210079193 1.845390568971634 1.936185297369957 1.949501113295555 1.8445728707313538 2.327077766656876 2.608903034925461 2.3835558092594145 2.4699405777454375 2.4225846022367477 2.312124881744385 2.578062951564789 2.6872663259506226 2.733873252272606 2.748467276096344 2.6279246467351913 2.639113141298294 2.508223054409027 2.747432729005814 2.7753833174705504 2.5580675745010377 \n",
      "Mean_Reward:1.3173254855719398 1.5504414297938882 2.431514343002277 3.3659676671073218 1.1978101825820788 1.3177917447045575 2.436019402103984 2.1316178019735172 2.323129801704589 2.5353365915937047 2.3641570252042508 2.9073720667621905 2.8538712684980085 2.008542739840162 2.3492134831567877 2.1532761557752993 2.305804265017436 2.977801905586708 1.1516637438040005 2.0724034602724397 2.8350429854854893 2.4257796173193977 1.7113323998427794 1.3862586382766762 0.7166635929408861 0.7858790941677569 2.515835265039155 2.4995855833449823 2.0181282422548343 1.6856238700705122 2.696748709996005 2.072227309209823 2.2117496063585698 3.0223763557702172 2.399805589622965 3.11919138426396 1.3933447097301659 2.4963994825416127 2.696073026808018 1.8101296004125786 1.5289049865436124 2.3020485820240593 0.6587259225530407 2.8902058565143967 2.856695979180614 2.3259335223203093 2.3263977075256217 1.5664778077482495 1.3560812280245849 2.883833144387778 1.473675284136778 2.663611615152965 2.4887573902900995 1.5510985600849638 1.8627451295845237 2.557169856964243 1.8162346633113193 1.7915469820020926 2.5960922238267123 1.8782087309839135 2.898821253142046 2.94993889242384 2.321254018071442 1.98888870720157 3.386795611793614 2.2669700123833194 1.7973746927591912 1.2771673392757548 1.9541864141213572 1.5217861303025237 2.1047901640944073 1.9828795871711804 0.541878755380877 2.2928091148870227 2.49891353683362 1.9811522650535422 3.179663926611676 2.242277198457628 2.1898700850241712 2.616560865021175 1.8128742360499976 1.5550435796645166 2.061481585106159 1.8873052179056753 2.393644854205162 0.864330099874735 3.090643638095429 1.3322025896753178 2.4876825110370833 1.7514128872115344 1.9992806081661834 3.0950361457763154 2.6831396593835213 2.430707840654328 2.1657971793076327 1.133042867260063 2.83645046054181 2.5210769231693355 2.298560139212233 2.472116050801942 \n",
      "Steps:10000\n",
      "Evaluate of cluster 7, Epoch 2\n",
      "Top 5. Hit_rate:0.9016203703703703 nDCG:0.627510528875394 Precision:0.20694444444444446 Recall:0.87673279170675 F1:0.3348502801908564 Total steps:24030\n",
      "Top 10. Hit_rate:0.9560185185185185 nDCG:0.6460548819463506 Precision:0.11840277777777779 Recall:0.9485188567219817 F1:0.21052560659778558 Total steps:24030\n",
      "Top 20. Hit_rate:0.9675925925925926 nDCG:0.648955077486992 Precision:0.061921296296296294 Recall:0.9630916681697932 F1:0.11636111626303404 Total steps:24030\n",
      "Cluster:8\n",
      "A_Loss:-0.2795021642744541 -1.1688597935438156 -2.1022784793376923 -2.228689204454422 -2.1897350156307223 -2.547689445018768 -2.726592788696289 -2.567003356218338 -2.7449645936489104 -2.983621742725372 -3.0404094815254212 -2.931605530977249 -2.9106445944309236 -2.6815419948101042 -2.7359870302677156 -3.1166529154777525 -3.4496738743782043 -3.71533047914505 -4.075147716999054 -4.110865893363953 -4.322686874866486 -4.950943627357483 -5.417471261024475 -5.788494324684143 -5.998260321617127 -5.871265125274658 -5.843256583213806 -5.62621645450592 -5.602724514007568 -5.6753117990493775 -5.575665206909179 -5.4678972673416135 -5.774993810653687 -5.788438501358033 -6.159441885948181 -6.294185528755188 -6.22500693321228 -6.122858891487121 -5.951448607444763 -5.989736161231995 -5.939534683227539 -6.158496036529541 -5.68000786781311 -5.876388649940491 -6.112887697219849 -6.094954562187195 -6.016382565498352 -5.994099020957947 -6.083400163650513 -5.8640356588363645 -5.957965259552002 -5.892787938117981 -5.841897158622742 -5.833441271781921 -5.9457171487808225 -5.986224660873413 -5.616916122436524 -5.563587136268616 -5.480670762062073 -5.489911890029907 -5.454567155838013 -5.561302824020386 -5.648025484085083 -5.525490679740906 -5.496463751792907 -5.3897115516662595 -5.464010992050171 -5.333825535774231 -5.317272982597351 -5.220762333869934 -5.217907104492188 -5.20155017375946 -5.105085430145263 -5.053457713127136 -5.011634459495545 -4.912572422027588 -4.99524977684021 -4.9436105585098264 -4.748012869358063 -4.779472386837005 -4.6505949854850765 -4.701234934329986 -4.770019912719727 -4.651655535697937 -4.744548232555389 -4.74003084897995 -4.816674168109894 -4.856750836372376 -4.986910438537597 -4.931370220184326 -4.936340923309326 -5.065596809387207 -5.0142307472229 -5.054396817684173 -4.96874757528305 -4.901323006153107 -4.79590485572815 -4.664044058322906 -4.70359974861145 -4.665488743782044 \n",
      "C_Loss:4.58478952884674 3.0176254427433014 2.461625699400902 2.695585836172104 2.6346485877037047 2.6586482334136963 2.6709490203857422 2.981835973262787 3.1013395476341246 3.2979088282585143 3.1363552486896515 3.262027471065521 3.510572248697281 3.362425979375839 3.2003477108478546 3.161007205247879 3.3128608202934267 3.4400610649585723 3.1533198404312133 4.609499427080155 4.379480342864991 4.0929488956928255 4.36464438199997 3.8662671458721163 3.707471512556076 3.6180988919734953 3.4351410257816313 3.721141310930252 3.139699729681015 3.5445406472682954 3.7577360689640047 4.241675890684128 3.991376106739044 4.143520557880402 3.8751990497112274 3.7438514947891237 3.9888480377197264 3.836632344722748 3.7337482416629793 3.7707865500450133 3.3849833965301515 3.1555618405342103 3.1331181919574735 2.908403071165085 2.791115701198578 3.0735564708709715 2.9344114410877227 3.0865759325027464 2.95853253364563 3.987994599342346 3.912920029163361 3.6693361020088195 3.7080403220653535 3.4751717698574067 3.6530181670188906 3.409281224012375 3.3528828585147856 3.4996258413791654 3.5123775255680085 3.2774772560596466 3.0768332934379576 3.1200459015369417 3.1651531314849852 2.8922182500362394 2.8642375719547273 3.099820588827133 2.9542865681648256 2.797583758831024 2.8522069239616394 3.046665214300156 3.1070593750476836 3.216930034160614 3.4238283824920654 3.746653710603714 3.8205365180969237 3.7135819816589355 3.4689148831367493 3.694608939886093 3.2348207128047943 3.1527861666679384 3.281452317237854 3.2386751782894136 3.0193447411060332 2.8656877756118773 3.048828682899475 3.2259094846248626 2.8678880178928376 2.8470955753326415 2.886105889081955 2.8159640872478486 2.773490996360779 2.6494272708892823 2.9376587319374083 2.9295551657676695 2.8355022859573364 2.772869859933853 2.8251918959617615 3.0080848717689515 2.821421973705292 2.876931562423706 \n",
      "Mean_Reward:0.6961331615784377 0.48032370343237213 2.711928695090186 2.1909957371871163 2.356731385737982 3.430989746722008 3.7271452595397894 3.6650896527888546 4.653657773340965 3.174051200944314 4.551701209285294 4.640820708129171 3.140622356781934 4.2767784733946765 5.134244053296908 5.963233890153447 5.495612869671472 4.883715801475988 5.45499374178757 4.260225007120158 6.602406786819459 6.898308885050743 5.8350406147647425 7.0408631864702285 5.846773479085399 6.5977850713156245 6.323585887942748 6.104749972553902 5.649465495527059 6.434546118182572 4.521373873134625 6.9798636273239945 7.111112072131158 6.510101250423208 7.798562670235558 7.19487529923143 6.141617896580535 6.453404484723592 6.93970072471367 6.364643263650655 6.677379820239794 6.020518109732826 6.778411070553209 5.878902734189653 7.438130495862124 6.631198836424597 7.644322686934121 6.380517716938475 6.154701985558935 6.239978549990106 6.8012654388587945 5.540173166055468 7.138767462995161 6.93475486325438 6.895617933324883 5.652789881410408 5.60505586964092 6.918914619431295 6.363824845973053 7.244430776754102 6.778330197760829 6.401071709473544 6.85074866610298 6.536257493108383 6.960947546756139 6.665168112836158 7.001100015578207 6.225419361429756 6.1243436974430185 6.850755886829587 6.7231892081737366 5.851174531803879 6.46629284850718 5.477797736338696 5.962750257962042 5.71778283348284 5.832945774697154 6.490424205719011 6.009186440192625 7.006121279940595 5.599437456864961 6.279117558205421 6.447684045602114 5.538910374477356 6.437492873068817 6.582684598644589 7.4276259992909 7.349059350397223 6.582619500321385 6.654814873784861 6.672306656495525 7.251742323843249 5.451073844861512 7.024621857455619 6.492959717940633 6.440863107119205 5.564741332350139 7.157915585283624 6.372899520537167 7.161962647564383 \n",
      "Steps:10000\n",
      "Evaluate of cluster 8, Epoch 0\n",
      "Top 5. Hit_rate:0.9868173258003766 nDCG:0.9445430779256107 Precision:0.2606403013182675 Recall:0.9728709457523018 F1:0.41113394219937743 Total steps:25030\n",
      "Top 10. Hit_rate:0.9962335216572504 nDCG:0.9459398123947439 Precision:0.13879472693032016 Recall:0.9931030467753631 F1:0.24355087114299862 Total steps:25030\n",
      "Top 20. Hit_rate:0.9962335216572504 nDCG:0.9457236691976387 Precision:0.0711864406779661 Recall:0.9954850548070887 F1:0.13287121979760383 Total steps:25030\n",
      "Cluster:8\n",
      "A_Loss:-4.619875545501709 -4.620789537429809 -4.583924827575683 -4.652087559700012 -4.59405590057373 -4.649979310035706 -4.663563649654389 -4.843132379055024 -4.578180339336395 -4.595944635868072 -4.452533917427063 -4.363118393421173 -4.422135157585144 -4.148535521030426 -4.045640954971313 -4.171284651756286 -4.013347001075744 -4.035514667034149 -4.081281225681305 -4.24745274066925 -4.281763634681702 -4.497945282459259 -4.692857880592346 -4.648809065818787 -4.640881915092468 -4.71208550453186 -4.78677161693573 -4.761765353679657 -4.711672132015228 -4.607287304401398 -4.671269795894623 -4.509211897850037 -4.421096618175507 -4.46069319486618 -4.398474543094635 -4.375295524597168 -4.281220207214355 -4.363394558429718 -4.319123182296753 -4.409982833862305 -4.370937032699585 -4.493445861339569 -4.521065678596496 -4.488748736381531 -4.596655538082123 -4.440201892852783 -4.47308140039444 -4.449725067615509 -4.50369321346283 -4.649670431613922 -4.675440130233764 -4.5534929895401 -4.650315165519714 -4.642361826896668 -4.598739132881165 -4.597102990150452 -4.67506909608841 -4.724780530929565 -4.614152412414551 -4.606384670734405 -4.552237830162048 -4.637606816291809 -4.7455817270278935 -4.860995092391968 -4.811679985523224 -4.753072056770325 -4.67264743566513 -4.697442855834961 -4.635970520973205 -4.6697042226791385 -4.556923372745514 -4.754209971427917 -4.563355243206024 -4.462469866275788 -4.578323702812195 -4.499461319446564 -4.580813417434692 -4.4801275706291195 -4.305083405971527 -4.167111344337464 -4.270080671310425 -4.077557663917542 -4.186078038215637 -4.1682043814659115 -4.061186001300812 -4.084013593196869 -4.0923499846458435 -4.219296312332153 -4.3902886819839475 -4.609853749275207 -4.567751905918121 -4.563243360519409 -4.613134143352508 -4.608578286170959 -4.718622617721557 -4.798390080928803 -4.895615949630737 -4.817418789863586 -4.865992901325225 -4.8239460277557376 \n",
      "C_Loss:2.857844647169113 3.024830138683319 2.7087157547473906 2.9029332435131074 2.838578602075577 2.8703599834442137 2.815246490240097 3.1254760539531707 2.8966633796691896 2.937069101333618 2.9755188989639283 4.244218668937683 3.7141092801094056 3.5820946538448335 3.5200138223171233 3.227598680257797 3.3502574241161347 3.0413291013240813 3.1755010890960693 2.8563446152210235 2.9794403457641603 2.88156666636467 2.913255189061165 2.9781476068496704 2.99243812084198 3.441394407749176 3.263708621263504 3.3916646671295165 3.471414182186127 3.396882392168045 3.633047790527344 3.5717888116836547 3.6384019124507905 3.705523579120636 3.985032465457916 3.932466667890549 3.6742269468307494 3.774030876159668 3.6985040593147276 3.7698096013069153 3.5306366205215456 3.4066186594963073 3.4613157188892365 3.6047805523872376 3.4976600301265717 3.479485099315643 3.2452131903171537 3.205074430704117 3.2019986081123353 3.3098543202877044 3.215104398727417 3.156822669506073 2.9472791266441347 2.955835120677948 3.1978909611701964 3.205999187231064 3.0718167531490326 2.9775186443328856 2.9670443046092987 3.065721027851105 2.9869680428504943 3.1105625212192534 3.1595190846920014 3.175376114845276 3.288765102624893 3.3891922104358674 3.67538294672966 3.9206348729133604 4.033761559724808 3.8563887655735014 3.4004364609718323 3.3511302459239958 3.7805944371223448 3.2977647852897642 3.2755431079864503 3.428815494775772 3.033323358297348 3.1643908739089968 3.2206405651569368 3.2283958292007444 3.550475263595581 3.5869110321998594 3.532639889717102 3.412560764551163 3.6664833331108095 3.351795015335083 3.7569018244743346 3.6381437194347384 3.4578420770168306 3.3622630965709686 3.146063059568405 3.080474153757095 3.165603907108307 3.296679874658585 3.1867467617988585 3.206627492904663 2.985793753862381 3.066003975868225 3.485594139099121 3.753338828086853 \n",
      "Mean_Reward:5.978127596550311 6.615286208431669 6.65699721873861 6.4828900348850995 6.23071371856229 6.6702446862670435 6.622372140563181 6.554462448114162 5.982317044462872 6.214434234126158 4.921097821424787 6.257386972014136 6.5532000813715054 4.85500570316044 5.54978220947325 6.93643383808745 5.504936670277891 6.789450922209657 6.212899186359997 6.9466083711932285 6.090320896501701 7.30603175153874 6.861794789274138 5.9148280100183 6.913377196086502 6.539377700504582 6.688430448813657 5.658892633458097 5.960605280157652 6.2426087094876355 6.457269319991871 5.33666213149151 6.453493730935138 5.68583751403692 6.045669851754408 6.443083191890563 6.41238204699647 5.429172971596774 5.379044514589605 7.1073981246094915 5.6045713517617095 6.482373199872761 5.5007170028995604 6.996690077353431 5.576175143054168 6.00058354146772 5.7282947372198 6.242313134639664 6.282593308155985 7.008179066137181 6.381050052131061 5.740312823525767 5.606307014598331 6.612770841535945 6.054348539267814 6.97034573291268 6.0537744253109596 6.1356036764407005 6.015018847357353 6.598352261821693 6.557085683636805 7.040485694479348 7.729392371446072 6.249314561252763 5.388088020140177 5.582802534636401 6.704110364275766 5.674991945209258 7.3104124046096945 6.020977818736481 7.123800037966754 6.958511904355394 6.221008541423689 6.643094908863735 6.256721141387701 6.515090784491064 5.376643578604557 5.3298847253039945 5.228738651930615 6.365474420308214 6.731456573924541 5.614890899591034 6.7018065706644325 5.843559424136719 6.603455284565637 6.925480885049431 6.185674517799637 7.269107958883735 6.592841426666612 7.193607813844576 6.70857358371425 6.933594395122644 6.17192707030981 6.724195248934716 6.472083700409254 7.132200838767688 5.964289295410677 6.552685924733319 6.422644851189115 6.904894280728984 \n",
      "Steps:10000\n",
      "Evaluate of cluster 8, Epoch 1\n",
      "Top 5. Hit_rate:0.9868173258003766 nDCG:0.9438056474690537 Precision:0.2610169491525424 Recall:0.9730592696694391 F1:0.4116192374998472 Total steps:26030\n",
      "Top 10. Hit_rate:0.9962335216572504 nDCG:0.9454846996224903 Precision:0.1390772128060264 Recall:0.9933455851534947 F1:0.24399299199690197 Total steps:26030\n",
      "Top 20. Hit_rate:0.9962335216572504 nDCG:0.9453308827865513 Precision:0.07123352165725047 Recall:0.9955635231058959 F1:0.1329539290636359 Total steps:26030\n",
      "Cluster:8\n",
      "A_Loss:-4.887749381065369 -4.806623616218567 -4.860244736671448 -4.970848503112793 -4.953787264823913 -5.067970905303955 -5.185825710296631 -5.244834668636322 -5.209750514030457 -5.1873312664031985 -5.233285322189331 -5.377127561569214 -5.42046847820282 -5.244383540153503 -5.275711102485657 -5.111277232170105 -5.062086720466613 -5.185576281547546 -5.086871223449707 -5.057109518051147 -5.094622583389282 -5.020900049209595 -5.090754542350769 -5.13464569568634 -5.031222763061524 -5.060616106986999 -5.001054973602295 -4.989450635910035 -4.944817810058594 -4.91483099937439 -5.032179684638977 -4.924633326530457 -4.961640815734864 -4.949309821128845 -5.145173926353454 -5.410473022460938 -5.405812549591064 -5.466087350845337 -5.383062648773193 -5.402666153907776 -5.405671105384827 -5.498965125083924 -5.380166382789612 -5.213759059906006 -5.098997159004211 -5.0265037226676945 -4.912227680683136 -5.044676003456115 -5.063150181770324 -5.014382951259613 -5.012431373596192 -5.010885806083679 -5.238836426734924 -5.2637631130218505 -5.251222324371338 -5.148886017799377 -5.174050779342651 -5.224825048446656 -5.083062949180603 -5.260899691581726 -5.295461893081665 -5.111613259315491 -5.03000479221344 -5.096324243545532 -4.997461905479431 -4.978546009063721 -4.863519620895386 -5.0492973279953 -5.065124623775482 -4.917650785446167 -5.116443157196045 -5.2299844884872435 -5.25817325592041 -5.285125775337219 -5.33432412147522 -5.426404857635498 -5.4332487630844115 -5.348038167953491 -5.304277491569519 -5.186495013237 -5.132635192871094 -5.155409293174744 -5.111770610809327 -5.304193277359008 -5.250398988723755 -5.176949057579041 -5.253197526931762 -5.281057639122009 -5.261891140937805 -5.350644364356994 -5.361634902954101 -5.220389838218689 -5.013686685562134 -4.864871666431427 -4.798312318325043 -4.974235196113586 -5.041536819934845 -4.926679995059967 -4.894571008682251 -4.79925657749176 \n",
      "C_Loss:3.6130705857276917 3.8662089705467224 3.8410450339317324 3.758914294242859 3.807611758708954 3.8156629967689515 3.804940824508667 4.3337158036232 3.548859944343567 3.580713224411011 3.7061119616031646 3.5447829830646516 3.4553522443771363 3.4420537638664244 3.58730061173439 3.716981234550476 3.5971299588680266 3.4894954133033753 3.320122195482254 3.121944645643234 2.9960801672935484 2.958790397644043 3.0100706672668456 3.1058080697059633 2.847582309246063 2.8773660957813263 2.932426426410675 3.063130054473877 3.2186483299732207 3.17332137465477 3.3737701272964475 3.325548601150513 3.0755235147476196 3.2529285943508146 3.2829156565666198 3.154444478750229 3.319964213371277 3.3260069632530214 3.1921497488021853 3.2589043271541596 3.210759845972061 3.059587615728378 3.724413123130798 3.9752291512489317 4.211896872520446 3.438913722038269 3.465643984079361 3.0985681438446044 3.330990455150604 3.432229707241058 3.4518519616127015 3.391732156276703 3.481198066473007 3.302892928123474 3.382511477470398 3.231620388031006 3.2125321304798127 3.2265525591373443 3.322830785512924 3.3617945957183837 3.4870558619499206 3.4714715695381164 3.4451679372787476 3.4441785168647767 3.4742858672142027 3.781447455883026 3.7206630516052246 3.3645822620391845 3.4482835793495177 3.3550144124031065 3.4893503689765932 3.346641858816147 3.4331038963794707 3.3424213409423826 3.303892003297806 3.5137821102142333 3.2305871903896333 3.3518984162807466 3.35033992767334 3.6244797539711 3.567789160013199 3.7506982612609865 3.931767212152481 3.6934740233421324 4.194045746326447 4.502157962322235 4.016785283088684 4.038400092124939 3.964040582180023 3.94338073015213 3.950543736219406 3.618932213783264 4.440285046100616 4.313443386554718 4.301363868713379 3.8538916397094725 3.844114143848419 3.8340494203567506 3.6446676540374754 3.90251372218132 \n",
      "Mean_Reward:6.2842063788965925 6.379731053501428 7.2114403595237375 6.8148443893821185 6.801966250167407 7.5934748908143055 6.976071284832659 7.7076604926668555 5.675368425840315 6.864980402778553 6.555131046874183 6.7579523964628505 6.922947323461265 6.281087896195755 6.388630703600849 6.905158656361773 6.66137850911105 6.4920221818459085 6.8497516847722535 6.4218936605640575 6.633338987987551 6.645692115331895 6.813324807821286 5.625901461116947 6.42509072257082 5.8728078338270935 6.456316060869005 6.022697369880668 6.343051491650602 6.681254249124819 6.842034322447542 5.775046409779456 6.640506949356242 6.961929983179383 8.043167173095307 7.345254672729948 7.027474411306576 6.505453600733649 6.022353641231648 6.549307057946732 6.5821523559600905 6.560718034832794 4.102822587735321 7.123360460001009 6.362563700738008 6.934981216541683 6.452506697362276 6.387563652702756 6.248054120264163 5.907007020987813 7.193968824998755 7.1744089807074225 6.337331135396698 5.948074428948152 6.642068108916359 6.472176345705191 6.329076288121173 6.117499817811161 6.501386387766889 7.198476419698201 5.632622199885046 5.991155786781899 6.580415112425722 6.501667318117589 5.277437348406419 6.7913802550129 6.040023930644526 7.244050544370932 6.424210721309996 7.644437689283445 6.332385825460813 8.234794094924974 6.442569977100745 6.314047153951115 7.031366937665054 6.384635415614992 6.482706536627125 6.257494953485169 6.210598097286157 6.973046207924488 6.598580151695825 6.077433524774242 7.309008890721989 6.510575976610912 5.847826460428012 6.674781951939349 6.535382838029917 7.048264987128895 6.1656229756802885 7.068937126896734 6.5197950338953286 6.561084987241253 4.623298779533557 6.820076856935311 6.482208394513237 7.555007609044868 6.791501923376041 6.0828661027567685 5.062720171851005 6.905468883549816 \n",
      "Steps:10000\n",
      "Evaluate of cluster 8, Epoch 2\n",
      "Top 5. Hit_rate:0.9861895794099184 nDCG:0.9425575692753226 Precision:0.2611424984306341 Recall:0.9728081711132559 F1:0.4117528466769752 Total steps:27030\n",
      "Top 10. Hit_rate:0.9962335216572504 nDCG:0.9446340098044936 Precision:0.13917137476459512 Recall:0.9934264312795387 F1:0.24414032829780605 Total steps:27030\n",
      "Top 20. Hit_rate:0.9962335216572504 nDCG:0.9444857022619234 Precision:0.07124921531701192 Recall:0.9955896792054983 F1:0.13298149757111594 Total steps:27030\n",
      "Cluster:9\n",
      "A_Loss:-1.2822126726433636 -2.0043677616119386 -2.160034251213074 -1.8812164568901062 -2.1236274003982545 -2.2576447248458864 -2.308572602272034 -2.266082798242569 -2.223681528568268 -2.315285050868988 -2.8976717972755432 -3.0830379271507264 -3.372159068584442 -3.626229009628296 -4.113385159969329 -4.450233283042908 -4.432908141613007 -4.299560151100159 -4.503075892925263 -4.448283095359802 -4.828812325000763 -4.9853471493721 -5.038566789627075 -5.085590927600861 -5.284823393821716 -5.655988745689392 -5.836336193084716 -5.693180470466614 -5.781044702529908 -5.766189785003662 -5.71038031578064 -5.799442572593689 -5.743452687263488 -5.960254554748535 -5.7261190366745 -5.812067070007324 -5.6193083381652835 -5.786337027549743 -5.976192049980163 -6.313729825019837 -5.728137054443359 -6.024994931221008 -6.3131688737869265 -6.510677042007447 -6.463964605331421 -6.353369355201721 -6.111862406730652 -6.5181357955932615 -6.808322448730468 -6.763174161911011 -6.532751474380493 -6.24094907283783 -6.221590809822082 -5.96343418598175 -5.987080836296082 -6.071939182281494 -6.005104937553406 -5.9994143295288085 -5.767521662712097 -5.710122318267822 -5.86755069732666 -5.971151747703552 -5.793003816604614 -5.801709380149841 -5.7366908836364745 -6.013594779968262 -6.0427346563339235 -6.294485573768616 -6.226381511688232 -6.379458889961243 -6.556806206703186 -6.683013801574707 -6.643408670425415 -6.509578232765198 -6.349679565429687 -6.258122763633728 -6.236253304481506 -6.266971664428711 -6.373771615028382 -6.550027046203613 -6.408932070732117 -6.084275379180908 -5.98264666557312 -6.219277114868164 -6.283917102813721 -6.097678098678589 -6.1595376682281495 -6.069979929924012 -5.905554308891296 -6.016521615982056 -6.01694833278656 -5.887463202476502 -6.129860067367554 -6.22292158126831 -6.103659119606018 -6.265387177467346 -6.16377625465393 -6.082592101097107 -6.152465829849243 -6.167227535247803 \n",
      "C_Loss:7.324637749195099 4.946679458618164 4.162917889356613 4.087588114738464 3.647065154314041 3.5374509358406065 3.4372912466526033 3.3698735308647154 3.4252807939052583 3.448027563095093 3.9801115012168884 3.8517566204071043 4.289300653934479 4.228084625005722 4.538229677677155 4.317335691452026 4.73104017496109 4.825597820281982 4.9890037178993225 5.0888179063797 5.241183538436889 4.949514465332031 5.106003429889679 4.905806894302368 4.814407846927643 4.912902679443359 4.820671699047089 4.931444425582885 4.468772722482681 4.383702352046966 4.098308849334717 3.8912600719928743 4.309593615531921 4.306616044044494 4.108261795043945 3.8714465522766113 3.7412079763412476 4.000623723268509 4.241616530418396 4.121534049510956 4.583211665153503 4.2124269223213195 4.28614755153656 4.274753828048706 4.514147230386734 4.372354025840759 4.499047441482544 4.445560607910156 4.519039199352265 4.485097849369049 4.330709111690521 4.458107278347016 4.195890793800354 4.077891697883606 4.4124942111969 4.338024115562439 4.412270581722259 4.53193546295166 4.147626161575317 4.494752802848816 4.389858283996582 4.59133638381958 4.800064541101456 4.857202799320221 4.372536121606827 4.286241805553436 4.235578899383545 4.4867147731781 4.310812251567841 4.16480700969696 3.9033972775936125 3.802335990667343 3.8052531599998476 4.0461043667793275 4.167234854698181 4.248892812728882 4.36137903213501 4.152765598297119 4.21982233285904 4.310392353534699 4.57485057592392 4.740092096328735 4.6245978379249575 4.4083448195457455 4.202379891872406 4.430111997127533 4.184913253784179 4.301791095733643 4.2187559700012205 4.083570592403412 3.923437234163284 4.246568350791931 4.0163205409049985 4.434903674125671 4.136321393251419 4.483145899772644 4.150364162921906 4.470849723815918 4.2566475319862365 4.191761639118194 \n",
      "Mean_Reward:0.6436536026581132 1.2466713914891598 2.2115948583730987 2.7546520213663097 2.970654267077184 2.7772159226186766 3.8134811727626836 3.1815690381215944 2.780422618431509 5.003142501638344 4.66016224464698 4.431385670529636 4.05075273153414 5.358300734788213 5.3252522477315605 5.095523082084734 4.421070083620447 5.937220895207786 4.70662758926325 6.692734788315041 5.724485584252312 5.4982196484150245 6.105062352031596 5.212506380291118 6.832791034203119 6.706672233644382 4.598974339010303 6.267656548885633 6.135219244810328 4.311094090919617 6.444923575778894 5.757096753716787 5.86216426323699 5.606134538404348 5.727396355727288 5.921961973111927 5.771966579306184 6.091741896262773 6.268431681866582 4.873758436479071 4.274857456920229 6.443785957645482 6.9212688449230475 5.68537300872014 4.702928638441871 5.4406247143028486 5.323346239975588 7.101423021622558 6.311578112440762 5.986220652888612 5.327338336608109 4.751912158210733 5.733667380797097 6.562716296309085 4.781996086606327 5.801947387998475 6.322809015659346 3.9222194486955853 4.68386680709268 7.159074282292164 6.055658172772601 4.239192566962082 4.828392147531485 6.3801516205087845 6.788266032213678 6.19713187579596 6.369116898597976 4.775664255865205 5.580784750837096 6.220628871261454 6.7464415138532345 5.100867071251721 5.461685588117104 4.192921466572027 5.047764664578101 5.924042006183623 4.449191223968776 5.310291991230367 6.696744298029237 5.431616273599347 5.690222304360152 4.611753830057728 5.681525447499371 5.4761110353463165 4.742783512815966 5.178079503922476 5.329765829408939 4.7270105656239 5.159598669177576 6.115313348429993 5.642594420019176 4.430791874561382 6.815745117042345 5.289078952529528 5.639262301410547 4.8614577722852115 5.028857859840139 5.87212900962798 5.748677807658324 4.866874729438528 \n",
      "Steps:10000\n",
      "Evaluate of cluster 9, Epoch 0\n",
      "Top 5. Hit_rate:0.9638429752066116 nDCG:0.9051202912123479 Precision:0.2266528925619835 Recall:0.9569031347440439 F1:0.36649668480281516 Total steps:28030\n",
      "Top 10. Hit_rate:0.96900826446281 nDCG:0.9067685761152846 Precision:0.11580578512396697 Recall:0.9638933036660309 F1:0.20676930930305784 Total steps:28030\n",
      "Top 20. Hit_rate:0.984504132231405 nDCG:0.9100383184710661 Precision:0.05940082644628101 Recall:0.9804063360881542 F1:0.11201479025680966 Total steps:28030\n",
      "Cluster:9\n",
      "A_Loss:-6.0411338090896605 -6.11852041721344 -6.237339239120484 -6.325849199295044 -6.261816596984863 -6.478841161727905 -6.432806015014648 -6.44984959602356 -6.523342752456665 -6.50629231929779 -6.526970953941345 -6.511780571937561 -6.557843761444092 -6.513689069747925 -6.552094368934632 -6.563555555343628 -6.448913955688477 -6.615977549552918 -6.487410597801208 -6.738288493156433 -6.624411144256592 -6.631490230560303 -6.495997533798218 -6.548617725372314 -6.565875372886658 -6.438864521980285 -6.499904704093933 -6.293823790550232 -6.177771954536438 -6.051611213684082 -6.091458330154419 -5.999032444953919 -6.069426827430725 -5.937424192428589 -5.887604179382325 -5.805858416557312 -5.8333225917816165 -5.918586416244507 -5.771009173393249 -5.819084920883179 -5.864729466438294 -5.89874345779419 -5.939765367507935 -5.895049033164978 -5.899488968849182 -5.987478160858155 -6.040848217010498 -5.9151809740066525 -5.974370617866516 -6.101013998985291 -5.741231646537781 -5.649363789558411 -5.760561680793762 -6.123836007118225 -6.545026950836181 -6.387563242912292 -6.180565533638 -6.224368577003479 -6.314999451637268 -6.321858878135681 -6.581040878295898 -6.735420889854431 -6.53135908126831 -6.5771972274780275 -6.411624312400818 -6.399864053726196 -6.597688140869141 -6.564813981056213 -6.42796151638031 -6.552635359764099 -6.543860354423523 -6.476549592018127 -6.412721533775329 -6.424589986801148 -6.5233288717269895 -6.585741600990295 -6.608087205886841 -6.644806756973266 -6.528886938095093 -6.453095211982727 -6.451168551445007 -6.682860789299011 -6.72097644329071 -6.7668624591827395 -6.813943195343017 -6.726247391700745 -6.499363541603088 -6.455423731803894 -6.132950320243835 -6.106009197235108 -6.223577208518982 -5.921239218711853 -6.031844978332519 -6.0676793146133425 -6.21158399105072 -6.096440005302429 -6.082289505004883 -6.1874790239334105 -6.329805521965027 -6.323385109901428 \n",
      "C_Loss:4.2277327728271485 4.193187048435211 4.19662774682045 3.9275955140590666 3.782422661781311 4.118652005195617 4.11348769903183 4.067225203514099 4.3616698038578035 3.879306724071503 3.9508636844158174 3.947299180030823 4.118370366096497 3.7537507927417755 3.878605042695999 3.98798219203949 3.6808210003376005 3.9245441246032713 4.111847888231278 4.034699013233185 4.036728644371033 4.158019692897796 4.169155428409576 4.296125031709671 4.155415139198303 4.498770112991333 4.59301709651947 4.477111444473267 4.634237334728241 4.3246135866642 4.47570298910141 4.557161340713501 4.603398361206055 4.994851438999176 4.786294372081756 4.418786337375641 4.063540856838227 4.045945639610291 4.258723726272583 4.644509546756744 4.859536991119385 4.707723157405853 4.540774482488632 4.198550651073456 4.3894784605503085 4.536843252182007 4.399095821380615 4.496288304328918 4.6171977186203 4.373359993696213 4.696399912834168 4.12905062675476 4.49681313753128 4.641222896575928 4.4448062562942505 4.402354516983032 4.576724636554718 4.6690269422531125 4.6852993130683895 4.729408843517303 4.484740898609162 4.285711051225662 4.141559851169586 4.3197759342193605 3.9495876908302305 3.9728650462627413 4.05917861700058 4.175977187156677 4.0154179298877715 3.906326048374176 3.823349289894104 4.208163506984711 4.153603705167771 4.139760632514953 4.081763589382172 4.125575485229493 4.1568123245239255 4.117180787324905 4.0476949548721315 4.132658288478852 4.258854734897613 4.141935544013977 4.438949549198151 4.181021845340728 4.258810930252075 4.220615568161011 4.249340460300446 4.605833601951599 4.418666876554489 4.197324175834655 4.184177498817444 3.8261582040786744 4.020185782909393 4.35373974442482 4.016234517097473 4.001992013454437 3.9883589720726014 3.7985693681240082 3.663827135562897 3.7895983493328096 \n",
      "Mean_Reward:5.342845493135587 5.9147544203484435 6.9187449153701674 5.606912566328008 5.515990110508343 4.607307297710701 5.6243277401834515 5.736183255488793 5.701513256445772 5.63286828291883 5.348275245731471 7.358422682215235 6.068056129279302 4.994620062111341 5.611869351500794 4.867425171022581 7.113857909496457 5.640675069615856 6.82179458481595 5.252838675692815 6.1682007055191255 6.401599334156609 5.596337764199974 4.789544472669043 6.86573339610115 4.393926632211346 5.056571123829136 5.232657017007165 5.683833436750568 5.115021960241627 5.926936402024718 5.7861198404204695 3.958269256147346 4.978315718021789 5.518594115251403 5.986000889760345 5.83535131355892 4.945603094261509 5.069355931342951 5.877155984871011 7.253293800638446 5.172477931880158 5.396669007683297 5.230285539012997 5.770384576792646 6.724243868952906 4.492444916495737 4.388930398649857 6.261650681640927 4.543991591582934 4.498463956045799 5.461236371464475 5.820343733929291 6.862649525965036 5.805783244752616 4.640680727761728 5.865430588077238 6.347800236976019 6.101412618233006 5.897408185902027 6.379739736770396 4.956494417028899 5.520022306336143 6.144387173248328 5.590086441256601 5.020669578876094 5.551442452293645 5.462750382775513 5.478993052738906 6.997627489412426 5.128359574858855 5.128810712307418 4.834414973426402 7.190437172607055 5.501509320145738 7.179650792659983 5.41221661420816 5.855456758869192 5.090537645897657 6.0819346862794585 5.910851711232631 6.51964142674546 6.344460912818976 6.626251727488572 6.486675958828009 6.308497252667329 5.936446760517175 5.427455120149957 5.745015635298002 6.4810587535649935 6.439452573572222 5.608313160814106 6.26389792267545 6.784053467725314 6.544502510775543 5.202022892877796 6.254864017181576 6.490973428110803 5.87957799070402 4.895490552051378 \n",
      "Steps:10000\n",
      "Evaluate of cluster 9, Epoch 1\n",
      "Top 5. Hit_rate:0.9628099173553719 nDCG:0.9046899001056226 Precision:0.22654958677685955 Recall:0.9557151182151182 F1:0.3662744579223022 Total steps:29030\n",
      "Top 10. Hit_rate:0.9679752066115702 nDCG:0.9063301868588868 Precision:0.11575413223140499 Recall:0.9625556261919898 F1:0.20665618025960908 Total steps:29030\n",
      "Top 20. Hit_rate:0.9808884297520661 nDCG:0.9091093381205503 Precision:0.059168388429752077 Recall:0.9767906336088154 F1:0.11157791110545073 Total steps:29030\n",
      "Cluster:9\n",
      "A_Loss:-6.177176957130432 -6.255985579490662 -6.165305023193359 -6.18649269580841 -6.086211867332459 -6.015823144912719 -6.0781158924102785 -6.119900178909302 -6.049283657073975 -5.942524471282959 -5.9182079315185545 -5.806986293792725 -5.782044501304626 -5.821328477859497 -5.914382038116455 -5.845239148139954 -5.755585837364197 -5.902156367301941 -6.08630907535553 -6.205655431747436 -6.322159314155579 -6.202038779258728 -6.366133513450623 -6.376813745498657 -6.314835014343262 -6.369890336990356 -6.294660434722901 -6.229961829185486 -6.242496995925904 -6.134870257377624 -6.028714008331299 -6.1327686643600465 -5.954283533096313 -5.79562813282013 -5.705091981887818 -5.5351030635833744 -5.528839530944825 -5.447611441612244 -5.457350292205811 -5.538935599327087 -5.586544542312622 -5.503713440895081 -5.506008234024048 -5.431729121208191 -5.510393509864807 -5.577372713088989 -5.741326756477356 -5.6846926355361935 -5.737638192176819 -5.525776209831238 -5.343055720329285 -5.3434068775177 -5.551545214653015 -5.634731297492981 -5.545018215179443 -5.562489600181579 -5.562439832687378 -5.3793154001235965 -5.231434173583985 -5.316928362846374 -5.295448775291443 -5.3642324924469 -5.4279996776580814 -5.556615099906922 -5.612158036231994 -5.602665705680847 -5.579498977661133 -5.57750054359436 -5.6055043601989745 -5.597619071006775 -5.485891737937927 -5.25795687675476 -5.238713748455048 -5.157377481460571 -5.089025368690491 -5.27457762002945 -5.472914237976074 -5.541088547706604 -5.774183049201965 -5.744850435256958 -5.921237559318542 -5.923957052230835 -5.710492067337036 -5.697709240913391 -5.722968530654907 -5.711380248069763 -5.661019864082337 -5.605561380386352 -5.410511493682861 -5.273826355934143 -5.184041447639466 -5.233793702125549 -5.136879997253418 -5.098868262767792 -5.031839141845703 -5.197791528701782 -5.167995662689209 -5.191451292037964 -5.307246994972229 -5.290001239776611 \n",
      "C_Loss:4.028954445123673 4.292181119918824 4.22249032497406 4.021835834980011 4.358613777160644 4.359724283218384 4.452912762165069 4.575674278736114 4.640295357704162 4.307898335456848 4.48787415266037 4.476849479675293 4.372735525369644 4.312629954814911 4.424290409088135 3.959711037874222 3.8171203207969664 3.7020307064056395 3.909701271057129 3.9347028625011444 3.772065484523773 4.297278215885163 4.064638187885285 4.200164842605591 4.064292819499969 4.344364378452301 4.232035548686981 4.549766371250152 4.736744571924209 4.472659350633621 4.165772922039032 3.956947298049927 4.11286902666092 4.175044255256653 4.335154621601105 3.9171667075157166 4.073809622526169 4.059083251953125 3.9062579464912415 4.31570707321167 4.621806207895279 4.486443727016449 4.514103610515594 4.520935888290405 4.315014259815216 4.4197360801696775 4.351788370609284 4.106263310909271 4.125751950740814 3.941760084629059 4.407825248241425 4.3848126816749575 4.4100221824645995 4.495004482269287 4.326982822418213 4.582346971035004 4.4826353597640995 4.502308740615844 4.536049506664276 4.460317556858063 4.512627947330475 4.321555731296539 4.385137557983398 4.122160272598267 4.019093555212021 3.7737093007564546 3.6282025921344756 3.8014314556121827 3.9998410427570343 3.985827667713165 4.048863205909729 3.8599722135066985 4.087668824195862 4.145917551517487 4.098973915576935 4.40537682056427 4.507337944507599 4.192892706394195 4.169113445281982 3.98598486661911 4.134865901470184 4.20149005651474 4.1615988838672635 4.28997811794281 4.04614358663559 3.9012225675582886 3.7338823556900023 3.7476282000541685 3.6760387337207794 3.585607199668884 3.476701110601425 3.7288226544857026 3.445848889350891 3.517370940446854 3.6515678226947785 3.708777003288269 3.9805032086372374 4.046811752319336 3.90905450463295 3.8764335346221923 \n",
      "Mean_Reward:5.584525595674308 6.665404084735578 5.288082184676943 5.751789221208155 5.043526016987688 5.225518727510099 6.766736034437363 4.840095105853613 5.387928461945422 5.402300520176446 6.379495800519238 4.996851531817535 5.588296285326684 5.7494705713191125 6.11354417479115 4.2184737548830835 6.402996432859353 6.0209499053409195 5.278635865376703 6.661006020985741 4.702062573228863 6.7455368015500925 6.716267087464281 5.546004714390121 6.977714887738801 4.738673434915366 6.453294017004938 6.588118054922433 5.1277934228821165 5.477538954535434 5.957899212713941 6.3479961362585975 5.127679938992989 4.570728643339026 5.36447541551073 4.2496618803362 5.723412449512288 5.98897937391398 5.5912797773360206 6.196707720618358 5.4277166231614205 4.555107685974486 6.118576833780157 5.496456394172263 5.666210624472671 5.355666172791441 6.444540517795328 4.79413100968227 5.05576214345126 5.1053639850066865 5.218801703167238 5.972766633268784 6.356557768495459 5.274382674063242 5.715357991705563 5.567974032123426 4.857205148366972 3.6881467989731416 5.061788881125954 5.420309734087133 4.896787694094379 6.546794486686757 5.8015529204581275 5.565542341342739 5.6359372350613 5.905604687971231 4.6594784691841715 6.719063716459042 5.588012281847359 4.767873167215273 5.057092275739346 4.70661135259796 5.9721644793987885 5.245918286917307 5.4607603281889485 6.431100759584711 5.865227497874156 6.437179082065229 6.067403829657559 6.551744701302777 6.163927422710811 6.412332527120644 5.1733119671034205 6.075132101468072 5.1369500530189045 5.901856932258514 6.4904091677982505 5.005168495683819 4.789643688976664 5.516637663665048 6.494063121648227 5.170719259362872 5.625185083295167 5.473238626552317 6.028827323886516 5.043921303416235 6.643952382386613 5.349477743807369 6.133386259746212 5.4335887724805305 \n",
      "Steps:10000\n",
      "Evaluate of cluster 9, Epoch 2\n",
      "Top 5. Hit_rate:0.962465564738292 nDCG:0.9030218710672544 Precision:0.2265840220385675 Recall:0.9555486811168628 F1:0.3663072338487244 Total steps:30030\n",
      "Top 10. Hit_rate:0.96866391184573 nDCG:0.9048298419235252 Precision:0.11587465564738292 Recall:0.9633149678604224 F1:0.20686575244320377 Total steps:30030\n",
      "Top 20. Hit_rate:0.9817493112947658 nDCG:0.907698680288435 Precision:0.05922865013774105 Recall:0.9777376033057851 F1:0.1116912385427909 Total steps:30030\n",
      "ddpg_rec\n",
      "TTop 5. HR:0.9600575526369421 nDCG:0.8478181399778665 Precision:0.23638096143764695 Recall:0.9457814755298446 F1:0.3782298242435134\n",
      "TTop 10. HR:0.9719129049593697 nDCG:0.8510570762124928 Precision:0.12529456260586586 Recall:0.9656878740625077 F1:0.22180985655280736\n",
      "TTop 20. HR:0.9845183410293646 nDCG:0.8538549780393482 Precision:0.06516330185385874 Recall:0.9814249132572117 F1:0.12221201393268659\n",
      "Total train steps:300300 Cost time is 17295.350789\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8 -*- Merge into one file version\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from env import RecommendENV\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "#  DDPG\n",
    "#  hyper parameters\n",
    "LR_A = 0.0002  # learning rate for actor\n",
    "LR_C = 0.0004  # learning rate for critic\n",
    "GAMMA = 0.9  # reward discount\n",
    "TAU = 0.01  # soft replacement\n",
    "\n",
    "\n",
    "def initialize(in_num, out_num, constant=1):\n",
    "    low = -constant * np.sqrt(tf.math.divide(6.0, (in_num + out_num)))\n",
    "    high = constant * np.sqrt(tf.math.divide(6.0, (in_num + out_num)))\n",
    "    return tf.random_uniform((in_num, out_num), minval=low, maxval=high, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Data is limited to 0-1\n",
    "def normalize_data(row_data):\n",
    "    row_data = \\\n",
    "        tf.div((row_data - tf.reduce_min(row_data)), (tf.reduce_max(row_data) - tf.reduce_min(row_data) + 0.0000001))\n",
    "    return row_data\n",
    "\n",
    "\n",
    "class DDPG(object):\n",
    "    def __init__(self, sess, r_s_dim, r_s_num, r_i_num, r_a_w_dim, batch_size, MEMORY_CAPACITY):\n",
    "        self.sess = sess\n",
    "        self.keep_rate = 1\n",
    "        self.s_dim = r_s_dim\n",
    "        self.s_num = r_s_num\n",
    "        self.a_num = r_i_num\n",
    "        self.a_w_dim = r_a_w_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.MEMORY_CAPACITY = MEMORY_CAPACITY\n",
    "\n",
    "        self.memory = np.zeros((self.MEMORY_CAPACITY, self.s_num * self.s_dim * 2 + self.a_w_dim + 1),\n",
    "                               dtype=np.float32)\n",
    "        self.pointer = 0\n",
    "\n",
    "        self.S = tf.placeholder(tf.float32, [None, r_s_num * r_s_dim], 's')\n",
    "        self.S_ = tf.placeholder(tf.float32, [None, r_s_num * r_s_dim], 's_')\n",
    "        self.R = tf.placeholder(tf.float32, [None, 1], 'r')\n",
    "\n",
    "        # networks parameters\n",
    "        with tf.variable_scope('Actor'):\n",
    "            self.a_w = self._build_a(self.S, scope='eval')\n",
    "            self.a_w_ = self._build_a(self.S_, scope='target')\n",
    "        with tf.variable_scope('Critic'):\n",
    "            # assign self.a = a in memory when calculating q for td_error,\n",
    "            # otherwise the self.a is from Actor when updating Actor\n",
    "            self.q = self._build_c(self.S, self.a_w, scope='eval')\n",
    "            self.q_ = self._build_c(self.S_, self.a_w_, scope='target')\n",
    "        self.ae_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor/eval')\n",
    "        self.at_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Actor/target')\n",
    "        self.ce_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic/eval')\n",
    "        self.ct_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='Critic/target')\n",
    "\n",
    "        q_target = self.R + GAMMA * self.q_\n",
    "        self.td_error = tf.losses.mean_squared_error(labels=q_target, predictions=self.q)\n",
    "        self.c_train = tf.train.AdamOptimizer(LR_C).minimize(self.td_error, var_list=self.ce_params)\n",
    "\n",
    "        self.a_loss = -tf.reduce_mean(self.q)  # maximize the q\n",
    "        self.a_train = tf.train.AdamOptimizer(LR_A).minimize(self.a_loss, var_list=self.ae_params)\n",
    "\n",
    "        # target net replacement\n",
    "        self.soft_replace = [[tf.assign(ta, (1 - TAU) * ta + TAU * ea), tf.assign(tc, (1 - TAU) * tc + TAU * ec)]\n",
    "                             for ta, ea, tc, ec in zip(self.at_params, self.ae_params, self.ct_params, self.ce_params)]\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def set_mem(self, saved_mem):\n",
    "        self.memory = saved_mem\n",
    "\n",
    "    def _build_a(self, i_s, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.a_w1 = tf.Variable(name='a_w1_s',\n",
    "                                    initial_value=initialize(self.s_dim * self.s_num, self.a_w_dim))\n",
    "            self.a_b1 = tf.Variable(name='a_b1',\n",
    "                                    initial_value=tf.zeros([self.a_w_dim]))\n",
    "            action_w = normalize_data(tf.nn.relu(tf.nn.dropout((\n",
    "                tf.matmul(i_s, self.a_w1) + self.a_b1), rate=1-self.keep_rate)))\n",
    "            return action_w\n",
    "\n",
    "    def _build_c(self, i_s, i_a, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            n_l1 = 100\n",
    "            self.c_w1_s = tf.Variable(name='c_w1_s', initial_value=initialize(self.s_dim * self.s_num, n_l1))\n",
    "            self.c_w1_a = tf.Variable(name='c_w1_a', initial_value=initialize(self.a_w_dim, n_l1))\n",
    "            self.c_b1 = tf.Variable(name='c_b1', initial_value=tf.zeros([n_l1]))\n",
    "            # Q(s,a)\n",
    "            net = tf.nn.relu(tf.nn.dropout((\n",
    "                tf.matmul(i_s, self.c_w1_s) + tf.matmul(i_a, self.c_w1_a) + self.c_b1), rate=1-self.keep_rate))\n",
    "            self.c_w2 = tf.Variable(name='c_w2', initial_value=initialize(n_l1, 1))\n",
    "            self.c_b2 = tf.Variable(name='c_b2', initial_value=tf.zeros([1]))\n",
    "            q_value = tf.matmul(net, self.c_w2) + self.c_b2\n",
    "            return q_value\n",
    "\n",
    "    def choose_action_weight(self, i_s):\n",
    "        return self.sess.run(self.a_w, {self.S: i_s})[0]\n",
    "\n",
    "    def learn(self):\n",
    "        # soft target replacement\n",
    "        self.sess.run(self.soft_replace)\n",
    "\n",
    "        indices = np.random.choice(self.MEMORY_CAPACITY, size=self.batch_size)\n",
    "        bt = self.memory[indices, :]\n",
    "        bs = bt[:, :self.s_dim * self.s_num]\n",
    "        ba = bt[:, self.s_num * self.s_dim: self.s_num * self.s_dim + self.a_w_dim]\n",
    "        br = bt[:, -self.s_dim * self.s_num - 1: -self.s_dim * self.s_num]\n",
    "        bs_ = bt[:, -self.s_dim * self.s_num:]\n",
    "\n",
    "        _, it_a_loss = self.sess.run([self.a_train, self.a_loss],\n",
    "                                     feed_dict={self.S: bs})\n",
    "        _, it_td_error = self.sess.run([self.c_train, self.td_error],\n",
    "                                       feed_dict={self.S: bs, self.a_w: ba, self.R: br, self.S_: bs_})\n",
    "        return it_a_loss, it_td_error\n",
    "\n",
    "    def store_transition(self, i_s, i_a_w, i_r, i_s_):\n",
    "        index = self.pointer % self.MEMORY_CAPACITY  # replace the old memory with new memory\n",
    "        transition = np.hstack((i_s[0], i_a_w, i_r, i_s_[0]))\n",
    "        self.memory[index, :] = transition\n",
    "        # print(self.pointer)\n",
    "        self.pointer += 1\n",
    "\n",
    "    def set_keep_rate(self, keep_rate):\n",
    "        self.keep_rate = keep_rate\n",
    "\n",
    "\n",
    "class RlProcess:\n",
    "    def __init__(self, the_data_path, the_data_name, data_method, epochs, state_num, action_num, one_u_steps,\n",
    "                 test_top_k: list, is_use_history=True):\n",
    "        self.the_data_path = the_data_path\n",
    "        self.the_data_name = the_data_name\n",
    "        self.data_method = data_method\n",
    "        self.epochs = epochs\n",
    "        self.state_num = state_num\n",
    "        self.action_num = action_num\n",
    "        self.one_u_steps = one_u_steps\n",
    "        self.test_top_k = sorted(test_top_k)\n",
    "        self.is_use_history = is_use_history\n",
    "        self.item_vector = np.load(self.the_data_path + self.the_data_name + \"_embeddings.npy\")\n",
    "        self.user_label_list, self.user_label_num = None, None\n",
    "        self.cluster_users = None\n",
    "        self.train_user_items_dict, self.train_user_items_rating_dict = None, None\n",
    "        self.test_user_items_rating_dict = None\n",
    "        self.nega_user_items_rating_dict = None\n",
    "        self.supp_nega_cluster_items = None\n",
    "        self.old_user2new, self.old_item2new = None, None\n",
    "        self.data_shape, self.test_dict = None, None\n",
    "        # Data initialization\n",
    "        self.data_prepare()\n",
    "\n",
    "    # Data preparation\n",
    "    def data_prepare(self):\n",
    "        with open(self.the_data_path + \"user_label_predict.txt\", 'r') as l_file:\n",
    "            self.user_label_list = l_file.read().split(',')  # str\n",
    "        self.user_label_num = len(set(self.user_label_list)) - 1\n",
    "\n",
    "        with open(self.the_data_path + 'train_user_items_dict.txt', 'r') as train_ui_dict:\n",
    "            self.train_user_items_dict = eval(train_ui_dict.read())\n",
    "        with open(self.the_data_path + 'train_user_items_rating_dict.txt', 'r') as train_uir_dict:\n",
    "            self.train_user_items_rating_dict = eval(train_uir_dict.read())\n",
    "        with open(self.the_data_path + 'test_user_items_rating_dict.txt', 'r') as test_uir_dict:\n",
    "            self.test_user_items_rating_dict = eval(test_uir_dict.read())\n",
    "        with open(self.the_data_path + 'nega_user_items_rating_dict.txt', 'r') as nega_uir_dict:\n",
    "            self.nega_user_items_rating_dict = eval(nega_uir_dict.read())\n",
    "\n",
    "        with open(self.the_data_path + 'cluster_users.txt', 'r') as c_us:\n",
    "            self.cluster_users = eval(c_us.read())['cluster_users']\n",
    "\n",
    "        with open(self.the_data_path + 'old_user2new.txt', 'r', encoding=\"utf-8\") as f:\n",
    "            self.old_user2new = eval(f.read())\n",
    "        with open(self.the_data_path + 'old_item2new.txt', 'r', encoding=\"utf-8\") as f:\n",
    "            self.old_item2new = eval(f.read())\n",
    "        self.data_shape = [len(self.old_user2new.keys()), len(self.old_item2new.keys())]\n",
    "\n",
    "        # Obtain positive and negative samples for testing directly\n",
    "        with open(self.the_data_path + 'test_dict.txt', 'r') as test_dict_file:\n",
    "            self.test_dict = eval(test_dict_file.read())\n",
    "\n",
    "        # Gets the list of classes that appear in the current class but not the farthest from the current class\n",
    "        with open(self.the_data_path + 'supp_nega_cluster_items.txt', 'r') as nega_ci_file:\n",
    "            self.supp_nega_cluster_items = eval(nega_ci_file.read())\n",
    "\n",
    "    # hit_rate nDCG precision recall -- pre-user\n",
    "    def result_evaluate(self, user_id: int, top_k_list: list, the_model, in_emb_s):\n",
    "        one_hit, one_ndcg, one_precision, one_recall = [], [], [], []\n",
    "        h_test_items = self.test_dict[str(user_id)+'_p'].copy()\n",
    "        test_candidate_items = h_test_items + self.test_dict[str(user_id)+'_n'].copy()\n",
    "        # print('True Percent;', len(h_test_items) / len(test_candidate_items))\n",
    "        random.shuffle(test_candidate_items)\n",
    "        t_a_w = the_model.choose_action_weight(in_emb_s)\n",
    "        # print(t_a_w)\n",
    "        # Calculate first and then select Top-k\n",
    "        c_score_list = list()\n",
    "        for c_item in test_candidate_items:\n",
    "            c_item = int(c_item)\n",
    "            score = np.sum(np.multiply(t_a_w, self.item_vector[c_item]))\n",
    "            c_score_list.append([c_item, score])\n",
    "        a_t = []\n",
    "        for ii in range(top_k_list[len(top_k_list) - 1]):\n",
    "            r_item = -1\n",
    "            max_score = -9999\n",
    "            for c_score in c_score_list:\n",
    "                c_item = c_score[0]\n",
    "                score = c_score[1]\n",
    "                if score > max_score and c_item not in a_t:\n",
    "                    max_score = score\n",
    "                    r_item = c_item\n",
    "            a_t.append(r_item)\n",
    "        # print(test_item)\n",
    "        # print(test_candidate_items)\n",
    "        for top_k in top_k_list:\n",
    "            hit_count = 0\n",
    "            hit_list = []\n",
    "            dcg = 0\n",
    "            idcg = 0\n",
    "            for k in range(len(a_t[:top_k])):\n",
    "                t_item = a_t[k]\n",
    "                if t_item in h_test_items:\n",
    "                    hit_count += 1\n",
    "                    t_rating = self.test_user_items_rating_dict[user_id][t_item] - 2\n",
    "                    dcg += t_rating / math.log(k + 2)\n",
    "                    hit_list.append(t_rating)\n",
    "            hit_list.sort(reverse=True)\n",
    "            # print(hit_list)\n",
    "            kk = 0\n",
    "            for t_rating in hit_list:\n",
    "                idcg += t_rating / math.log(kk + 2)\n",
    "                kk += 1\n",
    "            if hit_count > 0:\n",
    "                one_hit.append(1)\n",
    "                one_ndcg.append(dcg / idcg)\n",
    "                one_precision.append(hit_count / top_k)\n",
    "                one_recall.append(hit_count / len(h_test_items))\n",
    "            else:\n",
    "                one_hit.append(0)\n",
    "                one_ndcg.append(0)\n",
    "                one_precision.append(0)\n",
    "                one_recall.append(0)\n",
    "        return one_hit, one_ndcg, one_precision, one_recall\n",
    "\n",
    "    def runProcess(self):\n",
    "        start_time = time.process_time()\n",
    "        emb_size = self.item_vector.shape[1]\n",
    "        s_dim, a_w_dim = emb_size, emb_size\n",
    "\n",
    "        if not os.path.exists('./reinforce_log/'):\n",
    "            os.makedirs('./reinforce_log/')\n",
    "        reinforce_log = open('./reinforce_log/' + self.the_data_name + '_ddpg_cluster-' + self.data_method\n",
    "                             + '_cluster' + str(self.user_label_num + 1)\n",
    "                             + '_state' + str(self.state_num)\n",
    "                             + '_action' + str(self.action_num)\n",
    "                             + '_alpha' + str_alpha + '_'\n",
    "                             + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.txt', 'w')\n",
    "\n",
    "        # training\n",
    "        BATCH_SIZE = 32\n",
    "        MEMORY_CAPACITY = 1000\n",
    "        boundry_rating = 2\n",
    "        print('MEMORY_CAPACITY:', MEMORY_CAPACITY)\n",
    "        env = RecommendENV(s_num=self.state_num, a_num=self.action_num, state_dim=s_dim,\n",
    "                           item_vector=self.item_vector, supp_nega_cluster_items=self.supp_nega_cluster_items,\n",
    "                           boundry_rating=boundry_rating, train_user_items_dict=self.train_user_items_dict,\n",
    "                           train_user_items_rating_dict=self.train_user_items_rating_dict,\n",
    "                           nega_user_items_rating_dict=self.nega_user_items_rating_dict,\n",
    "                           user_label_list=self.user_label_list, data_shape=self.data_shape)\n",
    "\n",
    "        # Control training times parameter setting\n",
    "        MAX_STEPS = MEMORY_CAPACITY * 2  # Maximum training steps\n",
    "        MIN_STEPS = MEMORY_CAPACITY * 1  # Minimum training steps, greater than or equal to memory\n",
    "        once_show_num = 10\n",
    "        # The convergence stop indicator,\n",
    "        # stops when the percentage of the sub average value to the original value is less than or equal to this value\n",
    "        stop_line = 0.1\n",
    "        c_select_size = 50  # Number of randomly selected candidate set items, make sure select_size < len(c_items_list)\n",
    "        o_train_percent = 0.1  # Select the proportion of users in the training set to see in the training\n",
    "\n",
    "        # result_evaluate\n",
    "        total_hits, total_ndcgs, total_precisions, total_recalls = [], [], [], []\n",
    "        for _ in self.test_top_k:\n",
    "            total_hits.append([])\n",
    "            total_ndcgs.append([])\n",
    "            total_precisions.append([])\n",
    "            total_recalls.append([])\n",
    "        cluster_w = []\n",
    "        # t_sun = 0\n",
    "        for i in range(self.user_label_num + 1):\n",
    "            cluster_w.append(len(self.cluster_users[i]) / self.data_shape[0])\n",
    "            # t_sun += cluster_w[i]\n",
    "        # print(cluster_w, t_sun)\n",
    "\n",
    "        total_cluster_steps = 0\n",
    "        for i in range(self.user_label_num + 1):\n",
    "            # user_cluster\n",
    "            cluster_hits, cluster_ndcgs, cluster_precisions, cluster_recalls = [], [], [], []\n",
    "            for _ in self.test_top_k:\n",
    "                cluster_hits.append([])\n",
    "                cluster_ndcgs.append([])\n",
    "                cluster_precisions.append([])\n",
    "                cluster_recalls.append([])\n",
    "\n",
    "            config = tf.ConfigProto(allow_soft_placement=True)\n",
    "            config.gpu_options.allow_growth = True\n",
    "            with tf.Session(config=config) as o_sess:\n",
    "                # Each cluster corresponds to a graph\n",
    "                ddpg = DDPG(o_sess, s_dim, self.state_num, self.action_num, a_w_dim, BATCH_SIZE, MEMORY_CAPACITY)\n",
    "                # Create a saver.\n",
    "                cluster_saver = tf.train.Saver()\n",
    "                the_saver_path = './reinforce_log/' + self.the_data_name + '_ddpg_cluster' \\\n",
    "                                 + '/state' + str(self.state_num) \\\n",
    "                                 + '/action' + str(self.action_num) \\\n",
    "                                 + '/' + self.data_method + '/c' + str(i)\n",
    "                meta_path = the_saver_path + '/model.meta'\n",
    "                if self.is_use_history:\n",
    "                    if os.path.exists(meta_path) \\\n",
    "                            and os.path.exists(the_saver_path):\n",
    "                        cluster_saver = tf.train.import_meta_graph(meta_path)\n",
    "                        cluster_saver.restore(o_sess, tf.train.latest_checkpoint(the_saver_path))\n",
    "                        ddpg.set_mem(np.load(the_saver_path + '/memory.npy'))\n",
    "                        print('Filled with', the_saver_path)\n",
    "                explore_var = 1  # Initial value of exploration item\n",
    "                user_size = len(self.cluster_users[i])  # Transboundary control\n",
    "\n",
    "                # Initialize memory buffer\n",
    "                for ii in range(MEMORY_CAPACITY):\n",
    "                    user_id = self.cluster_users[i][int(ii % user_size)]\n",
    "                    s, emb_s = env.init_env(user_id=user_id)\n",
    "                    a_w = ddpg.choose_action_weight(emb_s)\n",
    "                    # add randomness to action selection for exploration\n",
    "                    a_w = np.random.normal(a_w, explore_var)\n",
    "                    s_, emb_s_, r = env.step(user_id=user_id,\n",
    "                                             in_state=s,\n",
    "                                             in_a_w=a_w,\n",
    "                                             select_size=c_select_size,\n",
    "                                             train_percent=o_train_percent)\n",
    "                    ddpg.store_transition(emb_s, a_w, r, emb_s_)\n",
    "                hit_list, ndcg_list, precision_list, recall_list = [], [], [], []\n",
    "                for epoch in range(self.epochs):\n",
    "                    str_cluster = 'Cluster:' + str(i)\n",
    "                    str_a_loss = 'A_Loss:'\n",
    "                    str_c_loss = 'C_Loss:'\n",
    "                    str_reward = 'Mean_Reward:'\n",
    "                    t_sum_steps = 0\n",
    "                    step_count = 1\n",
    "                    once_show_r = 0\n",
    "                    o_a_loss = 0\n",
    "                    o_td_error = 0\n",
    "\n",
    "                    # training\n",
    "                    ddpg.set_keep_rate(keep_rate=0.8)\n",
    "                    while True:\n",
    "                        user_id = self.cluster_users[i][random.randint(0, user_size - 1)]\n",
    "                        s, emb_s = env.init_env(user_id=user_id)\n",
    "                        # A certain number of training for each user\n",
    "                        for _ in range(self.one_u_steps):\n",
    "                            # print(s, s_emb, s_flag)\n",
    "                            a_w = ddpg.choose_action_weight(emb_s)\n",
    "                            # add randomness to action selection for exploration\n",
    "                            a_w = np.random.normal(a_w, explore_var)\n",
    "                            # print(a_w.shape)\n",
    "                            s_, emb_s_, r = env.step(user_id=user_id,\n",
    "                                                     in_state=s,\n",
    "                                                     in_a_w=a_w,\n",
    "                                                     select_size=c_select_size,\n",
    "                                                     train_percent=o_train_percent)\n",
    "                            ddpg.store_transition(emb_s, a_w, r, emb_s_)\n",
    "                            s = s_\n",
    "                            emb_s = emb_s_\n",
    "                            once_show_r += r\n",
    "                            # train\n",
    "                            t_a_loss, t_td_error = ddpg.learn()\n",
    "                            o_a_loss += t_a_loss\n",
    "                            o_td_error += t_td_error\n",
    "                            # print(o_a_loss, o_td_error)\n",
    "                        if step_count % once_show_num == 0:\n",
    "                            # print('State_flag:', s_flag)\n",
    "                            explore_var *= 0.9\n",
    "                            # print(explore_var)\n",
    "                            # print('State:', s)\n",
    "                            str_a_loss += str(o_a_loss / (once_show_num * self.one_u_steps)) + ' '\n",
    "                            new_c_loss = o_td_error / (once_show_num * self.one_u_steps)\n",
    "                            str_c_loss += str(new_c_loss) + ' '\n",
    "                            str_reward += str(once_show_r / (once_show_num * self.one_u_steps)) + ' '\n",
    "\n",
    "                            if step_count >= MIN_STEPS:\n",
    "                                # Take absolute value to prevent division by 0\n",
    "                                if np.abs(old_c_loss - new_c_loss) / (np.abs(old_c_loss) + 0.000001) < stop_line:\n",
    "                                    break\n",
    "                            old_c_loss = new_c_loss\n",
    "                            once_show_r = 0\n",
    "                            o_a_loss = 0\n",
    "                            o_td_error = 0\n",
    "                        # print(t_td_error)\n",
    "                        if step_count >= MAX_STEPS:\n",
    "                            break\n",
    "                        step_count += 1\n",
    "                    t_sum_steps += step_count\n",
    "                    str_steps = 'Steps:' + str(t_sum_steps * self.one_u_steps)\n",
    "                    str_train_log = str_cluster + '\\n' + str_a_loss + '\\n' + str_c_loss + '\\n' + str_reward + '\\n' \\\n",
    "                                    + str_steps\n",
    "                    print(str_train_log)\n",
    "                    reinforce_log.write(str_train_log + '\\n')\n",
    "                    reinforce_log.flush()\n",
    "                    total_cluster_steps += step_count\n",
    "\n",
    "                    # Test and use the parameters of the corresponding class before changing the cluster\n",
    "                    ddpg.set_keep_rate(keep_rate=1)\n",
    "                    for t_user_id in self.cluster_users[i]:\n",
    "                        try:\n",
    "                            self.test_dict[str(t_user_id) + '_p']\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        # Initialize test environment\n",
    "                        s, emb_s = env.init_test_env(t_user_id)\n",
    "                        # print(s)\n",
    "                        # test\n",
    "                        one_hit, one_ndcg, one_precision, one_recall = self.result_evaluate(\n",
    "                            user_id=t_user_id,\n",
    "                            top_k_list=self.test_top_k,\n",
    "                            the_model=ddpg,\n",
    "                            in_emb_s=emb_s)\n",
    "                        # print(t_user_id, one_hit, one_ndcg, one_precision, one_recall)\n",
    "                        kk = 0\n",
    "                        for _ in self.test_top_k:\n",
    "                            cluster_hits[kk].append(one_hit[kk])\n",
    "                            cluster_ndcgs[kk].append(one_ndcg[kk])\n",
    "                            cluster_precisions[kk].append(one_precision[kk])\n",
    "                            cluster_recalls[kk].append(one_recall[kk])\n",
    "                            kk += 1\n",
    "                    # print(len(cluster_hits))\n",
    "                    str_rate = 'Evaluate of cluster ' + str(i) + ', Epoch ' + str(epoch)\n",
    "                    kk = 0\n",
    "                    hit_t, ndcg_t, precision_t, recall_t = [], [], [], []\n",
    "                    for top_k in self.test_top_k:\n",
    "                        if len(cluster_hits) > 0:\n",
    "                            cluster_hit = np.array(cluster_hits[kk]).mean()\n",
    "                            cluster_ndcg = np.array(cluster_ndcgs[kk]).mean()\n",
    "                            cluster_precision = np.array(cluster_precisions[kk]).mean()\n",
    "                            cluster_recall = np.array(cluster_recalls[kk]).mean()\n",
    "                        else:\n",
    "                            cluster_hit = 0\n",
    "                            cluster_ndcg = 0\n",
    "                            cluster_precision = 0\n",
    "                            cluster_recall = 0\n",
    "                        cluster_f1 = 2 * cluster_precision * cluster_recall / (\n",
    "                                cluster_precision + cluster_recall + 0.000001)\n",
    "                        hit_t.append(cluster_hit)\n",
    "                        ndcg_t.append(cluster_ndcg)\n",
    "                        precision_t.append(cluster_precision)\n",
    "                        recall_t.append(cluster_recall)\n",
    "                        str_rate += '\\nTop ' + str(top_k) + \\\n",
    "                                    '. Hit_rate:' + str(cluster_hit) + \\\n",
    "                                    ' nDCG:' + str(cluster_ndcg) + \\\n",
    "                                    ' Precision:' + str(cluster_precision) + \\\n",
    "                                    ' Recall:' + str(cluster_recall) + \\\n",
    "                                    ' F1:' + str(cluster_f1) + \\\n",
    "                                    ' Total steps:' + str(total_cluster_steps)\n",
    "                        kk += 1\n",
    "                    hit_list.append(hit_t)\n",
    "                    ndcg_list.append(ndcg_t)\n",
    "                    precision_list.append(precision_t)\n",
    "                    recall_list.append(recall_t)\n",
    "                    print(str_rate)\n",
    "                    reinforce_log.write(str_rate + '\\n')\n",
    "                    reinforce_log.flush()\n",
    "                best_pos = 0\n",
    "                for ii in range(1, len(hit_list)):\n",
    "                    if hit_list[ii][0] > hit_list[best_pos][0]:\n",
    "                        best_pos = ii\n",
    "                kk = 0\n",
    "                for _ in self.test_top_k:\n",
    "                    total_hits[kk].append(hit_list[best_pos][kk] * cluster_w[i])\n",
    "                    total_ndcgs[kk].append(ndcg_list[best_pos][kk] * cluster_w[i])\n",
    "                    total_precisions[kk].append(precision_list[best_pos][kk] * cluster_w[i])\n",
    "                    total_recalls[kk].append(recall_list[best_pos][kk] * cluster_w[i])\n",
    "                    kk += 1\n",
    "                # Save model each class has its own model\n",
    "                if not os.path.exists(the_saver_path):\n",
    "                    os.makedirs(the_saver_path)\n",
    "                cluster_saver.save(o_sess, os.path.join(the_saver_path, 'model'))\n",
    "                np.save(the_saver_path + '/memory.npy', ddpg.memory)\n",
    "            # Clear variables previously defined in the default graph\n",
    "            tf.reset_default_graph()\n",
    "\n",
    "        str_log = 'ddpg_rec'\n",
    "        kk = 0\n",
    "        for top_k in self.test_top_k:\n",
    "            total_hr, total_ndcg, total_precision, total_recall = 0, 0, 0, 0\n",
    "            # print(total_hits)\n",
    "            for i in range(self.user_label_num + 1):\n",
    "                total_hr += total_hits[kk][i]\n",
    "                total_ndcg += total_ndcgs[kk][i]\n",
    "                total_precision += total_precisions[kk][i]\n",
    "                total_recall += total_recalls[kk][i]\n",
    "            total_f1 = 2 * total_precision * total_recall / (total_precision + total_recall + 0.000001)\n",
    "            str_log += '\\nTTop ' + str(top_k) + \\\n",
    "                       '. HR:' + str(total_hr) + \\\n",
    "                       ' nDCG:' + str(total_ndcg) + \\\n",
    "                       ' Precision:' + str(total_precision) + \\\n",
    "                       ' Recall:' + str(total_recall) + \\\n",
    "                       ' F1:' + str(total_f1)\n",
    "            kk += 1\n",
    "        str_steps = 'Total train steps:' + str(total_cluster_steps * self.one_u_steps)\n",
    "        end_time = time.process_time()\n",
    "        str_time = \"Cost time is %f\" % (end_time - start_time)\n",
    "        reinforce_log.write(str_log + '\\n' + str_steps + ' ' + str_time)\n",
    "        reinforce_log.flush()\n",
    "        reinforce_log.close()\n",
    "        print(str_log + '\\n' + str_steps + ' ' + str_time)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # glove mf\n",
    "    data_method = 'glove'\n",
    "    emb_size = 100\n",
    "    # 'Digital_Music' 'Beauty' 'Clothing_Shoes_and_Jewelry'\n",
    "    the_data_name = 'Digital_Music'\n",
    "    action_num = 10  # Number of items in the action\n",
    "    state_num = 20  # Number of items in the status\n",
    "    one_u_steps = 10  # Training times per user\n",
    "    test_top_k = [5, 10, 20]  # Top_k during test\n",
    "    str_alpha = '0.5'  # Proportion of product description\n",
    "    epochs = 3  # Number of training rounds\n",
    "\n",
    "    the_data_path = './Amazon/' + the_data_name + '/' + data_method + '/' + str(emb_size) + '/'\n",
    "    rl_model = RlProcess(the_data_path=the_data_path,\n",
    "                         the_data_name=the_data_name,\n",
    "                         data_method=data_method,\n",
    "                         epochs=epochs,\n",
    "                         state_num=state_num,\n",
    "                         action_num=action_num,\n",
    "                         one_u_steps=one_u_steps,\n",
    "                         test_top_k=test_top_k,\n",
    "                         is_use_history=False)\n",
    "    rl_model.runProcess()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DQN Rec System"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1be6c916519a21c4"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEMORY_CAPACITY: 100\n",
      "WARNING:tensorflow:From /Users/re378/anaconda3/envs/RL/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Cluster:0\n",
      "Loss:0.00011070719920098781 2.309335395693779e-05 2.620657905936241e-05 2.1950993686914445e-05 2.63274391181767e-05 1.9747219048440457e-05 1.875906134955585e-05 0.0005187612026929855 0.003822919726371765 0.011697660684585571 0.0237034010887146 0.01238896608352661 0.013219231367111206 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 -0.085 0.2 0.335 0.93 1.45 0.87 \n",
      "Steps:1300\n",
      "Evaluate of cluster 0, Epoch 0\n",
      "Top 5. Hit_rate:0.9730134932533733 nDCG:0.8471671636831104 Precision:0.22938530734632684 Recall:0.9632905159142041 F1:0.3705357339848524\n",
      "Top 10. Hit_rate:0.974512743628186 nDCG:0.8473045151081376 Precision:0.1184407796101949 Recall:0.9702081193835316 F1:0.21110957002824055\n",
      "Top 20. Hit_rate:0.9820089955022488 nDCG:0.8488835281452239 Precision:0.060269865067466274 Recall:0.9797958163775256 F1:0.11355456856804359\n",
      "Cluster:0\n",
      "Loss:0.01733853816986084 0.017665613889694214 0.022090327739715577 0.02659949064254761 0.016374568939208984 0.0219913387298584 0.022636480331420898 0.02002091646194458 0.023170676231384277 0.020792434215545653 0.023411793708801268 0.01933222770690918 0.021925487518310548 0.020627489089965822 \n",
      "Mean_Reward:1.63 0.93 2.07 0.81 1.58 1.35 1.02 1.45 1.34 1.67 1.01 0.83 1.34 1.92 \n",
      "Steps:1400\n",
      "Evaluate of cluster 0, Epoch 1\n",
      "Top 5. Hit_rate:0.974512743628186 nDCG:0.8610479868030371 Precision:0.22983508245877063 Recall:0.9645648787327946 F1:0.3712167951024109\n",
      "Top 10. Hit_rate:0.97976011994003 nDCG:0.8621562701589451 Precision:0.11934032983508246 Recall:0.9765620852577372 F1:0.21268889165606522\n",
      "Top 20. Hit_rate:0.9895052473763118 nDCG:0.86431895402709 Precision:0.06079460269865067 Recall:0.9883986578139502 F1:0.11454371410747344\n",
      "Cluster:0\n",
      "Loss:0.017448490858078 0.012230949401855469 0.019167940616607666 0.014281890392303466 0.015979771614074708 0.02533027172088623 0.020267953872680666 0.015399657487869263 0.019440550804138184 0.01600492000579834 0.02129937171936035 0.01519500494003296 0.01344322681427002 0.014635084867477418 \n",
      "Mean_Reward:0.99 0.71 1.44 1.4 1.21 1.23 1.74 1.68 1.05 1.66 1.52 1.5 1.08 1.51 \n",
      "Steps:1400\n",
      "Evaluate of cluster 0, Epoch 2\n",
      "Top 5. Hit_rate:0.9750124937531235 nDCG:0.8822098621084726 Precision:0.23078460769615194 Recall:0.9659304657805408 F1:0.3725560114844819\n",
      "Top 10. Hit_rate:0.9815092453773113 nDCG:0.8838410960081338 Precision:0.11959020489755125 Recall:0.9782358515491949 F1:0.2131254194144989\n",
      "Top 20. Hit_rate:0.991504247876062 nDCG:0.8858874643957861 Precision:0.06091954022988507 Recall:0.990599938126175 F1:0.11478025207220902\n",
      "Cluster:1\n",
      "Loss:6.576990708708763e-05 4.43718209862709e-05 2.859113272279501e-05 3.530466696247459e-05 3.110294695943594e-05 2.6529827155172826e-05 2.2884493228048085e-05 0.014665182828903198 0.019764124155044555 0.0052840131521224975 0.01125798225402832 0.009393003582954407 0.010547161102294922 0.004493596851825714 0.006093050241470337 0.0159851598739624 0.017296059131622313 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.42 0.785 0.31 0.72 0.68 0.64 0.55 0.55 1.16 0.96 \n",
      "Steps:1700\n",
      "Evaluate of cluster 1, Epoch 0\n",
      "Top 5. Hit_rate:0.9762174405436014 nDCG:0.8807684444067391 Precision:0.2620611551528879 Recall:0.9560646839944196 F1:0.4113650687868306\n",
      "Top 10. Hit_rate:0.9807474518686297 nDCG:0.8819218628476665 Precision:0.14156285390713477 Recall:0.9722432374064656 F1:0.24714069151211668\n",
      "Top 20. Hit_rate:0.9898074745186863 nDCG:0.8834126098783947 Precision:0.07429218573046434 Recall:0.9866828023975102 F1:0.1381799830213106\n",
      "Cluster:1\n",
      "Loss:0.017433991432189943 0.007914034128189086 0.01897871255874634 0.012056849002838134 0.012984951734542846 0.008122138381004333 0.012540653944015503 0.010432765483856202 0.016597487926483155 0.007147154808044434 0.009094899892807007 0.013569262027740479 0.016939826011657715 0.017307313680648802 \n",
      "Mean_Reward:0.645 0.38 1.32 0.8 0.8 0.79 1.01 0.38 0.82 0.56 0.55 0.93 1.12 1.2 \n",
      "Steps:1400\n",
      "Evaluate of cluster 1, Epoch 1\n",
      "Top 5. Hit_rate:0.9745186862967158 nDCG:0.8848441281749959 Precision:0.26115515288788227 Recall:0.9530712175921812 F1:0.40997174926952923\n",
      "Top 10. Hit_rate:0.9807474518686297 nDCG:0.8860532393485047 Precision:0.14150622876557192 Recall:0.9719312080614336 F1:0.24704431843447952\n",
      "Top 20. Hit_rate:0.9898074745186863 nDCG:0.8876318582458979 Precision:0.07426387315968291 Recall:0.986811493944723 F1:0.1381322700058161\n",
      "Cluster:1\n",
      "Loss:0.01869746804237366 0.017166650295257567 0.010136858224868775 0.01183294653892517 0.009787574410438538 0.008635376691818237 0.014433388710021972 0.007828084230422973 0.016326788663864136 0.015647919178009034 \n",
      "Mean_Reward:1.07 1.2 1.32 0.5 0.495 1.0 1.23 1.32 0.76 1.34 \n",
      "Steps:1000\n",
      "Evaluate of cluster 1, Epoch 2\n",
      "Top 5. Hit_rate:0.9713099282748207 nDCG:0.8888669288777661 Precision:0.2604001510003775 Recall:0.9492102403317875 F1:0.40868413059715775\n",
      "Top 10. Hit_rate:0.981124952812382 nDCG:0.8907699775487553 Precision:0.14171385428463573 Recall:0.9723972291743969 F1:0.24737575561367867\n",
      "Top 20. Hit_rate:0.9898074745186863 nDCG:0.8923295180904445 Precision:0.07416006040015101 Recall:0.9866969356469086 F1:0.13795155358563688\n",
      "Cluster:2\n",
      "Loss:0.00036992017179727555 4.429787397384644e-05 1.8977932631969453e-05 2.1380032412707804e-05 1.8780718091875316e-05 1.2356709921732545e-05 1.4023685362190007e-05 0.012233538627624512 0.007863775491714478 0.007913815379142762 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.675 0.64 0.75 \n",
      "Steps:1000\n",
      "Evaluate of cluster 2, Epoch 0\n",
      "Top 5. Hit_rate:0.8542654028436019 nDCG:0.7716345591528385 Precision:0.21066350710900475 Recall:0.8231852970066988 F1:0.33547445862569625\n",
      "Top 10. Hit_rate:0.8898104265402843 nDCG:0.7807234372124231 Precision:0.11350710900473936 Recall:0.8655663859400765 F1:0.20069553160053702\n",
      "Top 20. Hit_rate:0.943127962085308 nDCG:0.7920491107352785 Precision:0.061433649289099536 Recall:0.9263392868390997 F1:0.11522556080686444\n",
      "Cluster:2\n",
      "Loss:0.0105479097366333 0.009398936033248902 0.012142760753631592 0.008921432495117187 0.01883117198944092 0.009305443167686462 0.011389895677566528 0.01043199896812439 0.00900757074356079 0.017063417434692384 0.016072380542755126 \n",
      "Mean_Reward:0.82 0.9 1.38 0.93 0.95 0.72 0.66 0.57 0.68 1.0 0.91 \n",
      "Steps:1100\n",
      "Evaluate of cluster 2, Epoch 1\n",
      "Top 5. Hit_rate:0.8998815165876777 nDCG:0.8216934317061321 Precision:0.22452606635071093 Recall:0.8762956350556126 F1:0.35746212654950005\n",
      "Top 10. Hit_rate:0.9241706161137441 nDCG:0.8280182239485113 Precision:0.11978672985781992 Recall:0.9075656961141185 F1:0.211639585989205\n",
      "Top 20. Hit_rate:0.9591232227488151 nDCG:0.8355017071727857 Precision:0.06368483412322275 Recall:0.9482528032840611 F1:0.11935372413242679\n",
      "Cluster:2\n",
      "Loss:0.0075943881273269655 0.010712966918945313 0.010418365001678467 0.01530571937561035 0.01337501049041748 0.011922414302825928 0.007334094047546386 0.020434391498565675 0.011542611122131348 0.029740738868713378 0.015107131004333496 0.013628978729248047 \n",
      "Mean_Reward:0.73 0.63 1.48 1.46 0.68 0.86 0.88 1.52 0.99 1.53 0.92 1.5 \n",
      "Steps:1200\n",
      "Evaluate of cluster 2, Epoch 2\n",
      "Top 5. Hit_rate:0.9146919431279621 nDCG:0.8400575077868301 Precision:0.22890995260663505 Recall:0.8937602335581882 F1:0.3644711207106072\n",
      "Top 10. Hit_rate:0.9364139020537124 nDCG:0.8456702093772143 Precision:0.12199842022116902 Recall:0.922722089959088 F1:0.21550362691156064\n",
      "Top 20. Hit_rate:0.9632701421800948 nDCG:0.8515618221280149 Precision:0.06433649289099526 Recall:0.9543844846569965 F1:0.12054662992586397\n",
      "Cluster:3\n",
      "Loss:0.00026261890307068827 4.2336052283644674e-05 5.9958104975521566e-05 3.249299479648471e-05 2.381187863647938e-05 2.018535742536187e-05 2.33670836314559e-05 0.019927194118499757 0.01170781373977661 0.01652951955795288 0.012677375078201294 0.01460662841796875 0.011138429641723633 0.01892019748687744 0.014753669500350952 0.01713801622390747 0.013355000019073486 0.014792701005935669 0.02044551134109497 0.023803200721740723 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.28 1.24 1.29 1.24 1.41 1.97 1.18 1.66 1.4 1.18 1.24 1.39 1.46 \n",
      "Steps:2000\n",
      "Evaluate of cluster 3, Epoch 0\n",
      "Top 5. Hit_rate:0.7682926829268293 nDCG:0.7476357125266128 Precision:0.16829268292682922 Recall:0.7591463414634146 F1:0.27550843435501143\n",
      "Top 10. Hit_rate:0.8292682926829268 nDCG:0.7665863056416702 Precision:0.09146341463414633 Recall:0.8211382113821137 F1:0.1645932250434822\n",
      "Top 20. Hit_rate:0.9207317073170732 nDCG:0.7884759792618011 Precision:0.05091463414634146 Recall:0.9136178861788616 F1:0.09645392190966472\n",
      "Cluster:3\n",
      "Loss:0.016876862049102784 0.01407122254371643 0.017811329364776612 0.019937102794647218 0.019362485408782958 0.018880237340927124 0.017237313985824586 0.020606322288513182 0.01996464729309082 0.018492947816848754 \n",
      "Mean_Reward:1.36 1.415 1.47 1.39 1.11 1.35 1.645 1.09 1.26 1.71 \n",
      "Steps:1000\n",
      "Evaluate of cluster 3, Epoch 1\n",
      "Top 5. Hit_rate:0.7621951219512195 nDCG:0.7461351461968587 Precision:0.1670731707317073 Recall:0.7510162601626017 F1:0.27333836326822436\n",
      "Top 10. Hit_rate:0.8201219512195121 nDCG:0.7632346160774199 Precision:0.09085365853658536 Recall:0.8109756097560976 F1:0.16340126012795841\n",
      "Top 20. Hit_rate:0.9115853658536586 nDCG:0.7840439216375371 Precision:0.05060975609756097 Recall:0.9054878048780488 F1:0.09586149132456014\n",
      "Cluster:3\n",
      "Loss:0.015123361349105835 0.025604236125946044 0.014950754642486573 0.016577502489089967 0.016516164541244507 0.027751398086547852 0.022953784465789794 0.015779664516448976 0.025128626823425294 0.022027711868286132 0.01551041603088379 0.022406153678894043 0.027373714447021483 0.02132606029510498 0.01844192385673523 0.016262733936309816 0.01414830207824707 0.021529412269592284 0.02330519437789917 \n",
      "Mean_Reward:1.38 1.49 1.26 1.34 1.3 1.5 1.41 1.21 1.36 1.52 1.4 1.24 1.18 1.13 1.54 1.54 1.37 1.65 1.33 \n",
      "Steps:1900\n",
      "Evaluate of cluster 3, Epoch 2\n",
      "Top 5. Hit_rate:0.7601626016260162 nDCG:0.7447900612299029 Precision:0.16666666666666666 Recall:0.7483062330623306 F1:0.2726147828857809\n",
      "Top 10. Hit_rate:0.8170731707317073 nDCG:0.7611665496366543 Precision:0.09065040650406504 Recall:0.8075880758807588 F1:0.1630037173873919\n",
      "Top 20. Hit_rate:0.9105691056910569 nDCG:0.7826232683167499 Precision:0.05060975609756097 Recall:0.9048102981029811 F1:0.09585769185266783\n",
      "Cluster:4\n",
      "Loss:0.00018133021891117096 4.4204173609614375e-05 6.0928347520530226e-05 3.5226806066930296e-05 1.1353669688105583e-05 1.056782901287079e-05 1.7328414833173157e-05 0.008739572167396546 0.00994822859764099 0.01154152512550354 0.019095420837402344 0.014187271595001221 0.021233911514282226 0.014882446527481078 0.019222537279129027 0.012774693965911865 0.019756669998168944 0.01640345811843872 0.012939472198486329 0.021145682334899902 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.485 0.64 0.435 0.96 0.61 1.05 0.78 1.4 0.76 1.235 0.84 1.375 1.76 \n",
      "Steps:2000\n",
      "Evaluate of cluster 4, Epoch 0\n",
      "Top 5. Hit_rate:0.7570621468926554 nDCG:0.6405966176872232 Precision:0.19924670433145011 Recall:0.7139082346709464 F1:0.31154342183585415\n",
      "Top 10. Hit_rate:0.8229755178907722 nDCG:0.6583801368915911 Precision:0.1143126177024482 Recall:0.7941353489376088 F1:0.199856445173488\n",
      "Top 20. Hit_rate:0.9001883239171374 nDCG:0.674300276571147 Precision:0.06497175141242938 Recall:0.8856785264977356 F1:0.12106244717082354\n",
      "Cluster:4\n",
      "Loss:0.023350906372070313 0.017831900119781495 0.027619574069976807 0.019201884269714354 0.025501410961151123 0.02541354179382324 0.014383963346481322 0.026755838394165038 0.01943673372268677 0.014828002452850342 0.017964258193969726 0.02347459316253662 0.01632420063018799 0.013890738487243653 0.015620859861373902 0.019442830085754394 0.01733349561691284 0.015102020502090453 0.008432543873786925 0.014831035137176514 \n",
      "Mean_Reward:1.48 0.79 1.09 1.23 1.23 1.55 1.15 1.6 0.59 1.61 1.38 1.59 0.675 0.86 1.06 1.23 1.12 0.83 0.91 1.18 \n",
      "Steps:2000\n",
      "Evaluate of cluster 4, Epoch 1\n",
      "Top 5. Hit_rate:0.731638418079096 nDCG:0.6236213524130482 Precision:0.19058380414312617 Recall:0.6832655762740508 F1:0.2980358095265395\n",
      "Top 10. Hit_rate:0.8013182674199624 nDCG:0.6422881216978242 Precision:0.11101694915254237 Recall:0.7699020623455652 F1:0.19405207508568156\n",
      "Top 20. Hit_rate:0.8983050847457628 nDCG:0.6630336387760006 Precision:0.06440677966101696 Recall:0.8826959030348861 F1:0.1200535940745661\n",
      "Cluster:4\n",
      "Loss:0.016683868169784545 0.01883739709854126 0.013893367052078246 0.019036296606063843 0.01494817852973938 0.015357373952865601 0.017300899028778075 0.021243948936462403 0.010451868772506714 0.014607863426208496 0.015880730152130127 \n",
      "Mean_Reward:1.73 0.69 0.75 0.87 1.31 1.49 1.69 1.17 0.835 0.93 0.99 \n",
      "Steps:1100\n",
      "Evaluate of cluster 4, Epoch 2\n",
      "Top 5. Hit_rate:0.7325800376647834 nDCG:0.6302400554423512 Precision:0.19158819836785934 Recall:0.6854029874274695 F1:0.2994670320764376\n",
      "Top 10. Hit_rate:0.7972379158819837 nDCG:0.6478938529880732 Precision:0.11054613935969869 Recall:0.7660640524105684 F1:0.1932109110430515\n",
      "Top 20. Hit_rate:0.8995605775266792 nDCG:0.6702477375949287 Precision:0.0645323289391086 Recall:0.8844017024337176 F1:0.12028747951942168\n",
      "Cluster:5\n",
      "Loss:0.0005084509402513504 9.021369740366936e-05 3.284629434347153e-05 3.248438239097595e-05 2.173955086618662e-05 1.5804034192115068e-05 9.500671876594424e-06 0.017052565813064576 0.011691969633102418 0.01931326389312744 0.018502750396728516 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.2 2.25 2.01 2.05 \n",
      "Steps:1100\n",
      "Evaluate of cluster 5, Epoch 0\n",
      "Top 5. Hit_rate:0.9251336898395722 nDCG:0.8980929074358586 Precision:0.18930481283422454 Recall:0.9251336898395722 F1:0.3142965761381092\n",
      "Top 10. Hit_rate:0.9251336898395722 nDCG:0.8980929074358586 Precision:0.09465240641711227 Recall:0.9251336898395722 F1:0.17173414004214294\n",
      "Top 20. Hit_rate:0.9518716577540107 nDCG:0.9047973231474716 Precision:0.048663101604278065 Recall:0.9518716577540107 F1:0.09259244712098012\n",
      "Cluster:5\n",
      "Loss:0.019446847438812257 0.019817277193069457 0.014861493110656739 0.01972914695739746 0.013780049085617065 0.020919866561889648 0.02395885229110718 0.013617939949035644 0.017337133884429933 0.01060554027557373 0.01505652666091919 0.020873982906341553 0.025028932094573974 0.023446741104125975 \n",
      "Mean_Reward:2.07 2.43 2.15 1.91 2.08 1.68 1.61 2.32 1.59 2.28 2.13 2.01 2.305 2.27 \n",
      "Steps:1400\n",
      "Evaluate of cluster 5, Epoch 1\n",
      "Top 5. Hit_rate:0.9251336898395722 nDCG:0.8768879597524952 Precision:0.18930481283422454 Recall:0.9251336898395722 F1:0.3142965761381092\n",
      "Top 10. Hit_rate:0.93048128342246 nDCG:0.8786704909467912 Precision:0.09518716577540105 Recall:0.93048128342246 F1:0.1727064723343548\n",
      "Top 20. Hit_rate:0.9491978609625669 nDCG:0.883270792723791 Precision:0.048529411764705876 Recall:0.9491978609625669 F1:0.0923377939665181\n",
      "Cluster:5\n",
      "Loss:0.018676145076751707 0.020666348934173583 0.015035734176635743 0.019775137901306153 0.020388588905334473 0.013290719985961914 0.014280569553375245 0.02530679225921631 0.03837360382080078 0.017152304649353026 0.031090946197509767 0.02119702339172363 0.01960362195968628 \n",
      "Mean_Reward:1.9 1.935 1.88 1.88 1.95 1.95 2.24 2.29 1.89 2.015 1.86 2.06 2.26 \n",
      "Steps:1300\n",
      "Evaluate of cluster 5, Epoch 2\n",
      "Top 5. Hit_rate:0.9233511586452763 nDCG:0.8824138625432761 Precision:0.1889483065953654 Recall:0.9233511586452763 F1:0.3137023552015662\n",
      "Top 10. Hit_rate:0.9340463458110517 nDCG:0.8858061798106415 Precision:0.09554367201426024 Recall:0.9340463458110517 F1:0.17335469359238512\n",
      "Top 20. Hit_rate:0.946524064171123 nDCG:0.888873047661975 Precision:0.04839572192513369 Recall:0.946524064171123 F1:0.09208314077909165\n",
      "Cluster:6\n",
      "Loss:0.00030927665531635287 6.090058945119381e-05 3.433326724916697e-05 3.4107428509742023e-05 1.552812522277236e-05 2.2791880182921888e-05 1.666177762672305e-05 0.017788727283477784 0.017339630126953123 0.015980689525604247 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.43 0.845 1.75 \n",
      "Steps:1000\n",
      "Evaluate of cluster 6, Epoch 0\n",
      "Top 5. Hit_rate:0.972027972027972 nDCG:0.8476661123011537 Precision:0.23170163170163172 Recall:0.9609959484959485 F1:0.37337904651195675\n",
      "Top 10. Hit_rate:0.9976689976689976 nDCG:0.8548491431831414 Precision:0.12354312354312358 Recall:0.9958236208236207 F1:0.21981544712845538\n",
      "Top 20. Hit_rate:1.0 nDCG:0.8554690966335493 Precision:0.06247086247086248 Recall:0.9989801864801865 F1:0.11758826769874807\n",
      "Cluster:6\n",
      "Loss:0.014003188610076904 0.007732247710227966 0.029106178283691407 0.029941351413726808 0.020497024059295654 0.025340633392333986 0.022997465133666992 0.011635696887969971 0.014783049821853638 0.022697081565856935 0.020611963272094726 \n",
      "Mean_Reward:1.18 2.11 1.38 1.72 1.16 1.8 1.55 1.73 1.21 1.33 1.27 \n",
      "Steps:1100\n",
      "Evaluate of cluster 6, Epoch 1\n",
      "Top 5. Hit_rate:0.9638694638694638 nDCG:0.8717094207312286 Precision:0.23123543123543125 Recall:0.9547521922521922 F1:0.3723012692131662\n",
      "Top 10. Hit_rate:0.9918414918414918 nDCG:0.8798735650337149 Precision:0.12272727272727274 Recall:0.9896353646353647 F1:0.21837328229125355\n",
      "Top 20. Hit_rate:0.9965034965034965 nDCG:0.881046417005977 Precision:0.06223776223776224 Recall:0.9953865578865579 F1:0.11715043266385883\n",
      "Cluster:6\n",
      "Loss:0.01630958080291748 0.02135305166244507 0.007376413345336914 0.015276460647583008 0.021462390422821043 0.027686729431152343 0.021451377868652345 0.022184691429138183 0.01643776535987854 0.03271924257278443 0.017924914360046385 0.02209524393081665 0.013732614517211915 0.021893692016601563 0.0315357494354248 0.012789283990859985 0.020967528820037842 0.02050114393234253 \n",
      "Mean_Reward:1.84 2.07 2.17 1.92 1.1 1.72 2.01 1.54 1.68 1.87 1.6 1.35 1.6 2.16 1.7 1.86 1.81 1.55 \n",
      "Steps:1800\n",
      "Evaluate of cluster 6, Epoch 2\n",
      "Top 5. Hit_rate:0.9665889665889665 nDCG:0.8725299289109069 Precision:0.23154623154623155 Recall:0.9571571946571946 F1:0.37288687841111606\n",
      "Top 10. Hit_rate:0.98989898989899 nDCG:0.8792324814663426 Precision:0.12229992229992229 Recall:0.9874592999592999 F1:0.21764376346722036\n",
      "Top 20. Hit_rate:0.9953379953379954 nDCG:0.8805745119142173 Precision:0.06216006216006216 Recall:0.9941886816886816 F1:0.11700448759979541\n",
      "Cluster:7\n",
      "Loss:6.965706124901771e-05 1.933900057338178e-05 3.338034264743328e-05 1.2924221809953451e-05 1.2155976146459579e-05 1.2643857626244426e-05 6.445011822506786e-06 0.0018217141926288604 0.0010629665851593017 0.0017811912298202515 0.001441110372543335 0.0013916304707527161 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.05 0.21 0.19 0.23 0.175 \n",
      "Steps:1200\n",
      "Evaluate of cluster 7, Epoch 0\n",
      "Top 5. Hit_rate:0.7291666666666666 nDCG:0.5588135474538805 Precision:0.1701388888888889 Recall:0.7023364222582972 F1:0.27392087781066526\n",
      "Top 10. Hit_rate:0.8194444444444444 nDCG:0.5873735887280098 Precision:0.09965277777777777 Recall:0.7962010356541607 F1:0.17713505287429843\n",
      "Top 20. Hit_rate:0.8784722222222222 nDCG:0.6019793489267509 Precision:0.05451388888888889 Recall:0.856790186087061 F1:0.1025056620181186\n",
      "Cluster:7\n",
      "Loss:0.0015869426727294922 0.007024989128112793 0.004859762787818908 0.0059753811359405514 0.0029452532529830933 0.000654919147491455 0.003814448118209839 0.006588019728660584 0.005658403635025024 0.004450707137584687 0.00878176987171173 0.01084681749343872 0.004775000214576722 0.0034432709217071533 0.005230295062065124 0.006690381169319153 0.00482566624879837 0.0025987753272056578 0.008505924344062806 0.003066115379333496 \n",
      "Mean_Reward:0.215 0.405 0.225 0.445 0.15 0.095 0.405 0.55 0.18 0.54 0.36 0.21 0.355 0.245 0.305 0.31 0.515 0.205 0.61 0.645 \n",
      "Steps:2000\n",
      "Evaluate of cluster 7, Epoch 1\n",
      "Top 5. Hit_rate:0.6770833333333334 nDCG:0.5137454447971161 Precision:0.1565972222222222 Recall:0.644517346079846 F1:0.25197269923004684\n",
      "Top 10. Hit_rate:0.7552083333333334 nDCG:0.5379103879391922 Precision:0.09236111111111112 Recall:0.7300940957190957 F1:0.16397785398487183\n",
      "Top 20. Hit_rate:0.8142361111111112 nDCG:0.5517064611723675 Precision:0.051388888888888894 Recall:0.7955074367183743 F1:0.09654120290554084\n",
      "Cluster:7\n",
      "Loss:0.00467609703540802 0.001878189742565155 0.004308657646179199 0.006181593537330627 0.0027716952562332154 0.003936062455177307 0.008238574266433716 0.005081990957260132 0.003674103617668152 0.0018597425520420075 0.009026381969451904 0.002474111616611481 0.003989831507205963 0.004856369495391846 0.004973205924034119 \n",
      "Mean_Reward:0.11 0.27 0.64 0.615 0.315 0.65 0.885 0.365 0.365 0.36 0.64 0.23 0.665 0.39 0.425 \n",
      "Steps:1500\n",
      "Evaluate of cluster 7, Epoch 2\n",
      "Top 5. Hit_rate:0.7025462962962963 nDCG:0.5275143112177411 Precision:0.1615740740740741 Recall:0.6705673425725509 F1:0.2604032562529074\n",
      "Top 10. Hit_rate:0.7800925925925926 nDCG:0.5513294402372169 Precision:0.09560185185185187 Recall:0.7571058426527175 F1:0.16976658282465468\n",
      "Top 20. Hit_rate:0.8414351851851852 nDCG:0.5656555690783639 Precision:0.05324074074074074 Recall:0.8248821924603175 F1:0.10002537748934834\n",
      "Cluster:8\n",
      "Loss:0.00016733758151531218 3.1560584902763365e-05 2.271059900522232e-05 2.4254294112324713e-05 1.7794515006244183e-05 2.2341087460517885e-05 1.118999207392335e-05 0.01994709491729736 0.016595451831817626 0.01951340913772583 0.008609554171562195 0.01644765615463257 0.0117351233959198 0.010005800724029542 0.013460485935211182 0.015252282619476318 0.012090911865234375 0.012624113559722901 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.825 1.23 1.29 1.7 1.81 1.37 1.68 1.835 1.62 1.56 1.84 \n",
      "Steps:1800\n",
      "Evaluate of cluster 8, Epoch 0\n",
      "Top 5. Hit_rate:0.9397363465160076 nDCG:0.7692506502607588 Precision:0.2346516007532957 Recall:0.9052722962327483 F1:0.37269752417948426\n",
      "Top 10. Hit_rate:0.9736346516007532 nDCG:0.7781302226414396 Precision:0.13069679849340868 Recall:0.9601232310271859 F1:0.23007446512018576\n",
      "Top 20. Hit_rate:0.9849340866290018 nDCG:0.7805004535478737 Precision:0.06854990583804144 Recall:0.9768792412860209 F1:0.1281099080402687\n",
      "Cluster:8\n",
      "Loss:0.01717877507209778 0.016713788509368898 0.012438459396362305 0.013051481246948242 0.008522584438323974 0.016585052013397217 0.007872129082679749 0.007337616086006165 0.013737025260925293 0.010974160432815551 0.011744554042816163 \n",
      "Mean_Reward:1.42 1.705 1.88 1.41 1.97 1.61 1.79 1.525 1.45 1.86 1.29 \n",
      "Steps:1100\n",
      "Evaluate of cluster 8, Epoch 1\n",
      "Top 5. Hit_rate:0.9491525423728814 nDCG:0.7997400884857047 Precision:0.23992467043314503 Recall:0.9191731474217351 F1:0.3805237501221698\n",
      "Top 10. Hit_rate:0.9774011299435028 nDCG:0.8061531250640595 Precision:0.13210922787193974 Recall:0.9663737340291012 F1:0.23244196959847638\n",
      "Top 20. Hit_rate:0.9896421845574388 nDCG:0.8088320732306208 Precision:0.06935028248587571 Recall:0.9837493381278691 F1:0.1295665260451572\n",
      "Cluster:8\n",
      "Loss:0.014365870952606202 0.00989559769630432 0.01659407138824463 0.01939782381057739 0.017915476560592652 0.007257109880447388 0.006384562253952026 0.010366905927658081 0.009744155406951904 0.010062956809997558 \n",
      "Mean_Reward:1.47 1.49 1.69 1.575 1.17 1.81 1.77 2.075 1.86 1.445 \n",
      "Steps:1000\n",
      "Evaluate of cluster 8, Epoch 2\n",
      "Top 5. Hit_rate:0.9560577526679221 nDCG:0.8200834339361942 Precision:0.24281230382925298 Recall:0.9280335901804827 F1:0.3849145011453259\n",
      "Top 10. Hit_rate:0.9811676082862524 nDCG:0.8252138386279831 Precision:0.1330194601381042 Recall:0.9712890687466958 F1:0.23399299595504164\n",
      "Top 20. Hit_rate:0.9918392969240427 nDCG:0.8273531003250405 Precision:0.06977401129943503 Recall:0.9873332254688187 F1:0.13033707852050644\n",
      "Cluster:9\n",
      "Loss:4.5595895498991014e-05 1.5478533459827303e-05 3.027050755918026e-05 2.4726535193622113e-05 1.3796722050756216e-05 1.793680596165359e-05 1.2696536723524332e-05 0.010684061050415038 0.013973848819732666 0.012869741916656494 \n",
      "Mean_Reward:0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.44 1.44 1.5 \n",
      "Steps:1000\n",
      "Evaluate of cluster 9, Epoch 0\n",
      "Top 5. Hit_rate:0.36363636363636365 nDCG:0.32391424802247376 Precision:0.07975206611570249 Recall:0.3338927171313535 F1:0.12875090297394334\n",
      "Top 10. Hit_rate:0.42355371900826444 nDCG:0.3421799718253963 Precision:0.046900826446281 Recall:0.3929159855296219 F1:0.08379871821245796\n",
      "Top 20. Hit_rate:0.5010330578512396 nDCG:0.3587359961758492 Precision:0.02846074380165289 Recall:0.471481264947174 F1:0.053680948644617824\n",
      "Cluster:9\n",
      "Loss:0.015476093292236329 0.012552964687347411 0.01679694414138794 0.017818567752838136 0.022595012187957765 0.02500086784362793 0.026166820526123048 0.011809099912643433 0.014469566345214844 0.01802043557167053 0.012046904563903808 0.041617965698242186 0.01693273901939392 0.024500789642333983 0.014627997875213622 0.013174458742141723 \n",
      "Mean_Reward:0.95 0.73 1.0 0.92 1.16 1.22 1.23 2.12 0.87 1.21 0.89 1.34 1.81 1.1 1.02 1.1 \n",
      "Steps:1600\n",
      "Evaluate of cluster 9, Epoch 1\n",
      "Top 5. Hit_rate:0.5020661157024794 nDCG:0.4274515741131501 Precision:0.1115702479338843 Recall:0.4701632647655375 F1:0.18034423220270338\n",
      "Top 10. Hit_rate:0.574896694214876 nDCG:0.44892414659612145 Precision:0.0652892561983471 Recall:0.5465564265280174 F1:0.11664445870469753\n",
      "Top 20. Hit_rate:0.6539256198347108 nDCG:0.46602945456236444 Precision:0.03806818181818182 Recall:0.6306822911936548 F1:0.07180224373200772\n",
      "Cluster:9\n",
      "Loss:0.018062708377838136 0.015541436672210694 0.016979655027389528 0.020111899375915527 0.017100327014923096 0.03256618022918701 0.021333544254302977 0.02086493492126465 0.020481767654418944 0.017292211055755614 0.016163668632507323 \n",
      "Mean_Reward:1.315 1.815 0.665 0.79 1.0 1.275 1.61 1.43 1.87 0.8 1.13 \n",
      "Steps:1100\n",
      "Evaluate of cluster 9, Epoch 2\n",
      "Top 5. Hit_rate:0.5564738292011019 nDCG:0.4814045981818673 Precision:0.12479338842975207 Recall:0.5260411621207076 F1:0.20172978878933576\n",
      "Top 10. Hit_rate:0.6277548209366391 nDCG:0.5022392219244711 Precision:0.071866391184573 Recall:0.6004311029879212 F1:0.12836802967951677\n",
      "Top 20. Hit_rate:0.7107438016528925 nDCG:0.5199596676317876 Precision:0.041632231404958676 Recall:0.6903059377491196 F1:0.07852831970668478\n",
      "dqn_rec\n",
      "TTop 5. HR:0.8480878692713378 nDCG:0.7520713211840957 Precision:0.20847926184627097 Recall:0.8257491629305469 F1:0.33290790579679386\n",
      "TTop 10. HR:0.8829322698419135 nDCG:0.7618527836683948 Precision:0.11339878441795509 Recall:0.8688948342245179 F1:0.20061520468120086\n",
      "TTop 20. HR:0.9197867837186796 nDCG:0.7698176324690619 Precision:0.060487341659206176 Recall:0.9109255874622046 F1:0.11344178950527059\n",
      "Total train steps:41500 Cost time is 483.287736\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8 -*- DQN model\n",
    "# A method that replaces DDPG in TDDPG-Rec with DQN, while retains other components the same as that in TDDPG-Rec.\n",
    "# Select the normalized item vector with the max Q-value as policy vector\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from env import RecommendENV\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "def feature_normalize(data):\n",
    "    max_d = np.max(data)\n",
    "    min_d = np.min(data)\n",
    "    return (data - min_d)/(max_d - min_d)\n",
    "\n",
    "\n",
    "#  DQN\n",
    "#  hyper parameters\n",
    "LR = 0.0002  # learning rate\n",
    "GAMMA = 0.9  # reward discount\n",
    "TAU = 0.01  # soft replacement\n",
    "\n",
    "\n",
    "def initialize(in_num, out_num, constant=1):\n",
    "    low = -constant * np.sqrt(6.0 / (in_num + out_num))\n",
    "    high = constant * np.sqrt(6.0 / (in_num + out_num))\n",
    "    return tf.random_uniform((in_num, out_num), minval=low, maxval=high, dtype=tf.float32)\n",
    "\n",
    "\n",
    "class DQN(object):\n",
    "    def __init__(self, sess, item_vector, r_s_dim, r_s_num, batch_size, MEMORY_CAPACITY):\n",
    "        self.sess = sess\n",
    "        self.item_vector = item_vector\n",
    "\n",
    "        self.s_dim = r_s_dim\n",
    "        self.s_num = r_s_num\n",
    "        self.i_dim = self.s_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.MEMORY_CAPACITY = MEMORY_CAPACITY\n",
    "        self.memory = np.zeros((MEMORY_CAPACITY, self.s_dim * (self.s_num * 2) + self.i_dim + 2), dtype=np.float32)\n",
    "        self.pointer = 0\n",
    "\n",
    "        self.keep_rate = 1\n",
    "\n",
    "        self.S = tf.placeholder(tf.float32, [None, self.s_num * self.s_dim], 's')\n",
    "        self.S_ = tf.placeholder(tf.float32, [None, self.s_num * self.s_dim], 's_')\n",
    "        self.item = tf.placeholder(tf.float32, [None, self.i_dim], 'item')\n",
    "        self.R = tf.placeholder(tf.float32, [None, 1], 'r')\n",
    "\n",
    "        self.q = self._build_net(self.S, self.item, scope='eval')\n",
    "        self.q_ = self._build_net(self.S_, self.item, scope='target')\n",
    "        self.ae_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='eval')\n",
    "        self.at_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='target')\n",
    "\n",
    "        q_target = self.R + GAMMA * self.q_\n",
    "        self.td_error = tf.losses.mean_squared_error(labels=q_target, predictions=self.q)\n",
    "        self.train = tf.train.AdamOptimizer(LR).minimize(self.td_error, var_list=self.ae_params)\n",
    "\n",
    "        # target net replacement\n",
    "        self.soft_replace = [[tf.assign(ta, (1 - TAU) * ta + TAU * ea)] for ta, ea in zip(self.at_params, self.ae_params)]\n",
    "\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def _build_net(self, i_s, i_i, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            n_l1 = 100\n",
    "            self.w1_s = tf.Variable(name='w1_s', initial_value=initialize(self.s_dim * self.s_num, n_l1))\n",
    "            self.w1_i = tf.Variable(name='w1_i', initial_value=initialize(self.i_dim, n_l1))\n",
    "            self.b1 = tf.Variable(name='b1', initial_value=tf.zeros([n_l1]))\n",
    "            layer = tf.nn.relu(\n",
    "                tf.nn.dropout((tf.matmul(i_s, self.w1_s) + tf.matmul(i_i, self.w1_i) + self.b1), rate=1 - self.keep_rate))\n",
    "            # Q(s,a)\n",
    "            self.w2 = tf.Variable(name='w2', initial_value=initialize(n_l1, 1))\n",
    "            self.b2 = tf.Variable(name='b2', initial_value=tf.zeros([1]))\n",
    "            q_value = tf.matmul(layer, self.w2) + self.b2\n",
    "            return q_value\n",
    "\n",
    "    def choose_action(self, i_emb_s, c_list):\n",
    "        item = np.zeros((len(c_list), self.i_dim))\n",
    "        i = 0\n",
    "        for c_item in c_list:\n",
    "            item[i] = feature_normalize(self.item_vector[c_item])\n",
    "            i += 1\n",
    "        i_emb_s = np.tile(i_emb_s, [len(c_list), 1])\n",
    "        q_ = self.sess.run(self.q, {self.S: i_emb_s, self.item: item})\n",
    "        max_index = np.argmax(q_)\n",
    "        # print(max_index, c_list, q_)\n",
    "        return c_list[max_index]\n",
    "\n",
    "    def learn(self):\n",
    "        # soft target replacement\n",
    "        self.sess.run(self.soft_replace)\n",
    "\n",
    "        indices = np.random.choice(self.MEMORY_CAPACITY, size=self.batch_size)\n",
    "        bt = self.memory[indices, :]\n",
    "        bs = bt[:, :self.s_dim * self.s_num]\n",
    "        bi = bt[:, self.s_dim * self.s_num: self.s_dim * self.s_num + self.i_dim]\n",
    "        br = bt[:, -(self.s_dim * self.s_num) - 1: -(self.s_dim * self.s_num)]\n",
    "        bs_ = bt[:, -(self.s_dim * self.s_num):]\n",
    "\n",
    "        _, it_td_error = self.sess.run([self.train, self.td_error],\n",
    "                                       feed_dict={self.S: bs, self.item: bi, self.R: br, self.S_: bs_})\n",
    "        return it_td_error\n",
    "\n",
    "    def store_transition(self, i_s, i_i, i_a, i_r, i_s_):\n",
    "        index = self.pointer % self.MEMORY_CAPACITY  # replace the old memory with new memory\n",
    "\n",
    "        # Reshape i_s and i_i if needed\n",
    "        if i_s.ndim == 2:\n",
    "            i_s = i_s[0]  # Assuming it's shape (1, 1000), convert to (1000,)\n",
    "        if i_i.ndim == 2:\n",
    "            i_i = i_i[0]  # Assuming it's shape (1, 100), convert to (100,)\n",
    "\n",
    "        transition = np.hstack((i_s, i_i, i_a, i_r, i_s_[0]))\n",
    "        self.memory[index, :] = transition\n",
    "        self.pointer += 1\n",
    "\n",
    "    def set_keep_rate(self, keep_rate):\n",
    "        self.keep_rate = keep_rate\n",
    "\n",
    "\n",
    "class RlProcess:\n",
    "    def __init__(self, the_data_path, the_data_name, data_method, epochs, state_num, action_num, one_u_steps,\n",
    "                 test_top_k: list, is_use_history=True):\n",
    "        self.the_data_path = the_data_path\n",
    "        self.the_data_name = the_data_name\n",
    "        self.data_method = data_method\n",
    "        self.epochs = epochs\n",
    "        self.state_num = state_num\n",
    "        self.a_num = action_num\n",
    "        self.one_u_steps = one_u_steps\n",
    "        self.test_top_k = sorted(test_top_k)\n",
    "        self.is_use_history = is_use_history\n",
    "        self.item_vector = np.load(self.the_data_path + self.the_data_name + \"_embeddings.npy\")\n",
    "        self.user_label_list, self.user_label_num = None, None\n",
    "        self.cluster_items, self.cluster_users = None, None\n",
    "        self.train_user_items_dict, self.train_user_items_rating_dict = None, None\n",
    "        self.test_user_items_rating_dict = None\n",
    "        self.nega_user_items_rating_dict = None\n",
    "        self.supp_nega_cluster_items = None\n",
    "        self.old_user2new, self.old_item2new = None, None\n",
    "        self.data_shape, self.max_dis_dict = None, None\n",
    "        self.test_dict = None\n",
    "        # Data initialization\n",
    "        self.data_prepare()\n",
    "\n",
    "    # Data preparation\n",
    "    def data_prepare(self):\n",
    "        with open(self.the_data_path + \"user_label_predict.txt\", 'r') as l_file:\n",
    "            self.user_label_list = l_file.read().split(',')  # str\n",
    "        self.user_label_num = len(set(self.user_label_list)) - 1\n",
    "\n",
    "        with open(self.the_data_path + 'train_user_items_dict.txt', 'r') as train_ui_dict:\n",
    "            self.train_user_items_dict = eval(train_ui_dict.read())\n",
    "        with open(self.the_data_path + 'train_user_items_rating_dict.txt', 'r') as train_uir_dict:\n",
    "            self.train_user_items_rating_dict = eval(train_uir_dict.read())\n",
    "        with open(self.the_data_path + 'test_user_items_rating_dict.txt', 'r') as test_uir_dict:\n",
    "            self.test_user_items_rating_dict = eval(test_uir_dict.read())\n",
    "        with open(self.the_data_path + 'nega_user_items_rating_dict.txt', 'r') as nega_uir_dict:\n",
    "            self.nega_user_items_rating_dict = eval(nega_uir_dict.read())\n",
    "\n",
    "        with open(self.the_data_path + 'cluster_users.txt', 'r') as c_us:\n",
    "            self.cluster_users = eval(c_us.read())['cluster_users']\n",
    "\n",
    "        with open(self.the_data_path + 'old_user2new.txt', 'r', encoding=\"utf-8\") as f:\n",
    "            self.old_user2new = eval(f.read())\n",
    "        with open(self.the_data_path + 'old_item2new.txt', 'r', encoding=\"utf-8\") as f:\n",
    "            self.old_item2new = eval(f.read())\n",
    "        self.data_shape = [len(self.old_user2new.keys()), len(self.old_item2new.keys())]\n",
    "\n",
    "        # Obtain positive and negative samples for testing directly\n",
    "        with open(self.the_data_path + 'test_dict.txt', 'r') as test_dict_file:\n",
    "            self.test_dict = eval(test_dict_file.read())\n",
    "\n",
    "        # Gets the list of classes that appear in the current class but not the farthest from the current class\n",
    "        with open(self.the_data_path + 'supp_nega_cluster_items.txt', 'r') as nega_ci_file:\n",
    "            self.supp_nega_cluster_items = eval(nega_ci_file.read())\n",
    "\n",
    "    # hit_rate nDCG precision recall -- pre-user\n",
    "    def result_evaluate(self, user_id: int, top_k_list: list, the_model, in_emb_s):\n",
    "        one_hit, one_ndcg, one_precision, one_recall = [], [], [], []\n",
    "        h_test_items = self.test_dict[str(user_id) + '_p'].copy()\n",
    "        test_candidate_items = h_test_items + self.test_dict[str(user_id) + '_n'].copy()\n",
    "        # print('True Percent;', len(h_test_items) / len(test_candidate_items))\n",
    "        random.shuffle(test_candidate_items)\n",
    "\n",
    "        # Select the first few with the largest Q value\n",
    "        item = np.zeros((len(test_candidate_items), self.item_vector.shape[1]))\n",
    "        i = 0\n",
    "        for c_item in test_candidate_items:\n",
    "            item[i] = feature_normalize(self.item_vector[c_item])\n",
    "            i += 1\n",
    "        i_emb_s = np.tile(in_emb_s, [len(test_candidate_items), 1])\n",
    "        q = the_model.sess.run(the_model.q, {the_model.S: i_emb_s, the_model.item: item})\n",
    "        q = -1 * q.reshape(1, len(q))[0]\n",
    "        q_sort_index = np.argsort(q)\n",
    "        a_t = np.array(test_candidate_items)[q_sort_index].tolist()[:top_k_list[-1]]\n",
    "        # print(a_t)\n",
    "        # print(test_item)\n",
    "        # print(test_candidate_items)\n",
    "\n",
    "        for top_k in top_k_list:\n",
    "            hit_count = 0\n",
    "            hit_list = []\n",
    "            dcg = 0\n",
    "            idcg = 0\n",
    "            for k in range(len(a_t[:top_k])):\n",
    "                t_item = a_t[k]\n",
    "                if t_item in h_test_items:\n",
    "                    hit_count += 1\n",
    "                    t_rating = self.test_user_items_rating_dict[user_id][t_item] - 2\n",
    "                    dcg += t_rating / math.log(k + 2)\n",
    "                    hit_list.append(t_rating)\n",
    "            hit_list.sort(reverse=True)\n",
    "            # print(hit_list)\n",
    "            kk = 0\n",
    "            for t_rating in hit_list:\n",
    "                idcg += t_rating / math.log(kk + 2)\n",
    "                kk += 1\n",
    "            if hit_count > 0:\n",
    "                one_hit.append(1)\n",
    "                one_ndcg.append(dcg / idcg)\n",
    "                one_precision.append(hit_count / top_k)\n",
    "                one_recall.append(hit_count / len(h_test_items))\n",
    "            else:\n",
    "                one_hit.append(0)\n",
    "                one_ndcg.append(0)\n",
    "                one_precision.append(0)\n",
    "                one_recall.append(0)\n",
    "        return one_hit, one_ndcg, one_precision, one_recall\n",
    "\n",
    "    def runProcess(self):\n",
    "        start_time = time.process_time()\n",
    "        emb_size = self.item_vector.shape[1]\n",
    "        s_dim, a_w_dim = emb_size, emb_size\n",
    "        if not os.path.exists('./reinforce_log/'):\n",
    "            os.makedirs('./reinforce_log/')\n",
    "        reinforce_log = open('./reinforce_log/' + the_data_name + '_dqn_cluster-' + self.data_method\n",
    "                             + '_cluster' + str(self.user_label_num + 1)\n",
    "                             + '_state' + str(self.state_num)\n",
    "                             + '_action' + str(self.a_num)\n",
    "                             + '_alpha' + str_alpha + '_'\n",
    "                             + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + '.txt', 'w')\n",
    "\n",
    "        BATCH_SIZE = 32\n",
    "        MEMORY_CAPACITY = 100\n",
    "        boundry_rating = 2\n",
    "        print('MEMORY_CAPACITY:', MEMORY_CAPACITY)\n",
    "        env = RecommendENV(s_num=self.state_num, a_num=self.a_num, state_dim=s_dim,\n",
    "                           item_vector=self.item_vector, supp_nega_cluster_items=self.supp_nega_cluster_items,\n",
    "                           boundry_rating=boundry_rating, train_user_items_dict=self.train_user_items_dict,\n",
    "                           train_user_items_rating_dict=self.train_user_items_rating_dict,\n",
    "                           nega_user_items_rating_dict=self.nega_user_items_rating_dict,\n",
    "                           user_label_list=self.user_label_list, data_shape=self.data_shape)\n",
    "\n",
    "        # Control training times parameter setting\n",
    "        MAX_STEPS = MEMORY_CAPACITY * 2  # Maximum training steps\n",
    "        MIN_STEPS = MEMORY_CAPACITY * 1  # Minimum training steps, greater than or equal to memory\n",
    "        once_show_num = 10\n",
    "        # The convergence stop indicator,\n",
    "        # stops when the percentage of the sub average value to the original value is less than or equal to this value\n",
    "        stop_line = 0.1\n",
    "        c_select_size = 50  # Number of randomly selected candidate set items, make sure select_size < len(c_items_list)\n",
    "        o_train_percent = 0.1  # Select the proportion of users in the training set to see in the training\n",
    "\n",
    "        # result_evaluate\n",
    "        total_hits, total_ndcgs, total_precisions, total_recalls = [], [], [], []\n",
    "        for _ in self.test_top_k:\n",
    "            total_hits.append([])\n",
    "            total_ndcgs.append([])\n",
    "            total_precisions.append([])\n",
    "            total_recalls.append([])\n",
    "        cluster_w = []\n",
    "        # t_sun = 0\n",
    "        for i in range(self.user_label_num + 1):\n",
    "            cluster_w.append(len(self.cluster_users[i]) / self.data_shape[0])\n",
    "            # t_sun += cluster_w[i]\n",
    "        # print(cluster_w, t_sun)\n",
    "\n",
    "        total_cluster_steps = 0\n",
    "        for i in range(self.user_label_num + 1):\n",
    "            # user_cluster\n",
    "            cluster_hits, cluster_ndcgs, cluster_precisions, cluster_recalls = [], [], [], []\n",
    "            for _ in self.test_top_k:\n",
    "                cluster_hits.append([])\n",
    "                cluster_ndcgs.append([])\n",
    "                cluster_precisions.append([])\n",
    "                cluster_recalls.append([])\n",
    "\n",
    "            config = tf.ConfigProto(allow_soft_placement=True)\n",
    "            config.gpu_options.allow_growth = True\n",
    "            with tf.Session(config=config) as o_sess:\n",
    "                # Each cluster corresponds to a graph\n",
    "                dqn = DQN(o_sess, self.item_vector, s_dim, self.state_num, BATCH_SIZE, MEMORY_CAPACITY)\n",
    "                o_sess.run(tf.global_variables_initializer())\n",
    "                # Create a saver.\n",
    "                cluster_saver = tf.train.Saver()\n",
    "                the_saver_path = './reinforce_log/' + the_data_name + '_dqn_cluster' \\\n",
    "                                 + '/state' + str(self.state_num) \\\n",
    "                                 + '/action' + str(self.a_num) \\\n",
    "                                 + '/' + self.data_method + '/c' + str(i)\n",
    "                meta_path = the_saver_path + '/model.meta'\n",
    "                if self.is_use_history:\n",
    "                    if os.path.exists(meta_path) \\\n",
    "                            and os.path.exists(the_saver_path):\n",
    "                        cluster_saver = tf.train.import_meta_graph(meta_path)\n",
    "                        cluster_saver.restore(o_sess, tf.train.latest_checkpoint(the_saver_path))\n",
    "                        print('Filled with', the_saver_path)\n",
    "                explore_var = 1  # Initial value of exploration item\n",
    "                user_size = len(self.cluster_users[i])  # Transboundary control\n",
    "\n",
    "                # Initialize memory buffer\n",
    "                for ii in range(MEMORY_CAPACITY):\n",
    "                    user_id = self.cluster_users[i][int(ii % user_size)]\n",
    "\n",
    "                    # Construct candidate set once per selection\n",
    "                    train_num = int(o_train_percent * c_select_size)\n",
    "                    if train_num > len(self.train_user_items_dict[user_id]):\n",
    "                        train_num = len(self.train_user_items_dict[user_id])\n",
    "                    train_list = random.sample(self.train_user_items_dict[user_id], train_num)\n",
    "                    nega_num = int((c_select_size - train_num) / 2)\n",
    "                    nega_list = env.getNegative(user_id=user_id, nega_num=nega_num,\n",
    "                                                supp_nega_cluster_items=self.supp_nega_cluster_items[int(self.user_label_list[user_id])])\n",
    "                    random_c_list = train_list + nega_list\n",
    "                    num_random = c_select_size - train_num - len(nega_list)\n",
    "                    random_list = env.getRandom(random_c_list, num_random)\n",
    "                    random_c_list += random_list\n",
    "                    random.shuffle(random_c_list)\n",
    "\n",
    "                    s, emb_s = env.init_env(user_id=user_id)\n",
    "                    a_ = dqn.choose_action(emb_s, random_c_list)\n",
    "                    item_vec = self.item_vector[a_]\n",
    "                    s_, emb_s_, r = env.step_dqn(user_id=user_id,\n",
    "                                                 in_state=s,\n",
    "                                                 in_a=a_,\n",
    "                                                 train_list=train_list,\n",
    "                                                 nega_list=nega_list)\n",
    "                    # print(emb_s.shape)\n",
    "                    # print(item_vec.shape)\n",
    "                    dqn.store_transition(emb_s, item_vec, a_, r, emb_s_)\n",
    "                hit_list, ndcg_list, precision_list, recall_list = [], [], [], []\n",
    "                for epoch in range(self.epochs):\n",
    "                    str_cluster = 'Cluster:' + str(i)\n",
    "                    str_td_loss = 'Loss:'\n",
    "                    str_reward = 'Mean_Reward:'\n",
    "                    t_sum_steps = 0\n",
    "                    step_count = 1\n",
    "                    once_show_r = 0\n",
    "                    o_td_error = 0\n",
    "\n",
    "                    # training\n",
    "                    dqn.set_keep_rate(keep_rate=0.8)\n",
    "                    while True:\n",
    "                        user_id = self.cluster_users[i][random.randint(0, user_size - 1)]\n",
    "                        s, emb_s = env.init_env(user_id=user_id)\n",
    "                        # A certain number of training for each user\n",
    "                        for _ in range(self.one_u_steps):\n",
    "                            train_num = int(o_train_percent * c_select_size)\n",
    "                            if train_num > len(self.train_user_items_dict[user_id]):\n",
    "                                train_num = len(self.train_user_items_dict[user_id])\n",
    "                            train_list = random.sample(self.train_user_items_dict[user_id], train_num)\n",
    "                            nega_num = int((c_select_size - train_num) / 2)\n",
    "                            nega_list = env.getNegative(user_id=user_id, nega_num=nega_num,\n",
    "                                                        supp_nega_cluster_items=self.supp_nega_cluster_items[int(self.user_label_list[user_id])])\n",
    "                            random_c_list = train_list + nega_list\n",
    "                            num_random = c_select_size - train_num - len(nega_list)\n",
    "                            random_list = env.getRandom(random_c_list, num_random)\n",
    "                            random_c_list += random_list\n",
    "                            random.shuffle(random_c_list)\n",
    "                            # print(random_c_list)\n",
    "                            # print(s, s_emb, s_flag)\n",
    "                            if explore_var > 0.5:\n",
    "                                a_ = random.sample(random_c_list, self.a_num)\n",
    "                                item_vec = self.item_vector[a_]\n",
    "                            else:\n",
    "                                a_ = dqn.choose_action(emb_s, random_c_list)\n",
    "                                item_vec = self.item_vector[a_]\n",
    "                            s_, emb_s_, r = env.step_dqn(user_id=user_id,\n",
    "                                                         in_state=s,\n",
    "                                                         in_a=a_,\n",
    "                                                         train_list=train_list,\n",
    "                                                         nega_list=nega_list)\n",
    "                            # print(emb_s.shape)\n",
    "                            # print(item_vec.shape)\n",
    "                            dqn.store_transition(emb_s, item_vec, a_, r, emb_s_)\n",
    "\n",
    "                            s = s_\n",
    "                            emb_s = emb_s_\n",
    "                            once_show_r += r\n",
    "\n",
    "                            # train\n",
    "                            o_td_error = dqn.learn()\n",
    "                            # print(o_td_error)\n",
    "\n",
    "                        if step_count % once_show_num == 0:\n",
    "                            # print('State_flag:', s_flag)\n",
    "                            explore_var *= 0.9\n",
    "                            # print(explore_var)\n",
    "                            # print('State:', s)\n",
    "                            new_loss = o_td_error / (once_show_num * self.one_u_steps)\n",
    "                            str_td_loss += str(new_loss) + ' '\n",
    "                            str_reward += str(once_show_r / (once_show_num * self.one_u_steps)) + ' '\n",
    "\n",
    "                            if step_count >= MIN_STEPS:\n",
    "                                # Take absolute value to prevent division by 0\n",
    "                                if np.abs(old_loss - new_loss) / (np.abs(old_loss) + 0.000001) < stop_line:\n",
    "                                    break\n",
    "\n",
    "                            old_loss = new_loss\n",
    "                            once_show_r = 0\n",
    "                            o_td_error = 0\n",
    "                        # print(t_td_error)\n",
    "                        if step_count >= MAX_STEPS:\n",
    "                            break\n",
    "                        step_count += 1\n",
    "                    t_sum_steps += step_count\n",
    "                    str_steps = 'Steps:' + str(t_sum_steps * self.one_u_steps)\n",
    "                    str_train_log = str_cluster + '\\n' + str_td_loss + '\\n' + str_reward + '\\n' \\\n",
    "                                    + str_steps\n",
    "                    print(str_train_log)\n",
    "                    reinforce_log.write(str_train_log + '\\n')\n",
    "                    reinforce_log.flush()\n",
    "                    total_cluster_steps += step_count\n",
    "\n",
    "                    # Test and use the parameters of the corresponding class before changing the cluster\n",
    "                    dqn.set_keep_rate(keep_rate=1)\n",
    "                    for t_user_id in self.cluster_users[i]:\n",
    "                        try:\n",
    "                            self.test_dict[str(t_user_id) + '_p']\n",
    "                        except KeyError:\n",
    "                            continue\n",
    "                        # Initialize test environment\n",
    "                        s, emb_s = env.init_test_env(t_user_id)\n",
    "                        # print(s)\n",
    "                        # test\n",
    "                        one_hit, one_ndcg, one_precision, one_recall = self.result_evaluate(\n",
    "                            user_id=t_user_id,\n",
    "                            top_k_list=self.test_top_k,\n",
    "                            the_model=dqn,\n",
    "                            in_emb_s=emb_s)\n",
    "                        # print(t_user_id, one_hit, one_ndcg, one_precision, one_recall)\n",
    "                        kk = 0\n",
    "                        for _ in self.test_top_k:\n",
    "                            cluster_hits[kk].append(one_hit[kk])\n",
    "                            cluster_ndcgs[kk].append(one_ndcg[kk])\n",
    "                            cluster_precisions[kk].append(one_precision[kk])\n",
    "                            cluster_recalls[kk].append(one_recall[kk])\n",
    "                            kk += 1\n",
    "                    # print(len(cluster_hits))\n",
    "                    str_rate = 'Evaluate of cluster ' + str(i) + ', Epoch ' + str(epoch)\n",
    "                    kk = 0\n",
    "                    hit_t, ndcg_t, precision_t, recall_t = [], [], [], []\n",
    "                    for top_k in self.test_top_k:\n",
    "                        if len(cluster_hits) > 0:\n",
    "                            cluster_hit = np.array(cluster_hits[kk]).mean()\n",
    "                            cluster_ndcg = np.array(cluster_ndcgs[kk]).mean()\n",
    "                            cluster_precision = np.array(cluster_precisions[kk]).mean()\n",
    "                            cluster_recall = np.array(cluster_recalls[kk]).mean()\n",
    "                        else:\n",
    "                            cluster_hit = 0\n",
    "                            cluster_ndcg = 0\n",
    "                            cluster_precision = 0\n",
    "                            cluster_recall = 0\n",
    "                        cluster_f1 = 2 * cluster_precision * cluster_recall / (\n",
    "                                cluster_precision + cluster_recall + 0.000001)\n",
    "                        hit_t.append(cluster_hit)\n",
    "                        ndcg_t.append(cluster_ndcg)\n",
    "                        precision_t.append(cluster_precision)\n",
    "                        recall_t.append(cluster_recall)\n",
    "                        str_rate += '\\nTop ' + str(top_k) + \\\n",
    "                                    '. Hit_rate:' + str(cluster_hit) + \\\n",
    "                                    ' nDCG:' + str(cluster_ndcg) + \\\n",
    "                                    ' Precision:' + str(cluster_precision) + \\\n",
    "                                    ' Recall:' + str(cluster_recall) + \\\n",
    "                                    ' F1:' + str(cluster_f1)\n",
    "                        kk += 1\n",
    "                    hit_list.append(hit_t)\n",
    "                    ndcg_list.append(ndcg_t)\n",
    "                    precision_list.append(precision_t)\n",
    "                    recall_list.append(recall_t)\n",
    "                    print(str_rate)\n",
    "                    reinforce_log.write(str_rate + '\\n')\n",
    "                    reinforce_log.flush()\n",
    "                best_pos = 0\n",
    "                for ii in range(1, len(hit_list)):\n",
    "                    if hit_list[ii][0] > hit_list[best_pos][0]:\n",
    "                        best_pos = ii\n",
    "                kk = 0\n",
    "                for _ in self.test_top_k:\n",
    "                    total_hits[kk].append(hit_list[best_pos][kk] * cluster_w[i])\n",
    "                    total_ndcgs[kk].append(ndcg_list[best_pos][kk] * cluster_w[i])\n",
    "                    total_precisions[kk].append(precision_list[best_pos][kk] * cluster_w[i])\n",
    "                    total_recalls[kk].append(recall_list[best_pos][kk] * cluster_w[i])\n",
    "                    kk += 1\n",
    "                # Save model each class has its own model\n",
    "                if not os.path.exists(the_saver_path):\n",
    "                    os.makedirs(the_saver_path)\n",
    "                cluster_saver.save(o_sess, os.path.join(the_saver_path, 'model'))\n",
    "            # Clear variables previously defined in the default graph\n",
    "            tf.reset_default_graph()\n",
    "\n",
    "        str_log = 'dqn_rec'\n",
    "        kk = 0\n",
    "        for top_k in self.test_top_k:\n",
    "            total_hr, total_ndcg, total_precision, total_recall = 0, 0, 0, 0\n",
    "            # print(total_hits)\n",
    "            for i in range(self.user_label_num + 1):\n",
    "                total_hr += total_hits[kk][i]\n",
    "                total_ndcg += total_ndcgs[kk][i]\n",
    "                total_precision += total_precisions[kk][i]\n",
    "                total_recall += total_recalls[kk][i]\n",
    "            total_f1 = 2 * total_precision * total_recall / (total_precision + total_recall + 0.000001)\n",
    "            str_log += '\\nTTop ' + str(top_k) + \\\n",
    "                       '. HR:' + str(total_hr) + \\\n",
    "                       ' nDCG:' + str(total_ndcg) + \\\n",
    "                       ' Precision:' + str(total_precision) + \\\n",
    "                       ' Recall:' + str(total_recall) + \\\n",
    "                       ' F1:' + str(total_f1)\n",
    "            kk += 1\n",
    "        str_steps = 'Total train steps:' + str(total_cluster_steps * self.one_u_steps)\n",
    "        end_time = time.process_time()\n",
    "        str_time = \"Cost time is %f\" % (end_time - start_time)\n",
    "        reinforce_log.write(str_log + '\\n' + str_steps + ' ' + str_time)\n",
    "        reinforce_log.flush()\n",
    "        reinforce_log.close()\n",
    "        print(str_log + '\\n' + str_steps + ' ' + str_time)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # glove mf\n",
    "    data_method = 'glove'\n",
    "    emb_size = 100\n",
    "    # 'Digital_Music' 'Beauty' 'Clothing_Shoes_and_Jewelry'\n",
    "    the_data_name = 'Digital_Music'\n",
    "    state_num = 10  # Number of items in the action\n",
    "    one_u_steps = 10  # Training times per user\n",
    "    test_top_k = [5, 10, 20]  # Top_k during test\n",
    "    str_alpha = '0.5'  # Proportion of product description\n",
    "    epochs = 3  # Number of training rounds\n",
    "\n",
    "    the_data_path = './Amazon/' + the_data_name + '/' + data_method + '/' + str(emb_size) + '/'\n",
    "    rl_model = RlProcess(the_data_path=the_data_path,\n",
    "                         the_data_name=the_data_name,\n",
    "                         data_method=data_method,\n",
    "                         epochs=epochs,\n",
    "                         state_num=state_num,\n",
    "                         action_num=1,\n",
    "                         one_u_steps=one_u_steps,\n",
    "                         test_top_k=test_top_k,\n",
    "                         is_use_history=False)\n",
    "    rl_model.runProcess()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-11T19:30:07.754604Z",
     "start_time": "2024-03-11T19:27:31.956813Z"
    }
   },
   "id": "952420273f155ae5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "beca6c0476bde440"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
